{
  "hash": "c4820f096a6d7eb82fb91a2adba5e52c",
  "result": {
    "markdown": "---\ntitle: Limited Dependent Variable Models\nsubtitle: MLE-Mua ha ha ha\nauthor: Fernando Rios-Avila\nformat:\n  revealjs:\n    slide-number: true\n    width: 1600\n    height: 900\n    code-fold: true\n    code-overflow: wrap\n    echo: true\n    css: styles.css\n    chalkboard: true\n---\n\n## What do we mean Limited??\n\n::: {#29ad14d1 .cell execution_count=1}\n``` {.stata .cell-code}\nclear\nset obs 2000\ngen r1 = runiform()\ngen r2 = rchi2(5)/5 \ngen r3 = round(rchi2(3))*3\ngen r4 = rnormal()\nset scheme white2\ncolor_style tableau\nhistogram r1, name(m1, replace) \nhistogram r2, name(m2, replace)\nhistogram r3, name(m3, replace) width(1)  \nhistogram r4, name(m4, replace)\ngraph combine m1 m2 m3 m4\ngraph export images/fig9_1.png, width(1000) replace\n```\n:::\n\n\n![Limited Dependent variables](images/fig9_1.png)\n\n##\n\n### What do we mean Limited?? {.middle}\n\n- When we think about \"limited dependent variable\" models, we refer to models when the distribution of the dep.variable is \"limited\"\n  - In other words. The values it can take are restricted! (positive, or only integer), within a range, etc\n\n- Can you still use LRM for them? \n- Will anything change if you do?\n- Do we care?\n\n## No we dont, but..\n\n- We dont really care. In fact we have already use LRM on that fashion:\n  - LPM: Dep variable was a Dummy\n  - Wages: Always positive\n  - \\# Children: Countable\n\n- But, there are couple of things one should consider.\n  1. Models of this kind are usually heteroskedastic by construction. (robust? Weighted?)\n  2. Predictions could made no sense. \n  3. There are better models we could use to analyze the data\n\n**Better** under some assumptions\n\n- However, this models cannot be estimated using OLS (there is no \"close form solution\")\n- We ***may*** need to learn a new method: Maximum Likelihood \n\n\n## Probits and Logits\n\n- **LPM** are easy, fast, and good for most data analysis (exploration). But they have some limitations.\n- Most limitations can be overcome with alternative models: Logit or Probit\n- In constrast with LPM (which aims to explain individual outcomes), Logit/probit aims to explain Conditional Probabilities:\n\n$$p(y=1|x) = G(x\\beta)$$\n\n- where the function $G()$ makes sure the predicted outcome is always between 0 and 1. \n- Caveat: Because $G()$ is nonlinear, this is a nonlinear model, and marginal effects are harder to estimate.\n\n##\n\n### What to use for $G()$\n\n- Two leading options:\n\n$$logit: G(x\\beta) = \\frac{\\exp{x\\beta}}{1+\\exp{x\\beta}}$$\n$$probit: G(x\\beta) = \\Phi(x\\beta)=\\int_{-\\infty}^{x\\beta}\\phi(z)dz$$\n\n- But in practice Either will work. Then why the difference?\n\n## \n\n### Probits and Logits: Latent variables\n\n- It all comes down to the Latent variable!\n\n- Assumption: \n  - Everybody has a latent score on every \"binary\" decision: The value to a decision $y^*$\n    $$y^* = x\\beta + e $$\n\n  - If $y^*$ is above certain threshold ($y^*>0$), you \"do\" something ($y=1$). If not you dont ($y=0$).\n- Thus the choice between logit and probit depends on the distribution of $e$.\n  - $e$ is normal, then probit\n  - $e$ is logistic, then logit\n\n\n##\n\n### Some Math\n\nLatent Model:\n\n$$ y^* = x\\beta + e $$\n\nWe aim to measure the probablity of a positive latent. \n\n$$\\begin{aligned}\nP(y^*>0|x) & = P(x\\beta + e>0|x) \\\\\n& = P( e>- x\\beta|x) \\\\\n& = 1 - P( e < - x\\beta|x) = 1-G( - x\\beta|x) \\\\\n& = G(x\\beta)\n\\end{aligned}\n$$\n\nlast step valid only if $G()$ is symetrical. \n\n\n##\n\n###  Marginal Effects?\n\n- Same as before. The partial derivative!\n\n$$\\begin{aligned}\np(y=1|x) &= G(\\beta_0 + \\beta_1 x_1 +\\beta_2 x_2 ) \\\\\n\\frac{\\partial p(y=1|x)}{\\partial x_1} = G'(x\\beta)\\beta_1=g(x\\beta)\\beta_1\n\\end{aligned}\n$$\n\n- But if variables are dummies, we need to estimate true effect.\n\n$$\\begin{aligned}\np(y=1|x) &= G(\\beta_0 + \\beta_1 x_1 +\\beta_2 D_2 ) \\\\\n\\frac{\\partial p(y=1|x)}{\\partial D_2} = G(\\beta_0 + \\beta_1 x_1 +\\beta_2 )-G(\\beta_0 + \\beta_1 x_1 )\n\\end{aligned}\n$$\n\nand yes, you could also have interactions, polynomials, etc\n\n## MLE: How does this work?\n\n- MLE: Maximum Likelihood Estimator, is an alternative method to OLS that allows you to estimate parameters in nonlinear models.\n- The idea of the method is to \"model\" the conditional distribution of the data $F(y|x,\\theta)$ or $f(y|x,\\theta)$, assuming $X's$ are given and modifying values of $\\theta$ (distribution parameters).\n\n- $LRM$ **could** be estimated via MLE, but you will need More assumptions:\n  - The error $e$ is normal.\n- Then \"simply\" find the parameters for the mean and variance that \"maximizes\" the probability that data Comes a given distribution.\n\n- In the case of Probit/logit, there is \"only\" one paramter we need to identify. The conditional probabilty $p(y=1|X)$.\n  - Except that we allow this to vary by $X$\n\n## Likelihood function for Logit/probit\n\n$$L_i = G(x\\beta)^{y=1}*(1-G(x\\beta))^{y=0} \n$$\n\nUnder Independence:\n\n$$L_D = L_1 \\times L_2 \\times \\dots L_N\n$$\n\nThus we need to find the $\\beta's$ that make $L_D$ the largest.\n\n##\n\n::: {#11dbd454 .cell execution_count=2}\n``` {.stata .cell-code}\n  clear\n  set obs 25\n  gen r = runiform()<.7\n  mata: \n    r = st_data(.,\"r\")\n    ll = J(99,2,0)\n    for(i=1;i<=99;i++){\n      theta = i/100\n      // Log Properties\n      ll[i,]= theta,exp(sum(log(theta:^(r:==1) :* (1-theta):^(r:==0))))\n    }\n  end\n  qui getmata ll*=ll , force\n  ren ll1 theta\n  ren ll2 likelihood\n  *scatter likelihood theta \n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of observations (_N) was 0, now 25.\n\n```\n:::\n:::\n\n\n::: {#863cdaa2 .cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](9_ldvm_files/figure-html/cell-4-output-1.png){}\n:::\n:::\n\n\n## Testing?\n\n- You have two options...\n- And two sets of parameters\n\n",
    "supporting": [
      "9_ldvm_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}