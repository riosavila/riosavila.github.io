{
  "hash": "0837d6cfe2c593099c02fd90b54b0a5f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Times Series Part-I\nsubtitle: Basic Regression Analysis\nauthor: Fernando Rios-Avila\nformat:\n  revealjs:\n    slide-number: true\n    width: 1600\n    height: 900\n    code-fold: true\n    code-overflow: wrap\n    echo: true\n    css: styles.css\n    chalkboard: true\n---\n\n![](images/paste-8.png)\n\n## The nature of time series data\n\n-   Time series \"works\" different from Repeated crossection.\n\n    -   You do not have access to a random sample. (Window of time if fixed)\n\n    -   You have access to a single \"random\" time line\n\n-   And in time series, one needs to be quite aware that Data has Baggage...What you see today is the product of everything that happens in the far past.\n\n-   This is what we call Past Dependent, or simple serial correlation.\n\n    -   And is why we need to be careful when we use time series data.\n\n## The nature of time series data\n\n-   Data cannot not be arbitrarily reordered. (Past affect future)\n\n    -   Typical features: serial correlation/nonindependence of observations\n\n-   Randomness of the data comes from the uncertainty of shocks that affects a variable over time, not from sampling.\n\n-   Your \"Sample\" is one realized path that you observe in a narrow window of time.\n\n-   Because observations are no longer independent, we will need to worry about correlation across time.\n\n-   In fact, because data may be strongly correlated across time (say your age), it may generate some problems when applying OLS.\n\n    -   Highly correlated data (high innertia) will have common \"trends\" that do not necessarity reflect the causal relationship between variables.\n\n-   So, we must learn \"new\" tools to deal with this problem.\n\n# Basic TS models\n\n## 1: Static model\n\n-   The static model is the simplest model for analyzing time series data. (like SLRM)\n-   A Static model aims to find correlations between contemporaneous variables.\n    -   Implicity, this **assumes** there are no dynamic interactions among variables\n\n$$GDP_t = a_0 + a_1 educ_t + a_2 Invest_t + a_3 Unemp_t + u_t$$\n\nEducation, investment and Unemployment rate are assumed to affect GDP contemporaneously. But Lags of Leads of the data has no effect on GDP.\n\n-   These models are not useful for Forecasting, and Only produces reasonable estimates under very strong assumptions (we will see this later).\n\n## 2: Finite Distributed Lag model (FDL)\n\n-   The FDL model is a simple extension of the static model that allows for dynamic interactions of independent variables.\n    -   ***Finite*** Because we choose How far back (lags) to add to the model\n    -   ***Distributed*** Because each lag will have a different effect on the dependent variable.\n-   Simple Example: $$fr_t = a_0 + a_1 te_t +e_t$$ $$fr_t = a_0 + a_1 te_t + a_2 te_{t-1}+ a_3 te_{t-2}+e_t$$\n\n$fr_t$: Fertility Rate; $te_t$: Tax exemption\n\nThis is an FDL model with 2 lags.\n\n## \n\n-   More Generality, FDL of order **q** is defined as:\n\n$$y_t = a_0 + \\sum_{k=0}^q \\delta_k z_{t-k} + e_t$$\n\n-   You can choose Lags using F-statistic, but also considering the \"loss\" of Degrees of freedom.\n    -   More lags, less data to estimate the coefficients, more coefficients to estimate\n    -   Coefficients may suffer from High Collinearity\n    -   Allow us to draw inference on Duration of effects.\n-   Two Types of Effects:\n    -   Transitory effects $\\frac{\\partial y_t}{\\partial z_{t-q}}=\\delta_q$\n    -   Permanent effect $\\frac{\\partial y_t}{\\partial z}=\\sum \\frac{\\partial y_t}{\\partial z_{t-q}}=\\sum \\delta_k$\n\n## \n### What do you expect to see?\n\n::: {layout-ncol=2}\n\n![Transitory](images/paste-11.png)\n\n![Permanent](images/paste-12.png)\n\n:::\n\n- **Transitory** effects measure the short-term effect on outcome (Only of the additional unit)\n- **Permanent** effects measure the long-term effect on outcome (adding up Transitory effects)\n\n## 3: Infinite Distributed Lag model (IDL)\n\n- This is a more advanced model that allows for the effects of independent variables to last forever, but how?\n  - A model with infinite number of lags cannot be estimated...unless some restrictions are imposed.\n\n$$ \\text{Wrong: } y_t = a_0 + \\sum_{k=0}^{\\infty} \\delta_k z_{t-k} + e_t$$\n$$ \\text{Better: } y_t = a_0 + \\sum_{k=0}^{\\infty} \\gamma \\delta^k z_{t-k} + e_t$$\n\n- So we went from pretending to estimate an infinite number of coefficients $\\delta_k$ to estimating only two parameters $\\gamma$ and $\\delta$. \n    - This is called the **Geometric Distributed Lag** model.\n\n##\n\n- GDL requires an additional \"Trick\":\n\n$$\\begin{aligned}\ny_t &= a_0 + \\gamma z_t + \\gamma \\rho z_{t-1} + \\dots + e_t \\\\\ny_{t-1} &= a_0 + \\gamma z_{t-1} + \\gamma \\rho z_{t-2} + \\dots + e_{t-1}\n\\end{aligned}\n$$\n\n- Subtracting the second equation (times $\\rho$ ) from the first one, we get:\n  \n$$y_t =  \\rho y_{t-1} + a_0 (1-\\rho) + \\gamma z_t  + v_{t}$$\n\nWhich requires really strong assumptions!\n\n- The short and Long effects are:\n\n$$\\text{Short}\\frac{\\partial y_t}{\\partial z_{t-k}}=\\gamma \\rho^k \\text{ and }\n\\text{Long}\\frac{\\partial y_t}{\\partial z}=\\frac{\\gamma}{1-\\rho}$$\n\n\n## 4: Rational Distributed Lag model (RDL)\n\n- Because IDL imposes strong assumptions on coefficients, we can relax them by allowing for lags. This is called the RDL model.\n$$y_t = a_0 + \\gamma_0 z_t + \\gamma_1 z_t  +\\delta y_{t-1} + e_t- \\rho e_{t-1}$$\n\n- Which has the following short and long effects:\n\n$$\\text{ Short:}\\frac{\\partial y_t}{\\partial z_t} = \\gamma_0  $$\n$$\\text{ Short:}\\frac{\\partial y_t}{\\partial z_{t-k}} = \\rho^{k-1}(\\rho \\gamma_0 + \\gamma_1) $$\n$$\\text{ Long:}\\frac{\\partial y_t}{\\partial z} = \\frac{\\gamma_0 + \\gamma_1}{1-\\rho}\n$$\n\n# Assumptions\nAt least for M1 and M2\n\n## Assumptions: M1 and M2\n\nA1. Linear in Parameters: Same old, same old, $y_t = \\beta_0 + \\beta_1 x_{1t} + \\dots + \\beta_k x_{kt} + u_t$\n\nA2. No Perfect Collinearity: Also Same old, same old \n\n## \n### The Stronger ones\n\n$$X=\\begin{pmatrix}\nx_{11} & x_{12} & \\dots & x_{1k} \\\\\nx_{21} & x_{22} & \\dots & x_{2k} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{T1} & x_{T2} & \\dots & x_{Tk} \n\\end{pmatrix}\n$$\n\nA3. Zero Conditional Mean\n\n$$E(u_t|X)=0\n$$\n\nSo that $X$ is strictly Exogenous (across all possible times).\n\nNot only $x_t$ should not be affected by $u_t$, but neither should $x_{t-1}$ nor $x_{t+1}$\n\n**A1-A3** will guarantee that OLS is unbiased.\n\n## What about Std Errors?\n\nA4: Strong Homoskedasticity\n\n$$Var(u_t|X)=\\sigma^2\n$$\n\nA5: No Serial Correlation (Correlation across time of the errors)\n\n$$Corr(u_t,u_s|X)=0 \\text{ for all } t\\neq s\n$$\n\nAlso difficult to fulfill, because unobserved may have inertia, and depend on past values.\n\n##\n\nNevertheless, A1-A5: Standard errors can be estimated using the usual formula:\n\n$$\\begin{aligned}\n\\hat{Var}(\\hat{\\beta}) &= \\hat{\\sigma}^2(X'X)^{-1} \\\\\n\\hat{Var}(\\hat{\\beta_k}) &= \\frac{\\hat{\\sigma}^2}{SST_k(1-R^2_k)} \\\\\n\\hat \\sigma^2 &= \\frac{1}{T-k-1}\\sum_{t=1}^T \\hat{u}_t^2\n\\end{aligned}\n$$\n\nWhich are BLUE! (Best Linear Unbiased Estimators)\n\nA6: **Normality**, The $\\beta$'s are normally distributed, and F-tests and t-tests are valid.\n\n## Example: The effet of inflation and Deficit on Interest rates {.scrollable}\n\nModel: $i_t = \\beta_0 + \\beta_1 inf_t + \\beta_2 def_t + u_t$\n\nA1: $\\checkmark$ (but questionable)\n\nA2: $\\checkmark$ (almost never a problem)\n\nA3: NO! Deficits and inflation today may affect adjustments in the future ($u_{t+1}$), Similarly,  $u_t$ may have to be adjusted in the future using Deficits and inflation.\n\nA4: Perhaps? Usually there is a direct relationship between deficit and uncertainty, which will generate heteroskedasticity.\n\nA5: NO! There could be many things in $u_t$ that are correlated across time. (taxes?)\n\nA6: NO...the errors are almost never normal\n\n::: {#3cba7351 .cell .larger execution_count=1}\n``` {.stata .cell-code code-fold=\"false\"}\nfrause intdef, clear\nreg i3 inf def\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<style>div.jp-Notebook .datagrid-container {min-height: 448px; }</style>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n      Source |       SS           df       MS      Number of obs   =        56\n-------------+----------------------------------   F(2, 53)        =     40.09\n       Model |  272.420338         2  136.210169   Prob > F        =    0.0000\n    Residual |  180.054275        53  3.39725047   R-squared       =    0.6021\n-------------+----------------------------------   Adj R-squared   =    0.5871\n       Total |  452.474612        55  8.22681113   Root MSE        =    1.8432\n\n------------------------------------------------------------------------------\n          i3 | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n         inf |   .6058659   .0821348     7.38   0.000     .4411243    .7706074\n         def |   .5130579   .1183841     4.33   0.000     .2756095    .7505062\n       _cons |   1.733266    .431967     4.01   0.000     .8668497    2.599682\n------------------------------------------------------------------------------\n```\n:::\n:::\n\n\n# Extending the Basic Model\n\n## 1: Event Studies\n\n- We can use Dummies to represent Transitory shocks (events) on the outcome\n  - Dummies for the impact of Covid (if we assume effect was transitory), 0 for all periods except for months we were at home.\n- Or use Dummies to capture permanent changes in the outcome\n  - Dummies for ChatGPT. 0 before the introduction, 1 after\n- Possible to use Lags of Dummies to see the dynamics of the impact.\n  - With Time series may not be as useful, because its easy to mix event effects with trends, although one could also directly control for trends. \n\n$$FRate_t = 98.7 + 0.08 PE_t - 24.24 WW2 - 31.6 Pill_t+ e_t$$\n\n- $Pill_t$, $WW2_t$ are dummies for the introduction of the pill (permanent) and WW2 (transitory) effects on Fertility rate.\n\n## 2: Logs and Growth models\n\n- Very Similar to what was done in Cross Sectional Models. \n\n- Using Logs of the Dep variable changes the interpretation of the coefficients.\n\n$$\\Delta log(x)\\simeq \\%\\Delta x$$\n\n- Because of that, you can use \"log-models\" and a trend to estimate the growth rates.\n\n`reg log_gdp year`\n\nThe coefficient of `year` should give you the average growth rate of GDP.\n\n- But the model can also be used in levels to identify trends.\n\n## 3: Trends and Seasonality{.scrollable}\n\n- Trends are very common in time series data.\n  - Because of the \"inertia\" of the data, its very common to see variables sharing common trends even if they are completely unrelated. (GDP and age)\n- Ignoring this may cause problems, as one may identify spurious relationships. (things that look to have significant effects, even tho they are not related)\n  \n- Consider the following model (investment on housing, and housing prices):\n\n::: {#136614d6 .cell .larger execution_count=2}\n``` {.stata .cell-code}\nqui:frause hseinv,clear\nreg  linvpc lprice\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n      Source |       SS           df       MS      Number of obs   =        42\n-------------+----------------------------------   F(1, 40)        =     10.53\n       Model |  .254364468         1  .254364468   Prob > F        =    0.0024\n    Residual |  .966255566        40  .024156389   R-squared       =    0.2084\n-------------+----------------------------------   Adj R-squared   =    0.1886\n       Total |  1.22062003        41   .02977122   Root MSE        =    .15542\n\n------------------------------------------------------------------------------\n      linvpc | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      lprice |   1.240943   .3824192     3.24   0.002     .4680452    2.013841\n       _cons |  -.5502345   .0430266   -12.79   0.000    -.6371945   -.4632746\n------------------------------------------------------------------------------\n```\n:::\n:::\n\n\n- If we estimate this model, we find a very strong relationship, perhaps because of common trends. Adding a trend, however, may change the results.\n\n$$E(log(invpc_t)|x) = -20.04 -0.38 log(price) + 0.009 year $$\n\n::: {#378c7668 .cell .larger execution_count=3}\n``` {.stata .cell-code}\nreg linvpc lprice  year\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n      Source |       SS           df       MS      Number of obs   =        42\n-------------+----------------------------------   F(2, 39)        =     10.08\n       Model |  .415945108         2  .207972554   Prob > F        =    0.0003\n    Residual |  .804674927        39   .02063269   R-squared       =    0.3408\n-------------+----------------------------------   Adj R-squared   =    0.3070\n       Total |  1.22062003        41   .02977122   Root MSE        =    .14364\n\n------------------------------------------------------------------------------\n      linvpc | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      lprice |  -.3809612   .6788352    -0.56   0.578    -1.754035    .9921125\n        year |   .0098287   .0035122     2.80   0.008     .0027246    .0169328\n       _cons |  -20.03976   6.964526    -2.88   0.006    -34.12684   -5.952675\n------------------------------------------------------------------------------\n```\n:::\n:::\n\n\n## 3: Trends and Seasonality {.scrollable}\n\n- Just as time series are characterized by trends, they are also characterized by seasonality.\n  - Seasonality is the presence of regular patterns in the data that repeat over fixed periods of time.\n  - Seasonality is a form of \"deterministic\" variation, because it is predictable.\n- For example, If you look at Public expenditure, you will see that its higher the last year that a president is in office. (election year)\n- Similarly, you will see higher expenditure in December, because of Christmas.\n- As with trends, this may cause spurious relations, thus, its recommended to control for seasonality adding dummies.\n  - quarter, month, day of the week, year after election, etc.\n\n- As simple as adding dummies for each month, or quarter, etc.\n\n## 4: $R^2$ and Spurious Regressions\n\n- One of the consequences of spurious regressions is that the $R^2$ will be inflated. (caputred by the common trend or seasonality\n- Even if we add trends or seaonalities, the default $R^2$ will be too large. (Because it still describes ALL variation)\n\n- A better approach to understand the true explanatory power of the model is to use an **$R^2$** that adjusts for trends and seasonality.\n\n$$y_t = \\beta_0 + \\beta_1 x_{1t} + \\beta_2 x_{2t} + \\theta \\times t + \\sum \\gamma_k \\times D_k + u_t$$\n\nWhere $D_k$ are dummies for seasonality, and $\\theta \\times t$ is a trend. \n\n## 4: $R^2$ and Spurious Regressions\n\n- To estimate the adjusted $R^2$ it may be better to use de-trended and de-seasonalized data.\n\n$$\\tilde w_t = w_t - E(w_t| t , D_1, D_2, \\dots, D_k) \\forall w \\in {y, x_1, x_2}$$\n\n- Estimate model\n\n$$\\tilde y_t = \\beta_1 \\tilde x_{1t} + \\beta_2 \\tilde x_{2t} + u_t$$\n\n- Calculate the $R^2$ using the \"correct\" $SST$ and $SSE$ using the demeaned data.\n\n$$aR^2 = 1-\\frac{\\sum \\hat u^2_t}{\\sum \\tilde y^2_t}$$\n\n# Thats all for today!\nNext week, Advanced Time series\n\n",
    "supporting": [
      "12_timeseries_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}