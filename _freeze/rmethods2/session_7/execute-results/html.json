{
  "hash": "afe1a8c47361635d3d5f49349e40d241",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Research Methods II\"\nsubtitle: \"Session 7: Micro-Simulations, and Monte Carlo Methods\"\nauthor: Fernando Rios-Avila\nformat: \n  revealjs: \n    slide-number: true\n    width: 1600\n    height: 900\n    code-fold: true\n    echo: true\n    css: styles.css \n    highlight-style: github\nexecute: \n  freeze: auto    \n---\n\n# Simulation Methods in Economics\n\n## What is Monte Carlo Simulation?\n\n- Monte Carlo simulation are a generic name given to methods that use random numbers to simulate a process.\n\n- In econometrics, Monte Carlo methods are used to study the properties of estimators, and to evaluate the performance of statistical tests.\n\n- This can be a useful tool to understand some of the properties of estimators, or even problems related to violations of assumptions.\n\n- It can also be used to evaluate the performance of estimators in finite samples, and to compare different estimators.\n\n## Example: Mean vs Median {.scrollable}\n\n- Which of this estimators is more robust and efficient, when samples are small ?\n- Lets setup a program that would simulate this:\n\n::: {#6597105c .cell .larger execution_count=1}\n``` {.stata .cell-code code-fold=\"false\"}\n// define a program\ncapture program drop mean_vs_median\nprogram define mean_vs_median, eclass\n  syntax, [nobs(int 100)]\n  clear\n  ** Set  # of obs\n  set obs `nobs'\n  ** Generate a random variable\n  gen x = rnormal(0,1)\n  ** Calculate mean and median\n  qui:sum x,d\n  ** Store results\n  matrix b = r(mean), r(p50)\n  ** post results\n  matrix colname b = \"mean\" \"median\"\n  ereturn post b\nend\nmean_vs_median\nereturn display\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<style>div.jp-Notebook .datagrid-container {min-height: 448px; }</style>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nNumber of observations (_N) was 0, now 100.\n------------------------------------------------------------------------------\n             | Coefficient\n-------------+----------------------------------------------------------------\n        mean |  -.1445693\n      median |  -.1970271\n------------------------------------------------------------------------------\n```\n:::\n:::\n\n\nNow that the program is SET, lets run it 1000 times:\n\n::: {#757a097a .cell .larger execution_count=2}\n``` {.stata .cell-code code-fold=\"false\"}\nset seed 101\nsimulate, reps(1000): mean_vs_median, nobs(500)\nsum\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n      Command: mean_vs_median, nobs(500)\n\nSimulations (1,000): .........10.........20.........30.........40.........50...\n> ......60.........70.........80.........90.........100.........110.........120\n> .........130.........140.........150.........160.........170.........180.....\n> ....190.........200.........210.........220.........230.........240.........2\n> 50.........260.........270.........280.........290.........300.........310...\n> ......320.........330.........340.........350.........360.........370........\n> .380.........390.........400.........410.........420.........430.........440.\n> ........450.........460.........470.........480.........490.........500......\n> ...510.........520.........530.........540.........550.........560.........57\n> 0.........580.........590.........600.........610.........620.........630....\n> .....640.........650.........660.........670.........680.........690.........\n> 700.........710.........720.........730.........740.........750.........760..\n> .......770.........780.........790.........800.........810.........820.......\n> ..830.........840.........850.........860.........870.........880.........890\n> .........900.........910.........920.........930.........940.........950.....\n> ....960.........970.........980.........990.........1,000 done\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n     _b_mean |      1,000     .001419     .043875  -.1660358   .1525889\n   _b_median |      1,000    .0000899    .0544004  -.1851489   .1853068\n```\n:::\n:::\n\n\nConclusion, when N=100, and the distribution is normal, the mean is more efficient than the median.\n\n### Change assumptions, from N to t-distribution\n\n::: {#62eebb08 .cell .larger execution_count=3}\n``` {.stata .cell-code code-fold=\"false\"}\n// define a program\ncapture program drop mean_vs_median\nprogram define mean_vs_median, eclass\n  syntax, [nobs(int 100) rt(int 5)]\n  clear\n  set obs `nobs'\n  gen x = rt(`rt')\n  qui:sum x,d\n  matrix b = r(mean), r(p50)\n  matrix colname b = \"mean\" \"median\"\n  ereturn post b\nend\n set seed 101\nsimulate, reps(1000) nodots: mean_vs_median, nobs(500) rt(2)\nsum\nsimulate, reps(1000) nodots: mean_vs_median, nobs(500) rt(4)\nsum\nsimulate, reps(1000) nodots: mean_vs_median, nobs(500) rt(6)\nsum\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n      Command: mean_vs_median, nobs(500) rt(2)\n\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n     _b_mean |      1,000   -.0199475    .2203307  -4.369244   .6070946\n   _b_median |      1,000    .0002406    .0640181  -.1970648   .1889922\n\n      Command: mean_vs_median, nobs(500) rt(4)\n\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n     _b_mean |      1,000    .0007863    .0647392  -.2136446   .2056455\n   _b_median |      1,000    .0024002    .0602134  -.1902502   .2014696\n\n      Command: mean_vs_median, nobs(500) rt(6)\n\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n     _b_mean |      1,000    .0007195    .0531958  -.1984012   .2054568\n   _b_median |      1,000    .0008841    .0580835  -.1863388   .2035508\n```\n:::\n:::\n\n\n## Properties of estimators {.scrollable}\n\n- Monte Carlo methods can also be used to study the properties of estimators.\n- Consider the following example:\n  - We want to study the properties of the OLS estimator when the error term is heteroskedastic.\n\n$$y_i = \\beta_0 + \\beta_1 x_i + u_i*exp(\\gamma x_i)$$\n\n- What are the consequences of heteroskedasticity in the OLS estimator?\n\n- lets set up a simulation to study this.\n\n::: {#fbf00190 .cell .larger execution_count=4}\n``` {.stata .cell-code code-fold=\"false\"}\n// define a program\ncapture program drop ols_hetero\nprogram define ols_hetero, eclass\n  syntax, [nobs(int 100) b0(real 1) b1(real 1) gamma(real 1)]\n  clear\n  set obs `nobs'\n  gen x = rnormal(0,1)\n  gen u = rnormal(0,1)\n  gen y = `b0' + `b1' * x + u*exp(`gamma'*x)\n  // run regression (under homoskedasticity)\n  qui:reg y x\n  // store results\n  matrix b = _b[_cons], _se[_cons], _b[x], _se[x]\n  matrix colname b = \"b0\" \"se0\" \"b1\" \"se1\"\n  ereturn post b\nend\nsimulate, reps(1000) nodots: ols_hetero, nobs(500) b0(1) b1(1) gamma(1)\nsum \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n      Command: ols_hetero, nobs(500) b0(1) b1(1) gamma(1)\n\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       _b_b0 |      1,000    .9979773    .1210228   .6013685   1.434932\n      _b_se0 |      1,000    .1196379    .0220658   .0737395   .2717805\n       _b_b1 |      1,000    .9864205    .2661498   .0342865     1.8922\n      _b_se1 |      1,000    .1195836    .0210792   .0808713   .2756631\n```\n:::\n:::\n\n\n### Correcting for heteroskedasticity\n\nWe can correct for heteroskedasticity using robust standard errors.\n\n::: {#f78e4b99 .cell .larger execution_count=5}\n``` {.stata .cell-code code-fold=\"false\"}\n// define a program\ncapture program drop ols_hetero\nprogram define ols_hetero, eclass\n  syntax, [nobs(int 100) b0(real 1) b1(real 1) gamma(real 1)]\n  clear\n  set obs `nobs'\n  gen x = rnormal(0,1)\n  gen u = rnormal(0,1)\n  gen y = `b0' + `b1' * x + u*exp(`gamma'*x)\n  // run regression (under homoskedasticity)\n  qui:reg y x, robust\n  // store results\n  matrix b = _b[_cons], _se[_cons], _b[x], _se[x]\n  matrix colname b = \"b0\" \"se0\" \"b1\" \"se1\"\n  ereturn post b\nend\nsimulate, reps(1000) nodots: ols_hetero, nobs(500) b0(1) b1(1) gamma(1)\nsum \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n      Command: ols_hetero, nobs(500) b0(1) b1(1) gamma(1)\n\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       _b_b0 |      1,000     1.00342    .1180407   .6255065     1.3921\n      _b_se0 |      1,000    .1171892    .0219696   .0807092   .3564852\n       _b_b1 |      1,000     1.00355    .2589393  -.2493259   1.956252\n      _b_se1 |      1,000    .2407364    .0913925   .1092693   1.174903\n```\n:::\n:::\n\n\nor using weighted least squares.\n\n::: {#e5966504 .cell .larger execution_count=6}\n``` {.stata .cell-code code-fold=\"false\"}\n// define a program\ncapture program drop ols_hetero\nprogram define ols_hetero, eclass\n  syntax, [nobs(int 100) b0(real 1) b1(real 1) gamma(real 1)]\n  clear\n  set obs `nobs'\n  gen x = rnormal(0,1)\n  gen u = rnormal(0,1)\n  gen y = `b0' + `b1' * x + u*exp(`gamma'*x)\n  // run regression (under homoskedasticity)\n  qui:reg y x, \n  predict uhat, resid\n  gen lnuhat2 = ln(uhat^2)\n  reg lnuhat2 x\n  predict lnhx\n  gen hx=exp(lnhx)\n  // store results\n  qui:reg y x [w=1/hx], \n  matrix b = _b[_cons], _se[_cons], _b[x], _se[x]\n  matrix colname b = \"b0\" \"se0\" \"b1\" \"se1\"\n  ereturn post b\nend\nsimulate, reps(1000) nodots: ols_hetero, nobs(500) b0(1) b1(1) gamma(1)\nsum \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n      Command: ols_hetero, nobs(500) b0(1) b1(1) gamma(1)\n\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n       _b_b0 |      1,000    1.001033    .0465683   .8545606   1.252005\n      _b_se0 |      1,000    .0478398    .0084316   .0288236   .1462429\n       _b_b1 |      1,000    1.001063    .0277128   .8875045   1.301835\n      _b_se1 |      1,000    .0270911    .0091106   .0088032   .1357872\n```\n:::\n:::\n\n\n## More on Monte Carlo Simulations {.scrollable}\n\n- You can use Monte Carlo simulations to study the properties of new estimators as well. (most often)\n- The structure of the simulation, however, will depend on the estimator you want to study, and may not be fully generalizable.\n\n  - Notice that in the previous example, we assumed that all data needed to be simulated.\n  -  But, we could just as well simulate only \"parts\" of the data, and use observed data for the rest.\n\n::: {#95784d6b .cell .larger execution_count=7}\n``` {.stata .cell-code code-fold=\"false\"}\nfrause oaxaca, clear\nprobit lfp female educ age agesq married divorced\npredict lfp_xb, xb\nmatrix b=e(b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Excerpt from the Swiss Labor Market Survey 1998)\n\nIteration 0:  Log likelihood = -634.26553  \nIteration 1:  Log likelihood = -453.80541  \nIteration 2:  Log likelihood = -429.25759  \nIteration 3:  Log likelihood = -428.40991  \nIteration 4:  Log likelihood = -428.40986  \nIteration 5:  Log likelihood = -428.40986  \n\nProbit regression                                       Number of obs =  1,647\n                                                        LR chi2(6)    = 411.71\n                                                        Prob > chi2   = 0.0000\nLog likelihood = -428.40986                             Pseudo R2     = 0.3246\n\n------------------------------------------------------------------------------\n         lfp | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n      female |  -1.644408   .1498206   -10.98   0.000    -1.938051   -1.350765\n        educ |   .1051167   .0251728     4.18   0.000     .0557789    .1544544\n         age |   .1045008   .0385916     2.71   0.007     .0288627    .1801389\n       agesq |  -.0012596   .0004463    -2.82   0.005    -.0021344   -.0003848\n     married |  -1.692076   .1887409    -8.97   0.000    -2.062001    -1.32215\n    divorced |    -.68518   .2319883    -2.95   0.003    -1.139869   -.2304912\n       _cons |   .4413072   .7648821     0.58   0.564    -1.057834    1.940448\n------------------------------------------------------------------------------\n```\n:::\n:::\n\n\n::: {#16317a3c .cell .larger execution_count=8}\n``` {.stata .cell-code code-fold=\"false\"}\n* Latent model LFP =1(lfp_xb + e>0)\ncapture program drop probit_sim\nprogram  probit_sim, eclass\n  capture drop lfp_hat\n  gen lfp_hat=(lfp_xb + rnormal(0,1))>0\n  probit lfp_hat female educ age agesq married divorced, from(b, copy)\nend\nsimulate _b _se, reps(500) nodots: probit_sim\nren lfp_hat* *\nsum ,sep(7)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\n      Command: probit_sim\n\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n   _b_female |        500    -1.67208    .1594671  -2.262682  -1.280128\n     _b_educ |        500     .108218    .0251913   .0453378   .1974491\n      _b_age |        500    .1022977     .038849   -.004108   .2443264\n    _b_agesq |        500   -.0012359    .0004483  -.0029406  -.0000835\n  _b_married |        500   -1.720405    .1903062  -2.425838  -1.247641\n _b_divorced |        500   -.7046396    .2310935  -1.387282   .1018858\n     _b_cons |        500    .5167748    .7899037  -1.920398   2.650355\n-------------+---------------------------------------------------------\n  _se_female |        500    .1548574    .0187049   .1234346   .2547092\n    _se_educ |        500    .0255194    .0012991   .0223761    .029805\n     _se_age |        500    .0389973    .0017384   .0336116   .0466778\n   _se_agesq |        500    .0004507    .0000184   .0003941   .0005336\n _se_married |        500    .1987176    .0234131   .1538517   .3142596\n_se_divorced |        500    .2410041    .0207673    .199707   .3420741\n    _se_cons |        500    .7709869    .0397739   .6426999   .9831291\n```\n:::\n:::\n\n\n- To some extent, this is similar to the imputation methods we have seen before.\n- More complex versions of this can be used to elaborate micro-simulations.\n\n## What are micro-simulations?\n\n- Micro-simulation is a **technique** that is used to make micro units act and interact in a way that it is possible to aggregate to the level of interest.\n\n- A micro simulation model can be seen as a set of rules, which operates on a sample of micro units (individuals, households, firms, etc.) to produce a set of outcomes.\n\n- The goal is to produce synthetic datasets that can be used to estimate the effects of policy changes. \n\n- Because micro-simulations are based on micro-data, they have the potential to capture the heterogeneity of the population. (decisions, preferences, etc.)\n\n## \n\n- We can also think about micro-simulations as a way to **simulate/predict/impute**  the behavior of a population of interest.\n  - Thus a lot of what you learned in terms of Modeling, imputations, and matching can be applied here.\n\n### So what do we need?\n\n- We need a **population** of micro units (individuals, households, firms, etc.) that is representative of the population of interest. (survey data)\n  \n- Details on a policy change that we want to simulate. (policy parameters)\n\n- A set of rules that describe how the micro units interact with each other and with the policy change. (model for behavior)\n- An outcome of interest that we want to study. (outcome variable)\n\n## How do we do it?\n\n- Depending on the type of analysis we want to do, the structure of a micro-simulation can be very simple or very complex.\n\n- Consider the following example:\n\n  - We want to study the effect of a policy that aims to increase the minimum wage in the labor market. What effects would this have?\n    - Higher wages ? \n    - increase/decrease in employment?  \n    - Changes in the distribution of wages?\n    - Changes in the Economic structure?\n- More complex models require more sophisticated interactions between the micro/and macro units and the policy change.\n\n- However, simpler models can be useful at least to study first order/statistical effects of a policy change.\n\n## Example: The case of higher education\n\n- Consider the following. The government wants to increase educational attainment in the population.\n\n- To do so, they want to evaluate the impact that a 2 additional years for people with less than 12 years of education would have on the population.\n\n- How do we do this?\n\n- For simplicilty , lets use the `oaxaca` dataset\n\n## {.scrollable}\n\nWe can start by modeling the effect of education on wages.\n\n$$log(wage)= \\beta X + \\beta_e educ + u$$\n\n::: {#0c046c0e .cell .larger execution_count=9}\n``` {.stata .cell-code code-fold=\"false\"}\nfrause oaxaca, clear\nreg lnwage educ exper tenure female age, \npredict  res, res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Excerpt from the Swiss Labor Market Survey 1998)\n\n      Source |       SS           df       MS      Number of obs   =     1,434\n-------------+----------------------------------   F(5, 1428)      =    101.03\n       Model |   105.60186         5   21.120372   Prob > F        =    0.0000\n    Residual |  298.517944     1,428  .209046179   R-squared       =    0.2613\n-------------+----------------------------------   Adj R-squared   =    0.2587\n       Total |  404.119804     1,433  .282009633   Root MSE        =    .45722\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        educ |   .0743986   .0052612    14.14   0.000     .0640782    .0847191\n       exper |   .0022628   .0018958     1.19   0.233    -.0014562    .0059817\n      tenure |   .0021805   .0019783     1.10   0.271    -.0017001    .0060611\n      female |  -.1321951   .0254327    -5.20   0.000    -.1820846   -.0823056\n         age |   .0136344   .0017751     7.68   0.000     .0101523    .0171165\n       _cons |   1.985785   .0732567    27.11   0.000     1.842083    2.129488\n------------------------------------------------------------------------------\n(213 missing values generated)\n```\n:::\n:::\n\n\nID the policy change\n\n::: {#c7e442e2 .cell .larger execution_count=10}\n``` {.stata .cell-code code-fold=\"false\"}\nclonevar educ2=educ\nreplace educ=educ+2 if educ<12\npredict yhat2, xb\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(1,099 real changes made)\n(213 missing values generated)\n```\n:::\n:::\n\n\nSo what is the effect on wages? (if there is no selection bias)\n\n::: {#74eda541 .cell .larger execution_count=11}\n``` {.stata .cell-code code-fold=\"false\"}\ngen wage = exp(lnwage)\ngen wage2 = exp(yhat2+res)\ngen wage_diff = wage2-wage\ntabstat wage_diff\nreplace educ = educ2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(213 missing values generated)\n(213 missing values generated)\n(213 missing values generated)\n\n    Variable |      Mean\n-------------+----------\n   wage_diff |  2.947924\n------------------------\n(1,099 real changes made)\n```\n:::\n:::\n\n\nWage has increased in 2.95.\n\nBut is this the only effect??\n\n## {.scrollable}\n\n- What about the effect on employment? \n\n- This is a more complex model, and we need further assumptions\n  - Assume anyone who wants to work, will find a job.\n  - Those employed remain employed\n  - Those non-employed will transition to employment marginally\n\n$$P(lfp=1|X,educ)= \\beta X + \\beta_e educ + u\n$$\n\nFirst model the probability of employment\n\n::: {#4bef62aa .cell .larger execution_count=12}\n``` {.stata .cell-code code-fold=\"false\"}\nfrause oaxaca, clear\nqui:probit lfp educ female age single married kids6 kids714\npredict lfp_xb, xb\npredict pr_org, pr\n\nreplace lfp_xb = lfp_xb + _b[educ] * 2 if educ<12\ngen plfp = normal(lfp_xb)\n\n** Before and after the policy change\nsum plfp pr_org \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Excerpt from the Swiss Labor Market Survey 1998)\n(1,099 real changes made)\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n        plfp |      1,647    .8995986    .1614962   .0777393   .9999999\n      pr_org |      1,647    .8707874    .1925782   .0604887   .9999999\n```\n:::\n:::\n\n\nSo now we have the original probability of employment and the probability of employment after the policy change.\n\nHow do we know who will transition from not working to working?\n\n- Option 1. Assign new workers based on the relative change in the probability of employment.\n\n::: {#e9b4161b .cell .larger execution_count=13}\n``` {.stata .cell-code code-fold=\"false\"}\ngen dprob = (plfp-pr_org)/pr_org\nclonevar lfp_post1 = lfp\nreplace lfp_post1 =1 if lfp==0 & dprob>runiform()\nsum  lfp_post1 lfp\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(35 real changes made)\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n   lfp_post1 |      1,647    .8919247    .3105698          0          1\n         lfp |      1,647     .870674    .3356624          0          1\n```\n:::\n:::\n\n\n- Option 2. Simulate employment status based on the original and post-policy probability of employment.\n\n::: {#111d1527 .cell .larger execution_count=14}\n``` {.stata .cell-code code-fold=\"false\"}\n** Option 2\ndrop2 unf lfp_org lfp_post\ngen unf = runiform()\ngen lfp_org  = pr_org>unf\ngen lfp_post = plfp  >unf\n\nsum lfp_post  lfp_org\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nvariable unf not found\nvariable lfp_org not found\nvariable lfp_post not found\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n    lfp_post |      1,647    .9046752    .2937523          0          1\n     lfp_org |      1,647    .8737098    .3322771          0          1\n```\n:::\n:::\n\n\n- Both options are valid, but\n  - First one requires to impute wages for the new workers only.\n  - Second one requires to impute wages for the entire population.\n\n## {.scrollable}\n\n### Imputing wages: \n\n  - We could assume no selection bias.\n  - We may need to use only data available for everyone, or use imputed data (exper tenure) (perhaps at 0?)\n\n::: {#53e4ffec .cell .larger execution_count=15}\n``` {.stata .cell-code code-fold=\"false\"}\nreg lnwage educ female age single married kids6 kids714, \npredict  res, res\npredict lnwage_hat, xb\n** Simulating Known wages component\nreplace lnwage_hat = lnwage_hat + _b[educ] * 2 if educ<12\n** Simulating random component\n** For those already working:\nreplace lnwage_hat = lnwage_hat + res if lfp==1\n** Simulate unobserved\nqui: sum res, \nreplace lnwage_hat = lnwage_hat + rnormal(0,r(sd)) if lfp_post1==1 & lfp==0\n\ngen wage_post = exp(lnwage_hat) if lfp_post1==1 | lfp==1\ngen wage = exp(lnwage)\nsum wage wage_post\nsgini wage wage_post\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n      Source |       SS           df       MS      Number of obs   =     1,434\n-------------+----------------------------------   F(7, 1426)      =     79.23\n       Model |  113.158257         7  16.1654653   Prob > F        =    0.0000\n    Residual |  290.961547     1,426  .204040355   R-squared       =    0.2800\n-------------+----------------------------------   Adj R-squared   =    0.2765\n       Total |  404.119804     1,433  .282009633   Root MSE        =    .45171\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        educ |   .0709179   .0050262    14.11   0.000     .0610584    .0807774\n      female |  -.1427501   .0244736    -5.83   0.000    -.1907583   -.0947419\n         age |    .016475   .0014033    11.74   0.000     .0137222    .0192277\n      single |  -.0711724   .0443651    -1.60   0.109    -.1582002    .0158554\n     married |  -.0977016   .0379654    -2.57   0.010    -.1721755   -.0232276\n       kids6 |   .1085073   .0239699     4.53   0.000     .0614873    .1555272\n     kids714 |   .0656187    .019681     3.33   0.001      .027012    .1042254\n       _cons |   1.999222   .0902563    22.15   0.000     1.822173    2.176272\n------------------------------------------------------------------------------\n(213 missing values generated)\n(1,099 real changes made)\n(1,434 real changes made)\n(35 real changes made)\n(178 missing values generated)\n(213 missing values generated)\n\n    Variable |        Obs        Mean    Std. dev.       Min        Max\n-------------+---------------------------------------------------------\n        wage |      1,434    32.39167    16.12498   1.661434   192.3077\n   wage_post |      1,469    35.19396    16.94609   1.873127   221.6129\n\nGini coefficient for wage, wage_post\n\n-----------------------\n    Variable |      v=2\n-------------+---------\n        wage |   0.2460\n   wage_post |   0.2356\n-----------------------\n```\n:::\n:::\n\n\nThis is equivalent to running a single imputation round. However, we could repeat the process M times to get a measure for the precission of our estimates.\n\n### What else can we do?\n\n- We could go further and also simulate where would people work, and how would the economy change.\n- We could also account for selection problems\n- or make a more explicit model for distributional analysis.\n\n## 1st Micro-simulation\n### a Review\n\n- We have just use a simple micro-simulation to study the effect of a policy change (education) on wages and employment.\n\n- This simulation had many assumptions, and we could have done it in many different ways.\n\n- Among others, we assume no selection bias, with an instantaneous change in education, and no again of the population. \n\n- We also made important assumptions regarding the transition from non-employment to employment, and the imputation of wages.\n\n## Not the only way to do it\n\n- While many micro-simulations are based on stochastic simultions, there are other ways to do it.\n- In Hotckiss et al. (forthcoming), we use a deterministic micro-simulation to study the effect of tax-reforms on welfare changes and its distribution for the - first\n\n- How did we do it?\n\n## Tax Reform on Households Welfare\n\n  - We concentrated mostly on couple households with young children (0-18 years old). \n  - Using a heckman selection model, we impute wages for the non-working people (based on PMM).\n  - Using observed and imputed wages, we impute the tax liability for each household before and after the reform. (TAX-SIM), and estimate after-tax wages.\n  - Estimate Household Labor Supply based on HH utility and Non-linear Tobit model \n  - Use HLS models, we make predictions for Labor Supply changes and utility changes given the Reform.\n    - The Outcome was how much better/worse off would households be after the reform.\n\n# Levy Institute Microsimulation Model (LIMM)\n\n## Intro\n\n- At Levy, we have also constructed a micro-simulation model to study employment simulations.\n- Method first developed for estimating the impact of the American Recovery and Reinvestment Act of 2009\n  - Convert spending into jobs by industry and occupation (I/O matrix)\n  - Assign potential workers to jobs\n  - Predict earnings and hours\n- For the work with LIMEW and LIMTIP, this has also been used for distributional analysis of employment assigment and services use.\n\n## LIMM: Step I \n\n### Job Creation\n\n- Consider a policy: Road construction, Services provision, etc.\n  - Calculate changes in final demand for each industry the policy creates\n  - Using I-O tables estimate change in total output for each industry\n  - Use that change in output to estimate change demand for labor inputs\n    - Transform the changes from labor imputs to generated jobs (consider wages)\n  - Distribute changes across occupations (within industry)\n    - Using, for example, shares of employment by occupation within industry\n     \n- With this we have a total number of jobs created by industry and occupation.\n\n## LIMM: Step II\n\n### Job Assigment\n\n- Given the Total change in Jobs, we need to assign workers to those jobs.\n  - Who are the potential workers?\n    - Not in LF: Potential, but not looking for work (may depend on characteristics). Avoid retired, disabled and students\n    - Unemployed: Most likely to take a job (pool may not be large enough) \n    - Underemployed: Working part-time, but willing to work full-time, or people aiming for better jobs. (May create job openings)\n    - and Employed: May be willing to change jobs (may create job openings)\n\n##\n### Job Assigment II\n\n- Two Steps, modeling job creation and job assigment\n \n- A probit/logit model would be estimated to predict the likelihood of working, and this will be used to assign jobs.\n\n  - Job assignment is done using a multinomial model (`mprobit`) to predict likelihoods of working on a given occupation & industry. \n \n  - Ideally, you would like to do both at the same time, but that is a very complex model to estimate. Instead, each one is estimated separately.\n\n$$\\begin{aligned}\nI^*(ind = 1 ) &= \\beta_1 X + e_1 \\\\\nI^*(ind = 2 ) &= \\beta_2 X + e_2 \\\\\n&\\vdots \\\\\nI^*(ind = k ) &= \\beta_k X + e_k \n\\end{aligned}\n$$\n\nWhere $I^*(ind = k )$ is the latent likelihood of working on industry $k$ given characteristics. Mprobit or Mlogit depends on the distribution of $e_k$.\n\nYou choose Industry $k$ if $I^*(ind = k )$ is the highest among all industries.\n\n##\n### Job Assigment III\n\n- Job Assigment is done as follows:\n\n  - For each potential worker, Calculate Prob of working. Those with the highest probability are assigned jobs first.\n   \n  - For Worker, $i$, the individual is assigned to the industry with the highest likelihood of working. (until all jobs are assigned)\n    - Can be done followed by doing similar assigment for occupation within industry.\n    - Or combine both industry and occupation (p_o * p_i)\n  \n::: {.callout-note}\n  - Job allocation must consider jobs available and likehood of working on a given Occupation/Industry. \n  - May want to avoid deterministic assignment.\n  - could assigned based on random draws from the distribution of likelihoods.\n:::\n  \n##\n### Earning contributions\n\n- Because some of the newly created jobs go to people who are employed in Family businesses (Farm and non farm income), one has to account for the \"loss\" of income from those jobs. \n \n- This is done by estimating the contribution of each member to the family business, and imputing the loss of income from the now \"formally employed\" member.\n  - For example, modeling farm income, predicting that income without the family member, and imputing the difference as the loss of income.\n\n##\n### Job Assigment IV: Wages and Hours\n\n- Hours and Wages are imputed using a heckman model, and multiple stage process\n\n1. Use a probit model to predict the likelihood of working.\n2. Given the model obtain the inverse mills ratios. $imr = \\phi(\\alpha'x)/\\Phi(\\alpha'x)$\n3. Model wages and hours using IMR as a regressor. (Heckit model) (This includes info on imputed occupations/industry)\n4. Use Imputed wages and hours to Match data to \"donor\" individuals. (PMM)\n5. For people \"potentially\" leaving family business, compare new wages to family business contributions\n\n##\n### Hours of HP re-assigment\n\n- People taking jobs may have to change their contributions to household production. (less time for HP)\n- But the rest of the family may also have to adjust their contributions to HP. (more time for HP?)\n  - This is done via matching, where the \"donor\" are working individuals with similar family characteristics.\n  - Or All working individuals \n  - Currently, \"recipients\" are all individuals in the household, with atleast one new worker.\n    - May be more sensible to impute hours\n    - One may argue those not working may have to increase hours of HP. Or do nothing\n\n### Other considerations\n\n- Assigment of Child Care services\n\n## Assessing the quality of the simulation\n\n- In principle, there is no way to know if the simulation is correct.\n  - There is no \"true\" value to compare to.\n  - However, one may want to at least ensure the simulation replicates the data.\n  - One can potetially use the simulation to predict changes of a past policy, and compare to the actual changes.\n- We do want to make \"sanity\" checks \n  - Are results consistent and plausible?\n  - Are distributions of post-assigment outcomes consistent with the data?\n\n## Limitations\n\n- Since we use existing data, we make the implicit assumption \"no behavioral changes\" in other aspects\n  - Things change as far as we can model them.\n- Results are typically point estimates, and do not account for uncertainty.\n  - We can use multiple imputation, monte carlo simulations, or bootstrapping to account for uncertainty.\n- The results are only as good as the data we use and the assumptions we make.\n  - We can use sensitivity analysis to test the robustness of the results to changes in assumptions.\n\n# Thats All Folks!\n\n",
    "supporting": [
      "session_7_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}