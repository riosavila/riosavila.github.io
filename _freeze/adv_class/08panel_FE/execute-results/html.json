{
  "hash": "ba4d045c429bd1ce1d009bd42dc8691a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Panel data and Fixed Effects (Many FE)\"\nsubtitle: \"Are we seeing double?\"\nauthor: Fernando Rios-Avila\nformat:\n  revealjs: \n    slide-number: true\n    width: 1500\n    height: 900\n    code-fold: true\n    echo: true\n    css: styles.css  \n    theme: serif\n  pdf: default \nexecute:\n  freeze: true   \n---\n\n## Re-Cap: Potential outcome Model {.scrollable}\n\nIn the ideal world, where we can see all possible outcomes and scenarios of your potential treatments, it will be very simple to estimate treatment effects:\n\n$$\n\\delta_i = Y_i(1)-Y_i(0)\n$$\n\nWhy does this work??\n\nOne way to understand this it to imagine that potential outcomes are a function of all observed and unobserved individual characteristics, plust the treatment Status. \n\n$$y_i(D)=y_i(X,u,D) \n$$\n\nSo when comparing a person with himself (clones or parallel worlds), we know (or at least expect) that everything else is the same, except for the Treatment Status. \n\nDifferences between the two states are explained only by the treatment!\n\n## The Problem and first Solution RCT  \n\nWe do not observe both States at the same time. People will either be treated or untreated, not both.\n\nSo what can we do?\n\n> **We need to find good counterfactuals!**\n\nOne way to do so is via RCT, for example using a lottery!\n\n> Why does it work? \n\nPotential outcomes will be unrelated to treatment, because treatmet is assigned at random.\n\nHere, it also means that $X's$ and $u's$ will be similar across groups (because of random assigment)\n\nBut...you cannot estimatate individual effects, but at least estimate aggregate effects (ATE = ATT = ATU)\n\n## Other Solutions?  \n\nSo RCTs can be very expensive, and difficult to implement after the fact. In those situations, however, you can use observed data to try answering the same questions!.\n\nOne option? Something we have done before...Regression Analysis!\n\n$$y_i = a_0 + \\delta D_i + X_i\\beta + e_i$$\n\nThe idea is that you directly control for all confounding factors that could be related to $y_i$ and $d_i$.\n\nIn other words, you add controls until $D_i$ is exogenous! $E(e_i|D)=0$\n\n## Implications to the PO model?  \n\n- Assumes all individuals have the same outcome structure ($\\beta s$), except for the TE\n\n- The treatment is effect is homogenous (no heterogeneity) \n\n- and that functional form is correct (for extrapolation)\n\nHowever, explicitly controlling for covariates, balances characteristics (FWL):\n\n$$ \n\\begin{aligned}\nD_i &= X\\gamma + v_i \\\\\ny_i &= a_0 + \\delta v_i + u_i \\\\\n\\delta &=\\frac{1}{N} \\sum \\frac{D_i - X\\gamma}{var(v_i)} y_i\n\\end{aligned}\n$$\n\n- Treated units will get positive weights, and controls negative weights, with exceptions because of the LPM.\n\n- Weights will \"balance Samples\" to estimate ATE.\n\n## Controlling for Unobservables\n\n![](resources/fefig.jpg)\n\n## What if you can See X's\n\nSome times, you may have situations where some covariates cannot be observed (Z_i):\n$$\ny_i = \\delta D_i +X_i \\beta + Z_i \\gamma + e_i\n$$\n\nIf $Z_i$ is unrelated to $D_i$, you are on the clear. If its unrelated to $Y_i$ you are also ok. But what if that doesn happen? \n\n> Then you have a problem!\n\nYou no longer can use regression, because the potential outcomes will no longer be independent of the treatment.\n\nyou are dooomed!\n\n(when would this happen)\n\n## Having access to More Data  \n\nSolution?: Say you have access to panel data: Same individuals across time:\n\n$$\ny_{it} = \\delta D_{it} +X_{it} \\beta + Z_{it} \\gamma + e_{it}\n$$\n\nIf we can't measure $Z_{it}$, and you estimate this using Pool OLS (just simple OLS), you still need the assumption that:\n\n$$E(Z_{it}\\gamma + e_{it}|D_it)=0\n$$\n\nBut that doesnt solve the problem if $Z_{it}$ is related to $D_it$. \n\nOne option, in cases like this, is assuming that individual unobservables are **fixed** across time:\n\n$$\ny_{it} = \\delta D_{it} +X_{it} \\beta + Z_{i} \\gamma + e_{it}\n$$\n\nin which case, it may be possible to estimate Treatment effects\n\n## Fixed Effects \n\nWith panel data and assuming unobservables are fixed across time, estimating TE is \"Easy\". Just add Dummies for each individual!\n\n$$\ny_{it}= \\delta D_{it} +X_{it} \\beta + \\sum d_i \\gamma_i + e_{it}\n$$\n\nHere $d_i \\gamma_i$ is our proxy for **ALL** unobserved factors. OLS can be used to estimate ATEs\n\nThis happens because we can estimate potential outcome under the same assumptions as before. \n\nyou could, in fact, consider adding fixed effects for all dimensions you consider important to account for:\n\n> City, school, region, age, industry, etc\n\nThe only limitation...how many dummies can your computer handle? What happens internally?\n\n## Fixed Effects: Estimation - The variation within  \nThe obvious approach is using dummies. But that can take you only so far (why?), and may create other problems! (excluded variables)\n\nThe alternative is using the within estimator. Say we take the means across individuals, and use that to substract information from the original regression:\n\n$$\n\\begin{aligned}\ny_{it} &= \\delta D_{it} +X_{it} \\beta + Z_{i} \\gamma + e_{it} \\\\\n\\bar y_i &= \\delta \\bar D_i + \\bar X_i \\beta +  Z_{i} \\gamma + \\bar e_i \\\\\ny_{it}-\\bar y_i = \\tilde y_{it} &=\\delta \\tilde D_{it} + \\tilde X_{it}\\beta+\\tilde e_{it} \n\\end{aligned}\n$$\n\nLast equation is easier to estimate (no dummies!) however you need within variation. IF unobserved factors are fixed, they will be \"absorbed\".\n\nAlso, the SE will have to be adjusted for degrees of freedom. (but nothing else)\n\nThis is nothing else but the use of FWL and regression on residuals.\n\n## Dont Forget Random Effects\n\nThis approach is more efficient than Fixed effects because you don't estimate fixed effects, just the distribution.\n\nSo how does this affect the estimation:\n\n1. Errors have two components. One time fixed $e_i$, and one time variant $u_{it}$. Then total errors will be correlated with themselves across time\n$$corr(v_{it}, v_{is}) =  corr(e_i+u_{it}, e_i+u_{is}) = \\sigma^2_e\n$$\n2. Apply FGLS to eliminating this source of auto-correlation!\n$$y_{it}-\\lambda \\bar y_i = (X_{it}-\\lambda \\bar X_it) + v_{it}$$\n\nBut, you need the assumption that unobservables $e_i$ are unrelated to $X's$. (because we are not directly controlling for them). \n\nThe advantage, however, is that you do no need within variation!\n\n## FE vs RE\n\nSo there are two ways to Analyze data Panel data.\n\n- FE: Uses only within variation, is more consistent, but less efficient (too many dummies)\n- RE: Uses all variation in data, is less consistent (stronger assumptions), but more efficient!\n\n**How to choose?**\n\nThe Standard approach is to apply a Hausan Test:\n\n> H0:$\\beta^{FE} = \\beta^{RE}$ using Chi2\n\nIf they are not different (H0 cannot be rejected), then choose RE (efficient). If they are different then choose FE (consistent)\n\n## More Fixed effects: TWFE - NWFE? \n\nWith multiple sets of fixed effects (individual, time, cohort, region, etc), you can still use dummies to add them to the model.\n\nBut, you can apply something similar to the previous approach:\n\n$$\n\\begin{aligned}\ny_{it} &= \\delta D_{it}+x_{it}\\beta + \\gamma_i + \\gamma_t + e_{it} \\\\\n\\bar y_i &= \\bar D_i +\\bar x_{i}\\beta + \\gamma_i + E(\\gamma_t|i) + \\bar e_i \\\\\n\\bar y_t &= \\bar D_t +\\bar x_{t}\\beta + E(\\gamma_i|t) + \\gamma_t + \\bar e_t \\\\\n\\bar y &= \\bar D +\\bar x\\beta + E(\\gamma_i) + E(\\gamma_t)+ \\bar e \\\\\n\\tilde y_{it} &= y_{it}-\\bar y_i - \\bar y_t + \\bar y\n\\end{aligned}\n$$\n\nSo one can estimate the following:\n\n$$\n\\tilde y_{it} = \\delta \\tilde D_{it} + \\tilde X_{it} \\beta + \\tilde e_{it}\n$$\n\nThis eliminates FE for both time and individual (if panel is balanced)\n\n## Second Option:\n\nAlternatively, you can just run regressions of residuals:\n\n$$\nw_{it} = \\gamma^w_i+\\gamma^w_t+rw_{it}\n$$\n\nand make regressions using the residuals. (Demeaning also works, but its an iterative process)\n\n## Stata Example{.scrollable}\n\n::: {#c67f1b16 .cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<style>div.jp-Notebook .datagrid-container {min-height: 448px; }</style>\n```\n:::\n:::\n\n\n::: {#dc4df10a .cell execution_count=2}\n``` {.stata .cell-code}\n#delimit;\nfrause school93_98, clear;\nxtset schid year;\nqui:reg math4 lunch lenrol lrexpp                     ; est sto m1;\nqui:xtreg math4 lunch lenrol lrexpp                   ; est sto m2;\nqui:xtreg math4 lunch lenrol lrexpp, fe               ; est sto m3;\nqui:reghdfe math4 lunch lenrol lrexpp, abs(schid)     ; est sto m4;\nqui:reghdfe math4 lunch lenrol lrexpp, abs(schid year); est sto m5;\nesttab m1 m2 m3 m4 m5, mtitle(ols re fe refe1 refe2) compress se b(3);\nhausman m3 m2;\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nPanel variable: schid (strongly balanced)\n Time variable: year, 1993 to 1998\n         Delta: 1 unit\n\n---------------------------------------------------------------------------\n                 (1)          (2)          (3)          (4)          (5)   \n                 ols           re           fe        refe1        refe2   \n---------------------------------------------------------------------------\nlunch         -0.413***    -0.370***     0.057        0.057       -0.062*  \n             (0.007)      (0.011)      (0.031)      (0.031)      (0.026)   \n\nlenrol        -0.121        0.936        8.766***     8.766***     0.297   \n             (0.425)      (0.616)      (1.704)      (1.704)      (1.468)   \n\nlrexpp        28.887***    39.161***    46.450***    46.450***     2.799*  \n             (0.860)      (0.878)      (1.006)      (1.006)      (1.265)   \n\n_cons       -162.292***  -254.864***  -377.338***  -377.423***    37.398*  \n             (7.960)      (8.681)     (14.913)     (14.918)     (15.847)   \n---------------------------------------------------------------------------\nN               9369         9369         9369         9328         9328   \n---------------------------------------------------------------------------\nStandard errors in parentheses\n* p<0.05, ** p<0.01, *** p<0.001\n\n                 ---- Coefficients ----\n             |      (b)          (B)            (b-B)     sqrt(diag(V_b-V_B))\n             |       m3           m2         Difference       Std. err.\n-------------+----------------------------------------------------------------\n       lunch |     .056932    -.3703211        .4272531        .0287753\n      lenrol |    8.766051     .9357725        7.830279        1.588902\n      lrexpp |    46.44966     39.16107        7.288595        .4915896\n------------------------------------------------------------------------------\n                          b = Consistent under H0 and Ha; obtained from xtreg.\n           B = Inconsistent under Ha, efficient under H0; obtained from xtreg.\n\nTest of H0: Difference in coefficients not systematic\n\n    chi2(3) = (b-B)'[(V_b-V_B)^(-1)](b-B)\n            = 627.26\nProb > chi2 = 0.0000\n```\n:::\n:::\n\n\n## Correlated Random Effects\n\nRandom effects model may produce inconsistent results, because it assumes unobserved factors are uncorrelated to characteristics. \n\nFixed effects controls for individual effects explicitly, or via demeaning.\n\nA 3rd approach is known as CRE model. A more explicit modeling of the unobserved but fixed components.\n\n1. Call the unobserved component $a_i$, and say we suspect it may be related with individual characteristics. \n2. Because $a_i$ is constant over time, it may be reasonable assuming its correlated with individual average characteristics:\n   $$a_i = a + \\bar X_i \\gamma + r_i\n   $${#eq-m1}\n\nBy construction, $r_i$ and $X_{it} \\&  \\bar X_i$ will be uncorrelated. So lets just add that to the main model\n\n## CRE\n\nLets add @eq-m1 to our main equation.\n$$\ny_i = \\beta X_{it} +  \\theta Z_{i} + \\bar X_i \\gamma + r_i + e_{it}\n$$\n\nThis equation can now be estimated using RE, because it already allows controls for the correlation of unobserved factors and the individual effects.\n\nYou can also estimate the model using *pool* OLS, clustering errors at individual level. \n\n**Result**: \n\n- you now have a model that allows for time variant and time fixed components, that is consistent as FE (same coefficients).\n\n**Uses**: \n\n- Simpler way to test for FE vs RE (are the $\\gamma 's$ significant?)\n- there is no need for within variation for any variable! (just overall variation)\n\n## cre in Stata {.scrollable}\n\n::: {#b2c27e66 .cell execution_count=3}\n``` {.stata .cell-code}\n#delimit cr\nfrause school93_98, clear\nreghdfe math4 lunch lenrol lrexpp, abs(schid year) cluster(schid)\n** Experimental\ncre, abs(schid year): reg math4 lunch lenrol lrexpp, cluster(schid)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(dropped 41 singleton observations)\n(MWFE estimator converged in 5 iterations)\n\nHDFE Linear regression                            Number of obs   =      9,328\nAbsorbing 2 HDFE groups                           F(   3,   1734) =       2.59\nStatistics robust to heteroskedasticity           Prob > F        =     0.0515\n                                                  R-squared       =     0.7548\n                                                  Adj R-squared   =     0.6985\n                                                  Within R-sq.    =     0.0014\nNumber of clusters (schid)   =      1,735         Root MSE        =    11.5747\n\n                              (Std. err. adjusted for 1,735 clusters in schid)\n------------------------------------------------------------------------------\n             |               Robust\n       math4 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       lunch |  -.0620863   .0324188    -1.92   0.056    -.1256705    .0014978\n      lenrol |   .2966956   1.484868     0.20   0.842    -2.615625    3.209017\n      lrexpp |   2.798777   1.410581     1.98   0.047     .0321579    5.565397\n       _cons |   37.39798    16.8327     2.22   0.026     4.383449     70.4125\n------------------------------------------------------------------------------\n\nAbsorbed degrees of freedom:\n-----------------------------------------------------+\n Absorbed FE | Categories  - Redundant  = Num. Coefs |\n-------------+---------------------------------------|\n       schid |      1735        1735           0    *|\n        year |         6           0           6     |\n-----------------------------------------------------+\n* = FE nested within cluster; treated as redundant for DoF computation\n\nLinear regression                               Number of obs     =      9,328\n                                                F(9, 1734)        =     821.90\n                                                Prob > F          =     0.0000\n                                                R-squared         =     0.4595\n                                                Root MSE          =     15.505\n\n                              (Std. err. adjusted for 1,735 clusters in schid)\n------------------------------------------------------------------------------\n             |               Robust\n       math4 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n       lunch |  -.0620863   .0327488    -1.90   0.058    -.1263177     .002145\n      lenrol |   .2966948   1.509296     0.20   0.844    -2.663538    3.256927\n      lrexpp |   2.798777   1.435068     1.95   0.051    -.0158696    5.613423\n    m1_lunch |  -.3799049   .0343728   -11.05   0.000    -.4473213   -.3124884\n    m2_lunch |  -2.750266   .5058811    -5.44   0.000    -3.742467   -1.758065\n   m1_lenrol |  -2.394415   1.633657    -1.47   0.143    -5.598561     .809731\n   m2_lenrol |  -273.8924   11.25589   -24.33   0.000    -295.9689   -251.8158\n   m1_lrexpp |   5.667779   2.276245     2.49   0.013     1.203305    10.13225\n   m2_lrexpp |    73.4047   3.276595    22.40   0.000      66.9782    79.83119\n       _cons |   37.39799   17.10933     2.19   0.029     3.840901    70.95507\n------------------------------------------------------------------------------\n```\n:::\n:::\n\n\n## Caveats: Not everything is solved using FE\n\n- While FE allows you do control for unobserve but time fixed factors, it will Not help you if those factors are time varying.\n\n  if $e_{it}$ is different across treated and control groups $D_{it}=0,1$ then TE cannot be estimated.\n\n  This could happen if cases of reverse causality or \n\n- Because it depends strongly on within variation, it will be more sensitive to measurement errors.  Specifically:\n\n$$\\beta^{fe} = \\beta * \\left(1-\\frac{\\sigma_v^2}{(\\sigma^2_v+\\sigma^2_x)(1-\\rho_x)}\\right)\n$$\n\nIn other words. when $X$ has strong autocorrelation (Stable treatment), the measurement error effect is far larger!\n\n## Caveats: FE makes things harder to analyze\n\n- When using a single FE, OLS using within variation to identify the slope coefficients.\n    How does a change in X's (compared to the average) affect changes in the outcomes (respect to averages)\n\n- When using Two Fixed effects (individuals and time) identification becomes tricky:\n$$\\tilde y_{it} = y_{it}-\\bar y_i - \\bar y_t + \\bar y  $$\n\nWe are looking for variation across time but also across individuals.\n\n> we are using changes in outcome that are different from the average changes in the sample.\n\n- with Multiple FE, same story...we are trying to exploit variation across multiple dimensions! Difficult to understand\n\n## Caveats: Some times, the variation may be wrong:\n\nConsider:\n\n$$y_{it} = a_i + a_t + \\delta D_{it} + e_{it}$$\n\nIf $D_it$ changes only for some people at the same time, we are good.\n\n- The variation comes from comparing individuals (before and after) (time variation), who were treated and untreated (individual effects)\n\nBut if $D_{it}$ changes at different times for different people, we have a problem. \n\n- Who is being compared??? \n  - Those before and after (fine) to those with Status change (D=0 -> D=1) to those whos status do not change! (D=0 to D=0) or (D=1 to D=1)\n\nWe will discuss this problem again when talking about DID\n\n## Income, Schooling, and Ability: \n### Evidence from a New Sample of Identical Twins\n by\n\n**Orley Ashenfelter** and **Cecilia Rouse**\n\n## Motivation: \n### In search of Returns to Education\n\nThis paper aims to identify returns of education abstracting from the impact of innate ability.\n\nIn their framework, ability is mostly explained by genetics, thus to control for it, the authors use a sample \nof identical twins, to \"absorb\" unobserved genetics using FE.\n\nThey address some of the problems inherited to FE estimation\n\n## The model\n\n- The theoretical model described states that all individuals have an optimal level of Schooling, such that maximizes the his/her returns. \n- However, Total schooling may be affected by measurement or optimization errors. \n- Schooling will be directly affected by returns to education, but also by the ability of students.\n\nIn their framework, for the twins setup, (log)earnings will be determined by:\n\n$$\n\\begin{aligned}\ny_{1j}=A_j + b_j S_{1j} + \\gamma X_j + e_{1j} \\\\\ny_{2j}=A_j + b_j S_{2j} + \\gamma X_j + e_{2j} \n\\end{aligned}\n$$\n\n## The model\n\nBecause ability is related to schooling, they suggest using the following:\n\n$$\ny_{ij}=\\lambda(0.5(S_{1j}+S_{2j}) + b_j S_{1j} + \\gamma X_j + v_j+ e_{ij} \n$$\n\nWhich is the equivalent to CRE. Or estimate the fixed effects equivalent:\n\n$$y_{1j} - y_{2j} = b(S_{2j}-S_{1j}) + e_{2j} - e_{2j}\n$$\n\nThe later is a First difference, rather than FE estimator, but they both identical when T=2.\n\n- An additional model the authors use is one where returns to education could be related to ability. \n- Or where ability is measured/proxied by parents education. (which is fixed across twins)\n\n## Data\n\n![](resources\\pfe1.png)\n\n## OLS\n\n![](resources\\pfe2.png)\n\n## FE-RE-CRE?\n\n![](resources\\pfe3.png){height=800px width=1300px}\n\n## Heterogeneity\n\n![](resources\\pfe4.png)\n\n# Next Class (Friday) Instrumental Variables!\n\n",
    "supporting": [
      "08panel_FE_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}