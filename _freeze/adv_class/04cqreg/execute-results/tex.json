{
  "hash": "eac1398601e7a67e4e8166d93d02bdbf",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Conditional Quantile Regressions\"\nsubtitle: \"Because no-one is average\"\nauthor: Fernando Rios-Avila\nformat:\n  revealjs: \n    slide-number: true\n    width: 1600\n    height: 900\n    code-fold: true\n    echo: true\n    css: styles.css  \n  pdf: default     \nexecute:\n  freeze: true   \n---\n\n## Introduction {.scrollable}\n\n### Question: What are quantiles? and why do we care??\n\n-   Quantiles provide a better characterization of distributions.\n\n    -   It provides you with more information than standard summary statistics (means and variance)\n\n-   How so? In general, there are 3 ways you can use to know \"everything\" about a distribution.\n\n    -   You either have access to every single $y_i$\n\n    -   Or you know the distribution function $f(y)$ (pdf)\n\n    -   Or you know the cumulative distribution function $F(y)=\\int_\\infty^y f(t) dt = P(Y\\leq y)$\n\n-   However, there is an additional way. Quantile:\n\n$$\nQ(\\theta) = F^{-1}(p)\n$$\n\n\n## $Q(\\theta) = F^{-1}(\\theta)$\n\n![](resources/qreg1.png){fig-align=\"center\"}\n\n## Other advantages? Yes! {.scrollable}\n\n1.  Quantiles are far more stable in the presence of outliers. Because of this, they are particularly useful as measures of central tendency (perhaps superior to the mean) (ðŸ¤”?)\n\n    -   Simple \"test\". In the small town of Troy-NY one of the residents wins the 2B\\$ lottery. How much has welfare increase for the average resident?\n\n2.  Scaled IQR can be used as an alternative measure of dispersion.\n\n$$\nse2 = \\frac{Q_{75}-Q_{25}}{1.34898}\n$$\n\n3.  They are also \"function-transformation\" resistant: $exp(Q_{log(y)} (.10)) = Q_y(.10)$\n\n##\n\n4.   And are also very easy to estimate:\n\n-  Sort data by $y$ $\\rightarrow$ Obtain weighted ranks $\\rightarrow$ choose the lowest value so that $\\theta$ % of the data is less of equal to that number\n\n$$\nF^{-1} (tau) = inf(x: F(x)\\geq t)\n$$\n\n- This \"just\" requires obtaining an approximation for $F(\\theta)$, which can be approximated using nonparametric methods!\n\n$$\\hat F(x) = \\frac{1}{N}\\sum (K_F(x,x_i,h)) = \n\\frac{1}{N}\\sum 1(x_i<x)\n$$\n\n- then we simply \"invert\" the function for whichever quantile we are interested in.\n\n## Technical Note\n\n- There are many empirical ways to estimate quantiles, even when using the empirical distribution function. \n\n- So do not be suprised about small differences in the estimates.\n\n- When using Smooth functions, the choice of the kernel is also important. (and bandwidth)\n \n## Statistical Inference {.scrollable}\n\n- As with the mean, sampling quantiles are measured with sampling error.\n\n- However their standard errors are not as intuitive to obtain ( but can be derived using the delta Method)\n\n$$Q_y(\\tau) = F_y^{-1}(\\tau) \\rightarrow F_y(Q_y(\\tau)) = \\tau \\ || \\ \\frac{\\partial}{\\partial \\tau}\n$$\n\nThis gives us:\n$$f_y(Q_y(\\tau)) \\frac{dQ}{d\\tau}  =1 \\rightarrow \\frac{dQ}{d\\tau} =  \\frac{1}{f(Q_y(\\tau))}\n$$\n\n##\n### \n\nSo we have:\n\n$$\n\\begin{aligned}\n\\hat Q_y(\\tau) &\\simeq Q_y(\\tau) + \\frac{1}{f(Q_y(\\tau))}(\\hat \\tau-\\tau) \\\\\n\\hat Q_y(\\tau) - Q_y(\\tau) &\\simeq \\frac{1}{f(Q_y(\\tau)}(\\hat \\tau-\\tau) \\\\\nVar(\\hat Q_y(\\tau)) &= \\frac{Var(\\hat \\tau - \\tau) }{f^2(Q_y(\\tau))} = \\frac{N^{-1} \\tau(1-\\tau)}{f^2(Q_y(\\tau))}\n\\end{aligned}\n$$\n\nLets understand this elements\n\n##\n### Quantile SE {.scrollable}\n\n$$\nVar(\\hat Q_y(\\tau)) = \\frac{Var(\\hat \\tau - \\tau) }{f^2(Q_y(\\tau))} = \\frac{1}{f^2(Q_y(\\tau))}\\frac{\\tau(1-\\tau)}{N}\n$$\n\n-   The variance of a quantile depends on the distribution of $\\tau$. This follows a Bernoulli distribution: Is $y\\geq Q_y$ or $y<Q_y$.\n\n    -   Largest near the center of the distribution (50%-50%) but smaller (more precise) near the tails of the distribution.\n\n-   But also depends on the density of the distribution.\n\n    -   More precise estimates when the density is high (center), but less precise near tails of the distribution.\n    -   And, because $f()$ is unknown, there is another source of variation.\n\n-   And as usual, it depends on the sample size (N) \n-   Of course, you also have the alternative method. **Bootstrap**!\n\n## {.scrollable}\n\n### Example\n\n#### Using Bootstrap\n\n::: {.cell .larger execution_count=1}\n``` {.stata .cell-code code-fold=\"false\"}\nfrause wage2, clear\nbootstrap q10=r(r1) q25=r(r2) q50=r(r3) ///\n          q75=r(r4) q90=r(r5), reps(1000) nodots: ///\n          _pctile wage  , p(10 25 50 75 90)\n```\n\n::: {.cell-output .cell-output-display}\n```\n<IPython.core.display.HTML object>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nwarning: _pctile does not set e(sample), so no observations will be excluded\n         from the resampling because of missing values or other reasons. To\n         exclude observations, press Break, save the data, drop any\n         observations that are to be excluded, and rerun bootstrap.\n\nBootstrap results                                        Number of obs =   935\n                                                         Replications  = 1,000\n\n      Command: _pctile wage, p(10 25 50 75 90)\n          q10: r(r1)\n          q25: r(r2)\n          q50: r(r3)\n          q75: r(r4)\n          q90: r(r5)\n\n------------------------------------------------------------------------------\n             |   Observed   Bootstrap                         Normal-based\n             | coefficient  std. err.      z    P>|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n         q10 |        500   9.149192    54.65   0.000     482.0679    517.9321\n         q25 |        668   14.21654    46.99   0.000     640.1361    695.8639\n         q50 |        905   15.19745    59.55   0.000     875.2135    934.7865\n         q75 |       1160   20.87954    55.56   0.000     1119.077    1200.923\n         q90 |       1444   32.84186    43.97   0.000     1379.631    1508.369\n------------------------------------------------------------------------------\n```\n:::\n:::\n\n\n#### Analytical SE\n\n::: {.cell .larger execution_count=2}\n``` {.stata .cell-code code-fold=\"false\"}\nsort wage\ngen w1 = _n\ngen w0 = _n-1\nby wage:gen p=0.5*(w1[_N]+w0[1])/935\nkdensity wage, at(wage) gen(fwage) nodraw\ngen se = sqrt(p*(1-p)/935)/fwage\ntabstat wage se if inlist(wage,500,668,905,1160,1444), by(wage)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSummary statistics: Mean\nGroup variable: wage (monthly earnings)\n\n    wage |      wage        se\n---------+--------------------\n     500 |       500  13.27634\n     668 |       668  14.78419\n     905 |       905  14.69217\n    1160 |      1160   19.3574\n    1444 |      1444  29.32711\n---------+--------------------\n   Total |  730.7619  15.88035\n------------------------------\n```\n:::\n:::\n\n\n## From $Q_Y$ to $Q_{Y|X}$ {.scrollable}\n\n- The approaches used earlier to identify a particular quantile are not the only ones.\n\n- Just like we can use OLS to estimate Means, we could also use a similar method to estimate the median. \n  \n- We only need to change the loss function $L()$ from an $L^2$ to a $|L|$.\n\nConsider this:\n\n$$\\begin{aligned}\nmedian(Y) &= min_\\mu \\frac{1}{N}\\sum |y-\\mu| \\\\\n&=\\frac{2}{N}\\sum (y-u)(0.5-I([y-u]<0)\n\\end{aligned}\n$$\n\n##\n\n![](resources/image-639081794.png){fig-align=\"center\" width=\"751\"}\n\n## \n### Q and Loss functions\n\n::: {.panel-tabset}\n\n## Why does it matter?\n\n-   The loss function for Quantiles does not penalize \"errors\" as much as $L^2$ does. \n    -   This is why its more robust to outliers (almost not affected by them). \n\n-   However, the loss function is no longer differentiable (is discontinuous). So requires other methods to find the solution. Even if it may not look like that:\n\n## Objective function\n\n![](resources/image-1802600465.png){fig-align=\"center\" width=90%}\n\n:::\n\n##\n### From $\\beta$ to $X\\beta$\n\nKoenker and Bassett (1978) extended this approximation in two ways:\n\n-   Allowing for Covariates ($X's$) variation\n\n-   Allowing to identify other quantiles in the distribution:\n\n$$ \\beta(\\tau) = \\underset {b}{min} \\ N^{-1} \\sum \\rho_\\tau(y_i-X_i'b) \\\\\n\\rho_\\tau (u) = u (\\tau-I(u<0))\n$$\n\n-   This implicitly states that you want to find a combination of $X's$ such that $\\tau$ proportion of $y_i$ are lower than the $X_i'\\beta(\\tau)$, for every combination of $X's$.\n    - Or as close as possible.\n\n## Interpretation: Why is it so different from OLS?  \n\n::: {.panel-tabset}\n\n## \n\n-   In Rios-Avila and Maroto(2022) we stress that OLS can be interpreted at different \"levels\". Consider the following:\n\n$$\ny_i = b_0 + b_1 x_1 + b_2 x_2  + e\n$$ \n\nIf the errors are exogenous, and there is no heteroskedasticty, you can \"obtain\" marginal effects at many levels\n\n## Individual \n$$ Ind: \\frac{dy_i}{dx_{1i}}=b_1 \n$$\n\nIf $x_1i$ changes, and everything else is fixed, then $y_i$ changes by $b_1$ units for that individual.\n\n## Conditional \n\n$$\\begin{aligned}\nE(y_i|X=x)&=b_0 + b_1 x_1 + b_2 x_2 \\\\\n\\frac{dE(y|x)}{dx_1} &=b_1 \\\\\n\\end{aligned}\n$$\n\nIf $x_1$ changes for a group of individuals with the same characterisitcs, everything else is fixed, then everyone in that group will experience a change in $Y$ by $b_1$ units.\n\n## Unconditional\n\n$$\\begin{aligned}\nE(y_i) &= b_0 + b_1 E(x_1) + b_2 E(x_2) \\\\\n\\frac{dE(y)}{dE(x_1)} &=b_1 \n\\end{aligned}\n$$ \n\nIf $E(x_1)$ changes for everyone, then the overall average change in $Y$ is $b_1$ units.\n\n## Conclusion\n\n- So in OLS, assuming a linear model in parameters, **Nothing** changes. The effect is the same! (although magnitude of the \"experiment\" changes)\n\n:::\n\n## But *C*Qreg? {.scrollable}\n\nFor quantile regressions, things are not that simple.\n\n1.  There is no \"individual\" level quantile effect, because we do not observe individual ranks $\\tau$. \n\n    - If we could observe them, and we assume they are fixed, then one can obtain individual level effects.\n\n2.  Because $\\tau$ is unobserved, all Qregression coefficients, should be interpreted as effects on Conditional Distributions (thus the name **C**QREG).\n\n    -   In other words, effects are just expected changes in some points in the distribution.\n\n3.  You cannot use it for unconditional effects either (not easily), because\n\n$$\nE(Q_{Y|X}(\\tau)) \\neq Q_Y(\\tau)\n$$\n\nand you cannot \"simply\" average the CQREG effects to get unconditional quantiles.\n\n##\n### what does it mean?\n\n- This means that CQREG interpretation are percentile $\\tau$ and covariate $X$ specific. \n \n   -   **Fixed rank.** If you happen to be on the top of the distribution (and stay there), the quantile effect is given by the $\\beta(\\tau)$\n      \n   -   **Rank is not fixed:** What we see is the effect of a change in $X$ on the conditional distribution of $Y$ (measured by the quantile)\n\nSo this must be kept in mind, whenever one interpret results\n\n##\n\n### Visualizing Differences in Interpretation\n\n\n\n::: {.panel-tabset}\n\n## Fixed Rank\n\n::: {.cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](04cqreg_files/figure-pdf/cell-5-output-1.png){}\n:::\n:::\n\n\n## Varying Rank\n\n::: {.cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![](04cqreg_files/figure-pdf/cell-6-output-1.png){}\n:::\n:::\n\n\n:::\n\n## Example: Wages...\n\n::: {.cell .larger execution_count=6}\n``` {.stata .cell-code code-fold=\"false\"}\nfrause oaxaca, clear\nqui:qreg  lnwage educ exper tenure female, nolog q(10)\nest sto m1\nqui:qreg  lnwage educ exper tenure female, nolog q(50)\nest sto m2\nqui:qreg  lnwage educ exper tenure female, nolog q(90)\nest sto m3\n* ssc install estout\nesttab m1 m2 m3, se nogaps mtitle(q10 q50 q90)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Excerpt from the Swiss Labor Market Survey 1998)\n\n------------------------------------------------------------\n                      (1)             (2)             (3)   \n                      q10             q50             q90   \n------------------------------------------------------------\neduc                0.103***       0.0694***       0.0639***\n                 (0.0166)       (0.00433)       (0.00902)   \nexper              0.0200***      0.00758***      0.00402   \n                (0.00493)       (0.00128)       (0.00267)   \ntenure           0.000669         0.00657***      0.00774*  \n                (0.00603)       (0.00157)       (0.00327)   \nfemale             -0.151         -0.0689**       -0.0543   \n                 (0.0806)        (0.0210)        (0.0437)   \n_cons               1.462***        2.474***        2.984***\n                  (0.219)        (0.0570)         (0.119)   \n------------------------------------------------------------\nN                    1434            1434            1434   \n------------------------------------------------------------\nStandard errors in parentheses\n* p<0.05, ** p<0.01, *** p<0.001\n```\n:::\n:::\n\n\n## Example: Wages...\n\n`qregplot educ exper tenure female, cons q(5/95)`\n\n![](resources/image-728310792.png){fig-align=\"center\" width=100%}\n\n# Other Interpretations of Qreg\n\n## Random coefficents\n\nOne approach to both understanding, and simulating QREG is by also understanding the intuition behind the data generating process.\n\n$$\n\\begin{aligned}\ny &= b_0(\\tau)+b_1(\\tau)x_1 + +b_2(\\tau)x_2+...+b_k(\\tau) x_k \\\\\n \\tau &\\sim runiform(0,1) \n\\end{aligned}\n$$\n\nwhere all coefficients are a function (preferably monotonically increasing or decreasing) of $\\tau$ .\n\n> We want them to be monotonically increasing or decreasing because we want that\n$$\nX \\beta(\\tau_1 ) \\geq\nX \\beta(\\tau_2 ) \\  \\text{ if } \\ \\tau_1 > \\tau_2\n$$\n\n##\n\n- In this specification the unobserved component $\\tau$ is similar to luck. If you are lucky and get a high $\\tau$ then you will have better outcomes than anyone of your peers.\n\n- Also notice: $\\tau$ is the only random factor, and should be uncorrelated with $X$ (you do not make your luck!)\n \n\n## SVC model with a latent running variable {.scrollable}\n\n- Another way of thinking about Qreg is to align it to the **semiparametric** method we introduced ealier. SVC model.\n\n\n- In SVC, there is an observed running variable $z$, and we focus on analyzing how the \"local\" effects of $X$ on $Y$ change as a function of $z$.\n  \n- The difference with Qreg is that the running variable is unknown $\\tau$. \n \n  - Given the outcome, and characteristics we can identify something like a \"latent\" component.\n\n## \n\n- There are a few (recent) papers that focus on estimation and identification of these models. The general intuition is that the qreg model is identified by the following moment condition:\n\n$$\nE\\Big( 1[x\\beta(\\tau) - y > 0 ] - \\tau \\Big) = 0\n$$\n\nbut substitute the indicator function with a smooth function. CDF\n\n$$\nE\\Big( F(x\\beta(\\tau) - y) - \\tau \\Big) = 0\n$$\n\nBeing differentiable, this problem is relatively easier to solve (given good initial values)\n\n## Example (with `sivqr`)\n\n![](resources/image-2068895861.png){fig-align=\"center\"}\n\n## Scale and Location Model {.scrollable}\n\nAnother approach that can be used to understand Quantile regressions (and elaborate the interpretation) is to assume that the coefficients are in fact capturing two components:\n\n$$y = Xb + Xg(\\tau)\n$$\n\n-   **Location:** $Xb$ which indicates what is the average/typical relationship between X and Y.\n\n-   **Scale:** $Xg(\\tau)$ which indicates how far one could be from the average effect, given a relative rank $\\tau$\n\nEstimation of this model is not standard. But can be manually implemented:\n\n1.  Estimate OLS and get residuals\n2.  Estimate QREG using those residuals\n\nRequires additional care for the estimation of SE\n\n## Scale and Location 2: Heteroskedasticity {.scrollable}\n\nA second approach that is useful to understand and interpret CQreg is to consider a parametric version of the LS model:\n\n$$y = Xb + \\gamma (X) * e \\text{ with } \\gamma(X)>>0$$ \n\n- This shows the relationship between a quantile regressions and heteroskedasticity in the error term. \n\n- If we assume Heteroskedasticity is parametric ($\\gamma(x) = X \\gamma$), it constrains the relationship across all quantile coefficients:\n\n$$y = X(b+\\gamma F^{-1}(\\tau)) \\rightarrow b(\\tau)=b+\\gamma\\times q(\\tau)\n$$\n\n- Making it more efficient, albeit imposing constrains of the relationship.\n\n\n## {.scrollable}\n\n### Example (with `mmqreg`)\n\n::: {.cell .larger execution_count=7}\n``` {.stata .cell-code}\nqui:frause oaxaca, clear\nqui:mmqreg lnwage educ exper tenure female, robust\nqregplot educ exper tenure female, cons q(5(5)95)\n```\n\n::: {.cell-output .cell-output-display}\n![](04cqreg_files/figure-pdf/cell-8-output-1.png){fig-pos='H'}\n:::\n:::\n\n\n## Estimation and Statistical Inference {.scrollable}\n\nAs hinted previously, there are many approaches that can be used for the estimation of Conditional Quantile regressions.\n\n-   Official: `qreg`, `sqreg`, `bsqreg`, `iqreg`\n-   CContributed: `qreg2`, `qrprocess`, `mmqreg`, `smqreg`, `sivqr`\n\n- For Standard errors, however, there are main 3 options. Under the assumption of iid error. Non iid error (robust), and assuming clustered standard errors.\n\n$$\n\\begin{aligned}\n iid: \\Sigma_\\beta &=\\frac{\\tau(1-\\tau)}{N f^2_y(F^{-1}(\\tau))}(X'X)^{-1} \\\\\nniid: \\Sigma_\\beta &= \\tau(1-\\tau) (X'f(0|x)X)^{-1} \\ (X'X) \\ (X'f(0|x)X)^{-1} \\\\\nalt: \\Sigma_\\beta &= (IF_\\beta \\ ' IF_\\beta) N^{-2}\n\\end{aligned}\n$$\n\nOr simply Bootstrap\n\n## Problems and Considerations  {.scrollable}\n\n1.  Unless otherwise specified, quantile regressions are linear in variables (and parameters?)\n2.  With few exceptions, quantile regressions are quantile specific. Comparisons across quantiles require joint estimation (to construct VCV matrix)\n3.  Because they are \"local\" estimators, there is risk of crossing quantiles. (Violation of Monotonicity)\n4.  Non-linear effects will be present if either the location or scale components are nonlinear.\n5.  Quantile regressions are very sensitive to measurement errors in both dependent and independent variables\n6.  They can be difficult to interpret (see references)\n\n7. Implementation of fixed effects is not straightforward \n\n# Quantile Regressions with Fixed Effects\n\n## The problem\n\n- There are two problems related to Estimating Quantile Regressions with (multiple) Fixed Effects\n  - First: As with nonlinear models, Adding many fixed effects creates an incidental parameter problem.\n  - Second: For Conditional Quantile Regressions, it can be difficult to interpret the role of fixed effects.\n  \n## Simulating some data\n\n::: {.cell .larger execution_count=8}\n``` {.stata .cell-code code-fold=\"false\"}\nclear\nset obs 1000\ngen id = _n\ngen vi = rnormal()\ngen ui = rnormal()+vi\n\ngen toexp = 1+rpoisson(5)\nexpand toexp\ngen err = rnormal()\ngen x1 = rnormal()+vi+err\ngen x2 = rnormal()+vi+err\ngen y = 1+x1+x2+ui+rnormal()*exp(0.2*x1-0.2*x2+0.3*ui)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of observations (_N) was 0, now 1,000.\n(5,019 observations created)\n```\n:::\n:::\n\n\n# Accounting for Fixed effects\n\n## Benchmark\n\nAssume you observe those fixed effects:\n\n::: {.cell .larger execution_count=9}\n``` {.stata .cell-code}\nset line 255\nqui:qreg y x1 x2 ui, q(10)\nest sto m10\nqui:qreg y x1 x2 ui, q(50)\nest sto m20\nqui:qreg y x1 x2 ui, q(90)\nest sto m30\nesttab m10 m20 m30, se nogaps mtitle(q10 q50 q90)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n------------------------------------------------------------\n                      (1)             (2)             (3)   \n                      q10             q50             q90   \n------------------------------------------------------------\nx1                  0.780***        0.988***        1.219***\n                 (0.0190)        (0.0139)        (0.0224)   \nx2                  1.219***        1.000***        0.763***\n                 (0.0189)        (0.0138)        (0.0223)   \nui                  0.654***        1.000***        1.352***\n                 (0.0180)        (0.0132)        (0.0212)   \n_cons              -0.458***        0.970***        2.420***\n                 (0.0236)        (0.0173)        (0.0279)   \n------------------------------------------------------------\nN                    6019            6019            6019   \n------------------------------------------------------------\nStandard errors in parentheses\n* p<0.05, ** p<0.01, *** p<0.001\n```\n:::\n:::\n\n\n## Ignoring Fixed Effects\n\n::: {.cell .larger execution_count=10}\n``` {.stata .cell-code}\nqui:qreg y x1 x2  , q(10)\nest sto m1\nqui:qreg y x1 x2  , q(50)\nest sto m2\nqui:qreg y x1 x2  , q(90)\nest sto m3\nesttab m1 m2 m3 m10 m20 m30, se nogaps mtitle(q10 q50 q90)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n------------------------------------------------------------------------------------------------------------\n                      (1)             (2)             (3)             (4)             (5)             (6)   \n                      q10             q50             q90             m10             m20             m30   \n------------------------------------------------------------------------------------------------------------\nx1                  0.981***        1.171***        1.470***        0.780***        0.988***        1.219***\n                 (0.0235)        (0.0217)        (0.0415)        (0.0190)        (0.0139)        (0.0224)   \nx2                  1.339***        1.260***        1.139***        1.219***        1.000***        0.763***\n                 (0.0234)        (0.0215)        (0.0412)        (0.0189)        (0.0138)        (0.0223)   \nui                                                                  0.654***        1.000***        1.352***\n                                                                 (0.0180)        (0.0132)        (0.0212)   \n_cons              -1.133***        0.813***        3.275***       -0.458***        0.970***        2.420***\n                 (0.0300)        (0.0276)        (0.0529)        (0.0236)        (0.0173)        (0.0279)   \n------------------------------------------------------------------------------------------------------------\nN                    6019            6019            6019            6019            6019            6019   \n------------------------------------------------------------------------------------------------------------\nStandard errors in parentheses\n* p<0.05, ** p<0.01, *** p<0.001\n```\n:::\n:::\n\n\n## Solution 1: Correlated Random Effects {.scrollable}\n\nIdea: Include \"PAnel average\" of all indep variables as regressors. \n\nThey should control (at least partially) for the unobserved effects.\n\n$$Q_p(y|X) = X\\beta + \\alpha \\bar X + \\epsilon$$\n\n::: {.cell .larger execution_count=11}\n``` {.stata .cell-code}\nbysort id: egen x1p = mean(x1)\nbysort id: egen x2p = mean(x2)\nqui:qreg y x1 x2 x1p x2p , q(10)\nest sto m1\nqui:qreg y x1 x2  x1p x2p , q(50)\nest sto m2\nqui:qreg y x1 x2  x1p x2p , q(90)\nest sto m3\nesttab m1 m2 m3 m10 m20 m30, se nogaps mtitle(q10 q50 q90)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n------------------------------------------------------------------------------------------------------------\n                      (1)             (2)             (3)             (4)             (5)             (6)   \n                      q10             q50             q90             m10             m20             m30   \n------------------------------------------------------------------------------------------------------------\nx1                  0.825***        0.972***        1.195***        0.780***        0.988***        1.219***\n                 (0.0250)        (0.0246)        (0.0460)        (0.0190)        (0.0139)        (0.0224)   \nx2                  1.176***        1.023***        0.774***        1.219***        1.000***        0.763***\n                 (0.0252)        (0.0248)        (0.0463)        (0.0189)        (0.0138)        (0.0223)   \nx1p                 0.310***        0.413***        0.663***                                                \n                 (0.0575)        (0.0565)         (0.106)                                                   \nx2p                 0.283***        0.406***        0.551***                                                \n                 (0.0564)        (0.0555)         (0.104)                                                   \nui                                                                  0.654***        1.000***        1.352***\n                                                                 (0.0180)        (0.0132)        (0.0212)   \n_cons              -0.951***        0.861***        3.146***       -0.458***        0.970***        2.420***\n                 (0.0278)        (0.0273)        (0.0511)        (0.0236)        (0.0173)        (0.0279)   \n------------------------------------------------------------------------------------------------------------\nN                    6019            6019            6019            6019            6019            6019   \n------------------------------------------------------------------------------------------------------------\nStandard errors in parentheses\n* p<0.05, ** p<0.01, *** p<0.001\n```\n:::\n:::\n\n\n## Solution 2: FE are Fixed {.scrollable}\n\n- Canay (2011) proposes make the \"simplifying\" that \"Fixed effects\" are constant across quantiles. \n- Thus a two step procedure is proposed:\n  - First: Estimate the fixed effects using OLS\n  - Second: Estimate the quantile regression using outcome after taking FE \"off\"\n\n$$\\begin{aligned}\ny &= X\\beta + \\alpha_i + \\epsilon \\\\\nQ_\\tau(y - \\hat \\alpha_i |X) &= X\\beta(\\tau) +  \\epsilon_\\tau \\\\\n\\end{aligned}\n$$\n\n::: {.cell .larger execution_count=12}\n``` {.stata .cell-code}\nqui:reghdfe y x1 x2, absorb(fe = id)\ngen y_fe = y - fe\nqui:qreg y_fe x1 x2   , q(10)\nest sto m1\nqui:qreg y_fe x1 x2   , q(50)\nest sto m2\nqui:qreg y_fe x1 x2 , q(90)\nest sto m3\nesttab m1 m2 m3 m10 m20 m30, se nogaps mtitle(q10 q50 q90)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(4 missing values generated)\n\n------------------------------------------------------------------------------------------------------------\n                      (1)             (2)             (3)             (4)             (5)             (6)   \n                      q10             q50             q90             m10             m20             m30   \n------------------------------------------------------------------------------------------------------------\nx1                  0.727***        0.992***        1.277***        0.780***        0.988***        1.219***\n                 (0.0213)        (0.0120)        (0.0218)        (0.0190)        (0.0139)        (0.0224)   \nx2                  1.117***        1.004***        0.853***        1.219***        1.000***        0.763***\n                 (0.0212)        (0.0119)        (0.0216)        (0.0189)        (0.0138)        (0.0223)   \nui                                                                  0.654***        1.000***        1.352***\n                                                                 (0.0180)        (0.0132)        (0.0212)   \n_cons              -0.296***        1.021***        2.336***       -0.458***        0.970***        2.420***\n                 (0.0272)        (0.0153)        (0.0277)        (0.0236)        (0.0173)        (0.0279)   \n------------------------------------------------------------------------------------------------------------\nN                    6015            6015            6015            6019            6019            6019   \n------------------------------------------------------------------------------------------------------------\nStandard errors in parentheses\n* p<0.05, ** p<0.01, *** p<0.001\n```\n:::\n:::\n\n\n## Solution 3: Modified Canay(2011) {.scrollable}\n\n- Same as before, but rather than \"removing\" fixed effects, we control for them in the model:\n\n$$\\begin{aligned}\ny &= X\\beta + \\alpha_i + \\epsilon \\\\\nQ_\\tau(y |X) &= X\\beta(\\tau) + \\gamma \\hat \\alpha_i + \\epsilon_\\tau \\\\\n\\end{aligned}\n$$\n\n::: {.cell .larger execution_count=13}\n``` {.stata .cell-code}\nqui:qreg y x1 x2 fe  , q(10)\nest sto m1\nqui:qreg y x1 x2 fe  , q(50)\nest sto m2\nqui:qreg y x1 x2 fe, q(90)\nest sto m3\nesttab m1 m2 m3 m10 m20 m30, se nogaps mtitle(q10 q50 q90)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n------------------------------------------------------------------------------------------------------------\n                      (1)             (2)             (3)             (4)             (5)             (6)   \n                      q10             q50             q90             m10             m20             m30   \n------------------------------------------------------------------------------------------------------------\nx1                  0.800***        0.993***        1.171***        0.780***        0.988***        1.219***\n                 (0.0182)        (0.0137)        (0.0206)        (0.0190)        (0.0139)        (0.0224)   \nx2                  1.193***        1.006***        0.831***        1.219***        1.000***        0.763***\n                 (0.0181)        (0.0137)        (0.0205)        (0.0189)        (0.0138)        (0.0223)   \nfe                  0.691***        0.991***        1.279***                                                \n                 (0.0159)        (0.0120)        (0.0180)                                                   \nui                                                                  0.654***        1.000***        1.352***\n                                                                 (0.0180)        (0.0132)        (0.0212)   \n_cons              -0.334***        1.017***        2.354***       -0.458***        0.970***        2.420***\n                 (0.0227)        (0.0171)        (0.0257)        (0.0236)        (0.0173)        (0.0279)   \n------------------------------------------------------------------------------------------------------------\nN                    6015            6015            6015            6019            6019            6019   \n------------------------------------------------------------------------------------------------------------\nStandard errors in parentheses\n* p<0.05, ** p<0.01, *** p<0.001\n```\n:::\n:::\n\n\n## Solution 4: LS model {.scrollable}\n\n- Machado and Silva (2019) propose a different approach. They suggest modeling the quantile regression using linear models for a scale and location model.\n- This simplifies the task of estimating multiple equations:\n\n$$\\begin{aligned}\ny &= X\\beta + \\epsilon \\\\\n\\hat\\epsilon^2 &= X\\gamma + \\nu \\\\\nQ\\left( \\frac{\\hat\\epsilon}{X\\gamma}\\right) &= q(\\tau) \\\\\n\\beta(\\tau) &= \\beta + \\gamma \\times q(\\tau)\n\\end {aligned}\n$$\n\n::: {.cell .larger execution_count=14}\n``` {.stata .cell-code code-fold=\"false\"}\nqui:mmqreg y x1 x2   , q(10)  abs(id) robust\nest sto m1\nqui:mmqreg y x1 x2   , q(50)  abs(id) robust\nest sto m2\nqui:mmqreg y x1 x2 , q(90) abs(id) robust\nest sto m3\nesttab m1 m2 m3 m10 m20 m30, se nogaps mtitle(q10 q50 q90)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n------------------------------------------------------------------------------------------------------------\n                      (1)             (2)             (3)             (4)             (5)             (6)   \n                      q10             q50             q90             m10             m20             m30   \n------------------------------------------------------------------------------------------------------------\nmain                                                                                                        \nx1                  0.780***        0.993***        1.214***        0.780***        0.988***        1.219***\n                 (0.0183)        (0.0147)        (0.0203)        (0.0190)        (0.0139)        (0.0224)   \nx2                  1.231***        0.992***        0.745***        1.219***        1.000***        0.763***\n                 (0.0197)        (0.0162)        (0.0233)        (0.0189)        (0.0138)        (0.0223)   \nui                                                                  0.654***        1.000***        1.352***\n                                                                 (0.0180)        (0.0132)        (0.0212)   \n_cons              -0.346***        1.017***        2.431***       -0.458***        0.970***        2.420***\n                 (0.0220)        (0.0207)        (0.0251)        (0.0236)        (0.0173)        (0.0279)   \n------------------------------------------------------------------------------------------------------------\nN                    6019            6019            6019            6019            6019            6019   \n------------------------------------------------------------------------------------------------------------\nStandard errors in parentheses\n* p<0.05, ** p<0.01, *** p<0.001\n```\n:::\n:::\n\n\n# Next topic...Unconditional Quantiles\n\nUnconditional Quantile Regressions and RIF-Regressions\n\n",
    "supporting": [
      "04cqreg_files\\figure-pdf"
    ],
    "filters": []
  }
}