{
  "hash": "4b7b2b7791c054570c85e5f70e8d6bb1",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Exploratory Analysis and Comparisons\"\nauthor: \n  - name: Fernando Rios-Avila\n    affiliation: Levy Economics Institute  \ndate: last-modified\ndate-format: long\nformat:\n  revealjs:\n    theme: [ clean2.scss]\n    slide-number: true\n    footer: \"*Rios-Avila and Cia*\"\n    width:  1300\n    height: 675\njupyter: nbstata    \nexecute: \n  cache: true\n  freeze: true\n---\n\n\n\n \n\n## Motivation\n\n- You want to understand the market conditions for hotels in Vienna, using prices.\n  - How should you start the analysis itself?\n  - How to describe the data and present the key features?\n  - How to explore the data and check whether it is clean enough for (further) analysis?\n\n# Exploratory data analysis (EDA)\nOnce upon some data\n\n## Exploratory data analysis (EDA) - describing variables\n\n5 reasons to do EDA:\n\n1. To check data cleaning (part of iterative process)\n2. To guide subsequent analysis (for further analysis)\n3. To give context of the results of subsequent analysis (for interpretation)\n4. To ask additional questions (for specifying the (research) question)\n5. Offer simple, but possibly important answers to questions.\n\nAll and all, EDA should help you identify some of the key features of the data and how they relate to each other.\n\n## Key tasks: describe variables\n\n::: columns\n\n::: {.column width=\"50%\"}\n\nLook at key variables:\n\n- what values they can take and\n- how often they take each of those values.\n- are there extreme values\n:::\n\n::: {.column width=\"50%\"}\n\nDescribe what you see:\n\n- Descriptive statistics: key features summarized\n- to understand variables you work with\n- to make comparisons\n  \n:::\n:::\n\n# Describing variables\n\n## Frequency values\n\n- The **frequency** or more precisely, **absolute frequency** or count, of a value of a variable is simply the number of observations with that particular value. \n- The **relative frequency** is the frequency expressed in relative, or percentage, terms: the proportion of observations with that particular value among all observations.\n  - If missing values exist, Relative frequency could be relative to total observations or to non-missing observations.\n\n- Can also use Probabilities: the relative likelihood of a value of a variable.\n \n- How to? <u>`tab`</u>`ulate [variable]`, or better yet `fre [variable]` (SSC install)\n\n## The distribution \n\nA key part of EDA is to look at (**empirical**) distribution of **most** important variables.\n\n- All variables have a distribution. \n- The distribution determines the frequency of each value in the data.\n- May be expressed in terms of absolute frequencies (number of observations) or relative frequencies (percent of observations).\n- The distribution of a variable completely describes the variable as it occurs in the data.\n\n## Histograms\n\nHistogram reveals important properties of a distribution:\n\n- As with tabulation, Histograms show the empirical distribution of a variable.\n- They may allow you to see:\n  - Number and location of modes: these are the peaks in the distribution (compared to neighbors).\n- Shape of the distribution:\n  - Center, tails, if its symmetric or not, Long [left or right tails], and extreme values.\n\n- Extreme values: values that are very different from the rest. Extreme values are at the far end of the tails of histograms. (may even be signal of errors or missing)\n\n## Extreme values\n\n- Extreme values are substantially larger or smaller values for one or a handful of observations. Big departures from distribution.\n- Need conscious decision.\n  - Is this an error? (drop or replace)\n  - Is this not an error, code for missing? (replace)\n  - Is this not an error but not part of what we want to talk about? (drop?)\n  - Is this an integral feature of the data? (keep)\n\n## How to?\n\nHistograms in `Stata` are created with the `histogram` command.\n\n```stata\nhistogram [variable] [if in] [fweight], [bin(#) width(#) discrete] ///\n          [density] [frequency] [fraction] \n```\n\n- You can only create the histogram of one variable at a time. (unless combined)\n\n- and you can determine how \"fine\" or \"coarse\" the histogram is. (A bit of art)\n\n## Hotel Stars histograms\n\n\n\n:::{.columns}\n\n:::{.column width=\"50%\"}\n\n::: {#832a5fbf .cell execution_count=3}\n``` {.stata .cell-code code-fold=\"true\"}\nqui:histogram stars, d frequency ///\n    scale(1.5) addlabels xlabel(1(.5)5)\n```\n\n::: {.cell-output .cell-output-display}\n![Absolute frequency](week03_files/figure-revealjs/cell-3-output-1.png){}\n:::\n:::\n\n\n:::\n\n:::{.column width=\"50%\"}\n\n::: {#c758f998 .cell execution_count=4}\n``` {.stata .cell-code code-fold=\"true\"}\nqui:histogram stars, d percent ///\n    scale(1.5) addlabels xlabel(1(.5)5)\n```\n\n::: {.cell-output .cell-output-display}\n![Relative frequency](week03_files/figure-revealjs/cell-4-output-1.png){}\n:::\n:::\n\n\n:::\n:::\n\n## Hotel price histograms\n\n:::{.columns}\n\n:::{.column width=\"50%\"}\n\n::: {#6ad4d9ef .cell execution_count=5}\n``` {.stata .cell-code code-fold=\"true\"}\nqui:histogram price, d  ///\n    scale(1.5) width(1) \n```\n\n::: {.cell-output .cell-output-display}\n![Price Distribution  1$ bin](week03_files/figure-revealjs/cell-5-output-1.png){}\n:::\n:::\n\n\n:::\n\n:::{.column width=\"50%\"}\n\n::: {#36bdc240 .cell execution_count=6}\n``` {.stata .cell-code code-fold=\"true\"}\nqui:histogram price,  ///\n    scale(1.5) width(30)\n```\n\n::: {.cell-output .cell-output-display}\n![Price Distribution 30$ bin](week03_files/figure-revealjs/cell-6-output-1.png){}\n:::\n:::\n\n\n:::\n:::\n\n## Alternative Kdensity\n\n- Perhaps one weakness of Histograms are the implicit binning. The density \"jumps\" from bin to bin.\n- An alternative would be use smaller bins, requesting **jumps** to be smoother.\n- This is done with Kernel Density Estimation (KDE) plots. `kdensity` in Stata.\n- Two limitations: \n  - Not useful with discrete or limited variables\n  - Also requires the use of bandwiths\n\n## Kdensity for price\n\n:::{.panel-tabset}\n\n## Exmp1\n\n::: {#13873472 .cell execution_count=7}\n``` {.stata .cell-code code-fold=\"true\"}\n *| kdensity price,   ///\n    scale(1.5)  note(\"\") bw(10)\n```\n:::\n\n\n## Exmp2\n\n::: {#180e69b0 .cell execution_count=8}\n``` {.stata .cell-code code-fold=\"true\"}\n kdensity price,   ///\n    scale(1.5)  note(\"\") bw(1)\n```\n\n::: {.cell-output .cell-output-display}\n![Bandwidth of 1](week03_files/figure-revealjs/cell-8-output-1.png){}\n:::\n:::\n\n\n## Exmp3\n\n::: {#80e9457d .cell execution_count=9}\n``` {.stata .cell-code code-fold=\"true\"}\n kdensity price,   ///\n    scale(1.5)  note(\"\") bw(30)\n```\n\n::: {.cell-output .cell-output-display}\n![Bandwidth of 30](week03_files/figure-revealjs/cell-9-output-1.png){}\n:::\n:::\n\n\n:::\n\n## EDA and cleaning - Vienna hotels   \n\n1. Start with full data **N=428**\n2. Tabulate key qualitative variables\n3. Accommodation type - could be apartment, etc. Focus on hotels. N=264\n4. Stars - focus on 3, 3.5, 4 stars. <3 not well covered, >4 vary a lot. N=218\n5. Look at quantitative variables, focus on extreme values.\n6. Start with price. p=1012 likely error drop. keep others N= 217\n7. Distance: some hotels are far away. define cutoff. drop beyond 8km N=214\n8. Check why hotels could be far away. Find variable `city_actual`. Tabulate. Realise few hotels are not in Vienna. Drop them. N=207\n9. **the final cut**: Hotels, 3 to 4 stars, below 1000 euros, less than 8km from center, in Vienna actual **N=207**.\n\n# Summary statistics:\nCentral tendency\n\n## What are summary statistics?\n\n- Summary statistics are numbers that summarize the distribution of a variable.\n  - They provide numbers for the central tendency, spread, and shape.\n- Summary statistics are used to describe the data and to make comparisons between different datasets.\n\n## Summary statistics: Central Tendency\n\n- The most used statistic is the mean:\n  \n$$\\bar{x} = \\frac{\\sum x_i}{n}$$\n\nwhere $x_i$ is the value of variable $x$ for observation $i$ in the dataset that has $n$ observations in total. Two key features:\n\n1. Add a constant, the mean changes by the same constant.\n2. Multiply by a constant, the mean changes by the same constant.\n\n## The Expected value\n\n- The expected value is the value that one can expect for a randomly chosen observation. It relates to the distribution of the population, not the sample\n- The notation for the expected value is $E[x]$.\n- For a quantitative variable, the expected value is the mean\n- For a qualitative variable, means are not defined, but you can consider proportions.\n\n## The median and other quantiles\n\n- The median is another statistic of central tendency. It indicates the middle value of the distribution. Its a special case of quantiles.\n  - Its main advantage with the mean is that it is less sensitive to extreme values. \n- **quantiles**: a quantile is the value that divides the observations in the dataset to two parts in specific proportions.\n  \n  $$Q_\\tau(Y) \\rightarrow \\frac{1}{N}\\sum I(y<Q_\\tau) = \\tau $$ \n\n- The median and 25th and 75th percentiles are the most common quantiles used in EDA.\n\n## The mode\n\n- Yet another measure of central tendency. \n- The mode is the value with the highest frequency in the data (the most common).\n- If distributions have multimodal, you may be able to obtain multiple modes.\n- Multiple modes are apart from each other, each standing out in its \"neighborhood\", but they may have different frequencies.\n\n## Summary\n\n- The mean, median and mode are different statistics for the central value of the distribution\n- They try to provide you the most representative value of the distribution.\n  - The mode is the most frequent value\n  - The median is the middle value\n  - The mean is the value that one can expect for a randomly chosen observation.\n\n```stata\ntabstat vars, stats(mean p50 )\nsummarize vars, detail\n```\n\n# Summary statistics: \nSpread and Shape \n\n## Spread of distributions\n\n- Spread of distributions is often used in analysis.\n  - It tells you how concentrated or dispersed the values of a variable are.\n- The statistics that measure the spread of distributions are the range, inter-quantile ranges, the standard deviation and the variance.\n\n## Ranges\n\nThere are three common measures of ranges:\n\n- The **range** is the difference between the highest value (the maximum) and the lowest value (the minimum) of a variable.\n- The **inter-quantile ranges** is the difference between two quantiles- the third quartile (the 75th percentile) and the first quartile (the 25th percentile). Can be used as an alternative to Standard deviation.\n- The **90-10** percentile range gives the difference between the 90th percentile and the 10th percentile.\n\n## Standard deviation\n\nThe most widely used measure of spread is the standard deviation, and Its square is the variance.\n\n$$\n\\begin{aligned}\nVar[x] &= \\frac{\\sum (x_i - \\bar{x})^2}{n}=S^2_x \\\\\nStd[x] &= \\sqrt{\\frac{\\sum (x_i - \\bar{x})^2}{n}}=S_x\n\\end{aligned}\n$$\n\n- The variance is less intuitive measure (Squared), but easier to work with (mean)\n- The SD captures typical (not Mean) differences from the mean. \n- For the same mean, higher SD means more volatility. \n\n## Coefficient of variation\n\nUnit Free alternative, Coefficient of variation: \n\n$$CV = \\frac{Std[x]}{\\bar{x}}\n$$\n\n- The coefficient of variation is the standard deviation divided by the mean. It reads, how much variation is there in the data relative to the mean.\n\n## Other uses for SD: Standardized values\n\nThe SD is often used to re-calculate differences between values in order to express them as typical distance.\n\n$$x_{standardized} = \\frac{(x - \\bar{x})}{Std[x]}\n$$\n\n- The standardized value has a mean of zero and a standard deviation of one.\n- Represents the difference from the mean in units of standard deviation.\n  - For example: a standardized value of one shows a value is one standard deviation larger than the mean; a standardized value of negative one shows a value is one standard deviation smaller than the mean\n\n## Distribution Shape: Skewness\n\n- A distribution is skewed if it isn't symmetric.\n  - It may be skewed in two ways, having a long left tail or having a long right tail.\n  - Example: hotel price distributions having a long right tail \n- Skewness and the presence of extreme values are related. \n- When extreme values are important for the analysis, skewness of distributions is important, too.\n\n## Skewness measures\n\nThere are two common measures of skewness:\n\n$$\nSk^1 = \\frac{(\\bar{x} - median(x))}{Std[x]} \\text{ and } Sk^2 = \\frac{\\sum(x_i-\\bar x)^3}{Std[x]^3}\n$$\n\n- When the distribution is symmetric its mean = median.\n- Skewed to the right $\\bar x > Q_{50}(x)$. \n- When a distribution is skewed with a long left tail the mean is smaller than the median\n- To make this measure comparable, better to **standardize** the measure\n- $SK^2$ is another Skewness measure. if Possitive, Skewed to the right, if negative, to the left.\n\n## Stata Corner: How to?\n\nTwo basic options to get summary statistics in Stata:\n\n- `summarize` command: provides basic statistics for all variables in the dataset. Include `detail` option for more statistics.\n- `tabstat` command: provides more flexibility. You can choose which statistics to show and for which variables.\n- use `estpost` to store the results and create well formatted tables.\n- See [Stata Summary Statistics](https://friosavila.github.io/chatgpt/stata_08_04_2024/) for examples on how to use these commands.\n\n## Visualizing summary statistics\n\n- As mentioned before Histograms are a good way to visualize the distribution of a variable.\n- However, if you would like to also visualize the summary statistics, you can use box plots\n- The box plot is a visual representation of many quantiles and extreme values.\n\n![](images/box-plot-construction.png){fig-align=center}\n\n## Box Plot\n\n::: {.panel-tabset}\n\n## Full Sample\n\n::: {#6a78052c .cell execution_count=10}\n``` {.stata .cell-code code-fold=\"true\"}\nuse data_slides/hotels-vienna.dta, clear\nqui:drop if price>800\ngraph box price, scale(1.4)  ///\n  ytitle(\"Price in dollars (log Scale)\") \n```\n\n::: {.cell-output .cell-output-display}\n![Box Plot: Viena prices](week03_files/figure-revealjs/cell-10-output-1.png){fig-pos='center'}\n:::\n:::\n\n\n## By Stars\n\n::: {#5c011404 .cell execution_count=11}\n``` {.stata .cell-code code-fold=\"true\"}\nuse data_slides/hotels-vienna.dta, clear\nqui:drop if price>800\n graph box price if stars>1, scale(1.4) ///\n  over(stars)  xsize(10) ysize(4) ///\n  ytitle(\"Price in dollars (log Scale)\")  \n```\n\n::: {.cell-output .cell-output-display}\n![Box Plot: Viena prices](week03_files/figure-revealjs/cell-11-output-1.png){fig-pos='center'}\n:::\n:::\n\n\n:::\n\n# Distributions (in Theory)\n\n## Theoretical distributions\n\n- **Theoretical distributions** are distributions of variables with idealized properties.\n\n- Theoretical distributions are fully captured by few parameters: these are statistics determine the whole distributions\n\n- For example, the normal distribution is fully captured by two parameters: the **mean** and the **standard deviation**.\n \n- They may not accomodate empirical data \n\n## Theoretical distributions\n\nTheoretical distributions can be helpful:\n\n- Have well-known properties!\n- In real life, many variables surprisingly close to theoretical distributions.\n- Will be useful when generalizing from data \n\n## The Normal distribution\n\n:::{.columns}\n\n:::{.column width=\"50%\"}\n\n- Histogram is bell-shaped\n- Outcome (event), can take **any** value\n- Distribution is captured by $\\mu$ the mean and $\\sigma$ the SD \n- Symmetric = median, mean (and mode) are the same.\n:::\n\n:::{.column width=\"50%\"}\n\n::: {#8362fdba .cell execution_count=12}\n\n::: {.cell-output .cell-output-display}\n![](week03_files/figure-revealjs/cell-12-output-1.png){fig-pos='center'}\n:::\n:::\n\n\n:::\n\n:::\n\n## The log-normal distribution\n\n:::{.columns}\n\n:::{.column width=\"50%\"}\n- Asymmetrically distributed with long right tails.\n  - Derived from a normally distributed variable (x), transform it: ($x^* = e^x$). The result is a distributed log-normal.\n- **Always non-negative**\n- Example distributions of income, or firm size.\n:::\n\n:::{.column width=\"50%\"}\n\n::: {#670b6b26 .cell execution_count=13}\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of observations (_N) was 0, now 10,000.\n(bin=40, start=.79124224, width=1.5880267)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](week03_files/figure-revealjs/cell-13-output-2.png){fig-pos='center'}\n:::\n:::\n\n\n:::\n\n:::\n\n## The Normality of Reality\n\n- Quite suprisingly, many variables tend to follow normal distributions.\n  - Especially when adding them up.\n- May not be a good approximation when\n  - There are reasons for non-symmetry (e.g. income)\n  - If extreme values are \"common\"\n- Variables are well approximated by the log-normal if they are the result of many things multiplied.\n\n# Extra: Data Vizualization\nData Viz\n\n## Data Visualization Essentials\n\n::: columns\n\n::: {.column width=\"50%\"}\n1. Purposeful Decision-Making\n   - Avoid default settings\n   - Define purpose, focus, and audience\n   - Choose appropriate graph type\n\n2. Key Considerations\n   - Data type (qualitative, quantitative, time series)\n   - Formatting (colors, fonts, sizes)\n   - Essential elements: title, axis labels, legend\n\n:::\n\n::: {.column width=\"50%\"}\n\n3. One Graph, One Message\n   - Tailor complexity to audience (general vs. specialist)\n   - Be explicit about purpose and target audience\n\n:::\n\n:::\n\n## Data Visualization Process\n\n::: columns\n\n\n::: {.column width=\"50%\"}\n1. Planning\n   - Determine content and audience\n   - Select graph type and elements\n   - Seek help when needed (AI, online resources)\n\n2. Execution\n   - Include supporting elements for understanding\n   - Ensure readability (use `scale()` function)\n\n:::\n\n::: {.column width=\"50%\"}\n\n3. Essential Components\n   - Title (if not in the document)\n   - Axis titles and labels (what's being measured)\n   - Legend (group explanations)\n\n4. Final Check\n   - Verify all elements support the main message\n   - Confirm graph is clear and accessible to the audience\n\n:::\n:::\n\nSee [DataViz](https://friosavila.github.io/chatgpt/stata_08_06_2024/) for a guide of how to create graphs in Stata.\n\n## AI and data exploration/Viz\n\n- AI is very good at describing the data, if you give it the tools (data)\n- Pretty good with `python`, but less proficient with `Stata` for complex graphs.\n\n- Still good to have someone to ask without judgement.\n  \n## Summary steps of EDA\n\n1. First focus on the most important variables. Go back to look at others if\nsubsequent analysis suggests to.\n2. For **qualitative** variables, list relative frequencies.\n3. For **quantitative** variables, look at histograms. May decide for transformation, learn about key aspects of data.\n4. Check for **extreme** values. Decide what to do with them.\n5. Look at **summary** statistics. It may prompt actions, such as focusing on some part of the dataset.\n6. Do further exploration if necessary (time series data, comparisons across groups of observations, correlations, etc.)\n\n# **BREAK**\n\n# Comparisons and Correlations\n\n## Motivation\n\n- Are larger companies better managed?\n\nAnswering this question may help in benchmarking management practices in a specific company, assessing the value of a company, or estimating the potential benefits of a merger between two companies.\n\nTo answer this question you downloaded data from the World Management Survey.\n\n- How should you use the data to measure firm size and the quality of management?\n- How should you assess whether larger companies are better managed?\n\n# A story of two variables\n\n## The $y$ and the $x$\n\n-   Much of data analysis is built on comparing values of a $y$ variable against one, or more, $x$ variables.\n-   Our job is to uncover the **patterns** of association:\n    -   How observations with particular values of one variable ($x$) tend have particular values of the other variable ($y$).\n-   The role of $y$ is different from the role of $x$.\n    -   We are **interested** in $y$\n    -   $X's$ are factors that you will use to analyze $y$.\n\n## The $y$ and the $x$\n\n-   This asymmetry comes from the goal of our analysis.\n-   **Goal 1**: predicting the value of a $y$ variable with the help of other variables - many $x$ variables, such as $x_1$, $x_2$,...\n    -   This is more useful when we do not know $y$ but know $x$.\n-   **Goal 2**: learn about the effect of a causal variable $x$ on an outcome variable $y$.\n-   Assuming everything else remains constant, What the value of $y$ would be if we could change $x$\n\n# Conditioning and conditional distributions\n\n## Comparison and conditioning\n\n-   Similar ideas: Comparison $\\rightarrow$ conditioning\n-   We ***compare*** $y$, by values of $x$ $\\rightarrow$ we ***condition*** y on x.\n    -   $x$ (by the values of which we make comparisons) $\\rightarrow$ conditioning variable.\n    -   $y$ $\\rightarrow$ outcome variable.\n-   Compare salaries of workers ($y$) with low and high level of education ($x$)\n    -   salary is the outcome\n    -   education is the conditioning variable.\n\n## Comparisons and conditional distributions\n\n::::: columns\n::: {.column width=\"50%\"}\n-   The **conditional distribution** of a variable is the distribution of the outcome variable given the conditioning variable: $f(y|X=x)$\n-   Straightforward if $x$ is qualitative (simple if binary)\n-   With quantitative variables, this definition is less intuitive.\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#863e93ce .cell execution_count=14}\n``` {.stata .cell-code code-fold=\"true\"}\nqui: use \"data_slides/hotels-vienna-london\", clear\ndrop if price > 1000\nset scheme white2\ncolor_style tableau\ntwo (kdensity price) ///\n(kdensity price if city==\"Vienna\") ///\n(kdensity price if city==\"London\"), ///\nlegend(order(1 \"All\" 2 \"Vienna\" 3 \"London\")) ///\nxtitle(\"Hotel Prices\") xsize(9) ysize(6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(395 observations deleted)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](week03_files/figure-revealjs/cell-14-output-2.png){fig-align='center'}\n:::\n:::\n\n\n:::\n:::::\n\n## Conditional statistic\n\nIf there is a Conditional distribution, there is a conditional statistic.\n\n-   Conditional Stat is the Stat of a variable for each value of the conditioning variable.\n    -   The conditional expectation of variable y for different values of variable $x$ is $E[y|x]$\n-   This is a **function**: for a value of $x$, the conditional expectation is the expected value of $y$ for observations that have that $x$ value\n-   It gives different values for different values of $x$.\n\n## Case Study - Management quality and firm size\n\n-   Question: Are larger Firms Better managed?\n-   Data: World Management Survey\n-   Answering this questions may help inform policy decisions.\n-   How to measure firm size and quality of management?\n\n## Case Study - Management quality and firm size\n\n-   Interviews by CEO/senior managers, based on that a score is given.\n    Average across different domains.\n\n    -   tracking and reviewing performance or\n    -   time horizon and breadth of targets, etc\n\n-   Normalized - standardized score\n\n-   Firm size: Consider three bins: small (100–199), medium (200–999), large (1000+)\n\n\n\n## Case Study - Management quality and firm size\n\n::::: columns\n::: {.column width=\"50%\"}\n\n::: {#724e5e1b .cell tbl-align='center' execution_count=16}\n\n\n|                      |         mean |          p50 |           sd |\n| -------------------- | :----------: | :----------: | :----------: |\n| Small                |         2.68 |         2.78 |         0.51 |\n| Medium               |         2.94 |         3.00 |         0.62 |\n| Large                |         3.19 |         3.08 |         0.55 |\n| Total                |         2.94 |         2.94 |         0.60 |\n| Observations         |          300 |              |              |\n\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#6c6aeb04 .cell tbl-align='center' execution_count=17}\n\n\n|              |        Small |       Medium |        Large |        Total |\n| ------------ | :----------: | :----------: | :----------: | :----------: |\n| 1            |        19.44 |         8.33 |         6.94 |        10.67 |\n| 2            |        37.50 |        28.85 |        26.39 |        30.33 |\n| 3            |        31.94 |        35.90 |        30.56 |        33.67 |\n| 4            |        11.11 |        21.79 |        27.78 |        20.67 |\n| 5            |         0.00 |         5.13 |         8.33 |         4.67 |\n| Total        |       100.00 |       100.00 |       100.00 |       100.00 |\n| *N*          |          300 |              |              |              |\n\n:::\n\n\n:::\n:::::\n\n## Other options\n\n-   Since $x$ is qualitative, and there are \"enough\" observations in each category, its also posible to plot the conditional distribution of $y$ for each value of $x$.\n\n``` stata\ntwo (histogram management ), by(firm_size) \ntwo (kdensity management ), by(firm_size) \ngraph box management, over(firm_size) intensity(30) \n```\n\n## Conditional and joint distributions\n\n-   The previous Design assume $x$ to be discrete (Made Discrete). But what if not? Too many values!.\n    -   Need to think about **joint** distributions\n-   The joint distribution of two variables shows the probabilities (frequencies) of each value combination of the two variables.\n-   A `scatter` plot is a two-dimensional graph with the values of each of the two variables measured on its two axes.\n-   Works better when dataset is relatively small.\n-   For larger samples, we can bin values, and use \"bin scatter\"\n-   Bin scatter shows conditional means for bins we created\n\n## Case Study - Management quality and firm size\n\n::::: columns\n::: {.column width=\"50%\"}\n\n::: {#026ab310 .cell execution_count=18}\n``` {.stata .cell-code code-fold=\"true\"}\nscatter management emp_firm, xtitle(\"Firm size\") ytitle(\"Management score\") ///\n  legend(off) scale(1.5) \n```\n\n::: {.cell-output .cell-output-display}\n![](week03_files/figure-revealjs/cell-18-output-1.png){fig-align='center'}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {#600d2488 .cell execution_count=19}\n``` {.stata .cell-code code-fold=\"true\"}\nsort emp_firm\nqui:drop2 emp_firm_bin emp_mean_bin\nxtile emp_firm_bin = _n, n(20)\nbysort emp_firm_bin: egen emp_mean_bin=mean(emp_firm)\nbysort emp_firm_bin:egen mean_mng=mean(management)\n\nscatter mean_mng emp_mean_bin, xtitle(\"Firm size\") ytitle(\"Management score\") ///\n  scale(1.5) legend(off) ylabel(1/5) ///\n  note(\"Using 20 bins\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nvariable emp_firm_bin not found\nvariable emp_mean_bin not found\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](week03_files/figure-revealjs/cell-19-output-2.png){fig-align='center'}\n:::\n:::\n\n\n:::\n:::::\n\n::: notes\nSome association shown.\nScatter not easy to read, bin-scatter shows positive (weak) association.\nNotice Scale of y-axis.\nFlat line for large firms\n:::\n\n## Other Options\n\n::: panel-tabset\n## Model Based Scatterplot\n\n::: {#361fed4c .cell execution_count=20}\n``` {.stata .cell-code code-fold=\"true\"}\ntwo (scatter management emp_firm) ///\n    (lfitci management emp_firm, fcolor(%30)), ///\n    xtitle(\"Firm size\") ytitle(\"Management score\") ///\n    legend(off) scale(1.5)\n```\n\n::: {.cell-output .cell-output-display}\n![](week03_files/figure-revealjs/cell-20-output-1.png){fig-align='center'}\n:::\n:::\n\n\n## Scale Change\n\n::: {#27a7f401 .cell execution_count=21}\n``` {.stata .cell-code code-fold=\"true\"}\nscatter management emp_firm, ///\n  xtitle(\"Firm size\") ytitle(\"Management score\") ///\n  xscale(log) scale(1.5) xlabel(100 250 500 1000 2000 3000 4000 5000)\n```\n\n::: {.cell-output .cell-output-display}\n![](week03_files/figure-revealjs/cell-21-output-1.png){fig-align='center'}\n:::\n:::\n\n\n:::\n\n# Statistical dependence\n\nCorrelation, NOT causation\n\n## Dependence and independence\n\n-   Dependence of two variables $y$ and $x$ means that the conditional distributions of $y|x$ changes with $x$\n    -   This is what we showed earlier\n-   Independence means the opposite: the distribution of $y|x$ is the **same**, regardless of the value of $x$.\n-   Dependence, may take many forms.\n    -   $y$ may be more or less spread out for different $x$ values.\n    -   the **mean** of $y$ is different for different $x$ values.\n\n$$E[y|X=x_1] \\neq E[y|X=x_2]$$\n\n## Mean dependence\n\n-   Mean-dependence: conditional expectation $E[y|x]$ varies with the value of $x$.\n-   Two variables are positively **mean-dependent** if the average of two variables increase together.\n-   Covariance and Correlation Coefficient are measures of mean **linear** dependence.\n    -   They measure the same thing, but the correlation coefficient is a standardized version of the covariance.\n\n## Covariance\n\nThe formula for the covariance between two variables $x$ and $y$ with n observations is:\n\n$$Cov[x, y] = \\frac{1}{n}\\sum_i (x_i - \\bar{x})(y_i - \\bar{y})\n$$\n\n-   The Covariance is the [average]{.red} of the product of the deviations of the two variables from their respective means.\n-   Positive covariance: positive deviations of $x$ go with positive deviations of $y$.\n-   Negative covariance: positive deviations of $x$ go with negative deviations of $y$.\n\n## The correlation coefficient\n\n$$Corr[x, y] = \\rho_{xy}= \\frac{Cov[x, y]}{Std[x]Std[y]}$$\n\n$$-1 \\leq Corr[x, y] \\leq 1$$\n\n-   The correlation coefficient is the standardized version of the covariance.\n-   It is bound to be between negative one and positive one.\n\n## Dependence, mean-dependence, correlation\n\n::: callout-note\nIf two variables are **independent**, they are also mean-independent, Thus $E[y|x] = E[y]$ of any value of x.\n:::\n\n::: incremental\n-   Is this true the other way around?\n    -   No, it is not.\n-   Special cases:\n    -   $\\rho = 0$ but mean dependence (Sqrt of x)\n    -   $\\rho = 0$ and mean independence but different spread of $y$ (*`Heteroskedasticity`*)\n:::\n\n## Case Study - Management quality, firm size, Industry\n\n| Industry               | Correlation | Observations |\n|:-----------------------|------------:|-------------:|\n| Auto                   |        0.50 |           26 |\n| Chemicals              |        0.05 |           69 |\n| Electronics            |        0.33 |           24 |\n| Food, drinks, tobacco  |        0.05 |           34 |\n| Materials, metals      |        0.32 |           50 |\n| Textile, apparel       |        0.29 |           43 |\n| Wood, furniture, paper |        0.28 |           29 |\n| Other                  |        0.44 |           25 |\n| All                    |        0.30 |          300 |\n\n: Measures of management quality and their correlation with size by industry\n\n# Latent Information\n\nSight beyond Sight\n\n## *Measuring* a latent concept\n\n-   Often a concept is hard, even impossible, to measure...directly\n-   We often call them **Latent variables**: A variable that is not observed nor can be measured.\n-   Examples:\n    -   Quality of management at a firm - it is a concept that may be measured with a collection of variables, not a single one of them\n    -   IQ - measured by a series of quiz-like questions.\n    -   Employment satisfaction - measured by a series of questions about the job\n-   How do you combine multiple observed variables\n\n## Condensing information\n\n-   Alternatives:\n\n    -   Use one observed variable only: perhaps the one that is the best measure\n    -   Use all variables individually\n    -   Summarize them into a single variable\n        -   Use a weighted average of all variables\n        -   Principal component analysis (PCA)\n        -   Latent variable analysis, ETC\n\n## Using a single variable (or a few)\n\n-   Using one measured variable and exclude the rest has the advantage of easy interpretation.\n    -   The others could be used for robustness checks\n-   It has the **disadvantage** of discarding potentially useful information.\n-   But, can be often a sensible start\n\n## Using an \\[Weighted\\] Average\n\n-   Taking the average of all measured variables makes use of all information.\n\n$$\\bar{z_i} = \\frac{1}{k}\\sum_{j=1}^k z_i^j \\text{ or }\n\\bar{z_i} = \\frac{\\sum_{j=1}^k w_j \\times z_i^j}{\\sum_{j=1}^k w_j}\n$$\n\n-   All should be measured in the same Scale. Simple and a natural interpretation\n\n\n-   You can also use weights to give more importance to some variables than others.\n\n-   Or can use sub-groups indices to create a composite index.\n\n## Using an \\[Weighted\\] Average\n\n-   **IMPORTANT**: All variables should be measured in the same scale.\n    -   Otherwise, the average would be meaningless.\n-   Thus, need bring it to common scale.\n    -  **standardization**: Z-score\n$$\\tilde z_i^j = \\frac{z_i^j - \\bar{z}}{s_{z}}$$\n    -  0-1 scale: Min-Max scaling\n    $$\\tilde z_i^j = = \\frac{z_i^j - \\min(z^j)}{\\max(z^j) - \\min(z^j)}$$\n\n:::{.notes}\n\nYou may also want to consider using same units (dollars)\nor use transformations (logs)\n\n:::\n\n## Let the 🖥️ decide\n\n> Some times you may need to use other methods to combine variables. **Machine learning **methods! \n\n- Principal component analysis **(PCA)** is a method used for Data Reduction. Get weights to combine variables.\n- The weights are constructed based on how correlated variables are. (high correlation, high weight)\n- A Bit of black box method. But commonly used in practice: Wealth index, etc.\n\n```Stata\npca var1 var2 var3 .. , components(#)\npredict pca\n``` \n- Can give odd results\n\n## What to use?\n\n-   Z-scores, and averages, are simple, easy to understand, -   Transparent\n-   Typically marginally different to PCA (Try both)\n-   But, Need to pay attention\n    - Look at correlation signs, you may check it first (PCA is better here) (EDA. Do signs make sense?)\n    -   Sensitive to extreme values (But can be fixed)\n\n## Case Study - Management quality and firm size\n\n-   The latent concept here is the overall quality of management, but we have 18 variables that measure different aspects of management.\n-   Each were measured on a scale of 1 (worst practice) to 5 (best practice).\n-   Lets use Simple Average and PCA to create a composite index.\n\n## Stata Corner\n\n::: {#0119b75b .cell execution_count=22}\n``` {.stata .cell-code code-fold=\"false\"}\nuse \"data_slides\\wb-mx-management.dta\", clear\n** Simple mean\negen mng_mean = rowmean(perf* talent* lean*)\n** PCA\npca perf* talent* lean*, components(1)\npredict mng_pca\nlabel var mng_mean \"Management Score (Mean)\"\nlabel var mng_pca \"Management Score (PCA)\"\n```\n:::\n\n\n## Scatter PCA vs Mean\n\n::: {#9aa82708 .cell execution_count=23}\n\n::: {.cell-output .cell-output-display}\n![](week03_files/figure-revealjs/cell-23-output-1.png){fig-align='center'}\n:::\n:::\n\n\nA Correlation analysis could also be useful to compare the two measures.\n\n# Sources of Variation\nNot all variables are created equal\n\n:::{.notes}\nWe have talked that to make comparisons you need variation. But not all variation is the same. \n:::\n\n## Comparison and variation in $x$\n\n-   Variation in the **conditioning** variable is necessary to make comparisons.\n  \n-   Example: to uncover the effect of price changes on sales you need **many** observations with **different** price values.\n-   Generalization: The more variation is there in the conditioning variable the better are the chances for comparison.\n    -   Because the more likely you can capture \"reality\"\n\n## Source of variation \n\n-   Not all variation is the same. you must ask:\n    -   Why is there variation in the conditioning variable?\n-   Depending on the source of variation, the interpretation of the comparison may be different.\n    -   Good variation: You can make causal statements\n    -   Bad variation: At best you can make correlation statements\n\n## The Good: Experimental data\n\n-   Say you have an intervention or treatment.\n    -   Some people get the treatment, others do not.\n-   In experimental data, there is controlled variation: a rule deciding treatment\n-   This is the best source of variation for causal analysis.\n    -   Differences in the outcome variable will be due to the treatment variable only.\n-   Example: drug trial\n    -   Medical experiment: some patients receive the drug while others receive a placebo (treatment/control)\n    -   Outcome is recovery from the illness or not\n    \n\n## The Bad? Observational data\n\n-   Most data used in business, economics and policy analysis are observational. \n-   In observational data, **no variable** is fully controlled.\n-   They are the results of decisions, choices, interactions, expectations, etc. (sources of variation)\n    - Some of this could be random (good) but not all\n-  You can still make comparisons, but you must be careful.\n    -   Any difference in the outcome variable could be for other reasons.\n    -   Does smoking cause cancer? Or are people who smoke more likely to have other habits that cause cancer?\n\n## Source of variation and causal analysis\n\n- **Experimental data**: - Easy - if conditioning variable is experimentally controlled - \n  - Made sure that differences in the outcome variable are due to that variable only \n  \n- **Observational data**: - Hard - many other things may be different when the value of the conditioning variable differs \n  - You must be careful in making causal statements\n\nHowever, There are -advanced- methods that can help identify causal relationships in observational data. (Advanced Econometrics)\n\n## AI and patterns\n\n-   GenAI is great to give you a first review of patterns – similar to a few lines of code, or panda profiler in Python\n-   judgment of correlation (weak, strong) is often wrong.\n-   you need to know what pattern to pursue\n-   Can ask to explain different metrics of dependence\n\n## Summary\n\n-   Be explicit about what $y$ and $x$ are in your data and how they are related to the question of your analysis.\n-   For qualitative variables, correlation can be shown by summarizing conditional probabilities (frequencies).\n-   For quantitative variables, scatterplots offer a visual insight to the pattern of the relationship.\n-   The correlation coefficient captures a simple measure of mean dependence.\n\n# Extra: Functional Forms\nThe LOG transformation\n\n## Functional form: ln transformation\n\n-   Often, quasi-nonlinear patterns can be approximated with $y$ or $x$ transformed by taking logs.\n-   When transformed by taking the natural logarithm, differences in variable values we approximate relative/percentage differences.\n\n$$ln(x + \\Delta x) - ln(x) \\approx \\frac{\\Delta x}{x}$$\n\n\n## Logarithmic transformation - interpretation\n\n-   $ln(x)$:  the natural logarithm of x\n    -   Often refered as $log(x)$ or $ln(x)$ but they are often the same\n-   This transformation \"compresses\" the distribution of x\n-   but:\n    -   $x$ needs to be a positive number\n    -   $ln(0)$ or $ln(-|x|)$ are not defined in $\\mathbb{R}$.\n-   Advantage: Log transformation allows for comparison in relative terms – percentages\n\n$$\\begin{aligned}\nln(a) - ln(b) &\\approx \\frac{a-b}{0.5(a+b)} \\\\\nln(1.01)-ln(1) &= 0.0099 \\approx 0.01 \\\\\nln(1.1)-ln(1) &= 0.095 \\approx 0.1\n\\end{aligned}\n$$\n\n\n## Logarithmic Functions of y and/or x\n\n- This transformation works well if $\\Delta x$ is small ($<0.3$)\n- For larger differences, relative differences need to be calculated by hand\n- A difference of 0.1 log units corresponds to a 10% difference\n- For larger differences, \n  - if log difference is +1.0, it corresponds to a +170% difference\n  - if log difference is -1.0, it corresponds to a -63% difference\n\n- This transformation will be used often in economics.\n\n",
    "supporting": [
      "week03_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}