{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Unconditional Quantile Regressions (and RIF's)\"\n",
        "subtitle: \"When we care about everyone\"\n",
        "author: Fernando Rios-Avila\n",
        "format:\n",
        "  revealjs: \n",
        "    slide-number: true\n",
        "    width: 1600\n",
        "    height: 900\n",
        "    code-fold: true\n",
        "    echo: true\n",
        "    css: styles.css  \n",
        "    highlight-style: github\n",
        "  pdf: default  \n",
        "execute:\n",
        "  freeze: true   \n",
        "---\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "As we saw last class, conditional quantile regressions have only one purpose:\n",
        "\n",
        "-   Analyze relationships between conditional distributions.\n",
        "\n",
        "This is a very useful tool!. As it allows you to move beyond Average relationships.\n",
        "\n",
        "-   How do people (who are not all average) would be affected by changes in $Xs$\n",
        "\n",
        "There is a limitation, however. The effects you may estimate, will depend strongly on model specification.\n",
        "\n",
        "-   This is similar to OVB. Changing covariates could drastically change the conditional distributions and associated coefficients\n",
        "\n",
        "What if, you are interested in distributional effects across the whole population! Not only a subsample?\n",
        "\n",
        "## $E(q(y|X))$ is not $Q(y)$\n",
        "\n",
        "- Common mistake when analyzing QRegressions: Make interpretations as if the average effects on the $qth$ conditional quantiles would be the same as the effect on the \"overall\" $qth$ quantile.\n",
        "\n",
        "- Except for few cases (when Quantile regressions are not relevant), CQ effects do not translate ***directly*** into Changes into the unconditional quantile.\n",
        "\n",
        "However, as a policy maker, this would be the most relevant estimand you may be interested in :\n",
        "\n",
        "-   How does improving education affect inequality?\n",
        "\n",
        "-   Would eliminating Unionization would increase wage inequality?\n",
        "\n",
        "-   Is there heterogeneity in consumption expenditure?\n",
        "\n",
        "However, going from Conditional to unconditional statistics (not only Q) is not always straight forward.\n",
        "\n",
        "## âŒšWait...What do we mean unconditional?\n",
        "\n",
        "One of the questions I read a lot regarding UQR is what do we mean unconditional?\n",
        "\n",
        "-   This is perhaps a someone poor choice of words.\n",
        "\n",
        "-   Anytime we estimate **ANY** statistic, we condition on something.\n",
        "\n",
        "    -   We condition on all individual characteristics (including errors)\n",
        "\n",
        "    -   We condition on groups characteristics (CQREG and CEF)\n",
        "\n",
        "    -   or, We condition on all characteristics (distributions). We happen to call this, unconditional statistics.\n",
        "\n",
        "-   This, however, ***does*** make a big difference in interpretation.\n",
        "\n",
        "## From Condition on Individuals,\n",
        "\n",
        "### to conditioning on Distributions\n",
        "\n",
        "$$\\begin{aligned}\n",
        "y_i &= b_0 + b_1 x_i + e_i + x_i e_i \\\\\n",
        "\\frac{dy_i}{dx_i}&=b_1 + e_i \\\\\n",
        "E(y_i|x_i=x) &= b_0 + b_1 x  \\\\\n",
        "\\frac{dE(y_i|x)}{dx}&=b_1 \\\\\n",
        "E(E(y_i|x_i=x))=E(y_i) &= b_0 + b_1 E(x_i)    \\\\\n",
        "\\frac{dE(y_i)}{dE(x_i)}&=b_1\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Same effects, but different interpretations (specially last one)\n",
        "\n",
        "## How are Unconditional effects Estimated?\n",
        "\n",
        "Consider any distributional statistic $v$, which takes as arguments, all observations, density distributions $f()$, or cumulative distributions $F()$.\n",
        "\n",
        "$$\n",
        "v = v(F_y) \\ or \\ v(f_y) \\ or \\ v(y_1, y_2, ...,y_n)\n",
        "$$\n",
        "\n",
        "And to simplify notation, lets say this function is defined as follows:\n",
        "\n",
        "$$\n",
        "v(f_y) = \\int_{-\\infty}^\\infty h(y,\\theta) f(y)dy \n",
        "$$\n",
        "\n",
        "This simply considers distributional statistics $v$ that can be estimated by simply integrating a transformation of $h(y,\\theta)$ given a set of parameters $\\theta$.\n",
        "\n",
        "But for now, lets consider only the Identify function $h(y,\\theta)=y$\n",
        "\n",
        "but...What about Controls??\n",
        "\n",
        "## Introducing controls\n",
        "\n",
        "Assume there is a joint distribution of function $f(y,x)$, then\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "f(y,x)&=f(y|x)f(x) \\\\\n",
        "f(y) &= \\int f(y|x) f(x) dx\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "And all together:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "v(f_y) &= \\int y \\int f(y|x) f(x) dx \\ dy \\\\\n",
        "v(f_y) &= \\iint y f(y|x) dy \\ f(x) dx  \\\\\n",
        "v(f_y) &= \\int  E(y|X) f(x) dx  \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## Or a bit more General\n",
        "\n",
        "$$\n",
        "v(f_y) = \\iint h(y,\\theta) f(y|x)f(x)dxdy\n",
        "$$ \n",
        "\n",
        "So, the statistic $v$ will change if:\n",
        "\n",
        "\\- We change the function $h$ or its parameters $\\theta$.\n",
        "\n",
        "\\- Assume some shocks that change the conditional $f(y|x)$\n",
        "\n",
        "\\- or the distribution of characteristics change!\n",
        "\n",
        "Note: \n",
        "$$f(y|x) \\sim \\beta \\text{ and }\n",
        "f(x) \\sim x\n",
        "$$\n",
        "\n",
        "## Again...How are Unconditional effects Estimated?\n",
        "\n",
        "In an ideal scenario, you simple get the data under two regimes (before and after changes in $x$), and do the following:\n",
        "\n",
        "$$\\Delta v = v(f'_y)-v(f_y)\n",
        "$$\n",
        "\n",
        "That is, just estimate the statistic in two scenarios ($f'$ and $f$), and calculate the difference. (impossible!)\n",
        "\n",
        "But there are (at least) three alternatives:\n",
        "\n",
        "1.  Using Reweighting approaches to \"reshape\" the data: $f(x)$ (non-parametric)\n",
        "2.  Identify $f(y|x)$ so one can simulate how $\\Delta X$ affect y\n",
        "3.  Focus on the statistic $v$ and indirectly identify the effects of interest. (RIF!)\n",
        "\n",
        "## Op1: Re-weighting {.scrollable}\n",
        "\n",
        "Consider the following\n",
        "\n",
        "- There is a policy such that you plan to improve education in a country. \n",
        "  \n",
        "  Every single person will have at least 7 years of education, and will have free access to two additional years of education if they want to.\n",
        "\n",
        "  In other words, characteristics change from $f(x) \\rightarrow g(x)$ . But you do not see this! \n",
        "  \n",
        "$$ v(g_y) = \\iint h(y,\\theta) f(y|x) \\color{red}{g(x)}dxdy $$\n",
        "\n",
        "##\n",
        "\n",
        "but perhaps, we could see this:\n",
        "\n",
        "$$\\hat v(g_y) = \\iint h(y,\\theta) f(y|x) \\color{red}{\\hat w(x)}f(x) dxdy\n",
        "$$\n",
        "\n",
        "if we can come up with a set of weights $\\color{red}{\\hat w(x)}$ such that $f(x)\\hat w(x)=g(x)$\n",
        "\n",
        "$$\n",
        "\\hat w(x) = \\frac{\\hat g(x)}{\\hat f(x)}\n",
        "$$\n",
        "\n",
        "## \n",
        "\n",
        "Simple, yet hard. Estimation of multivariate densities can be a difficult task.\n",
        "\n",
        "$$\n",
        "f(x) = h(x|s=0) ; g(x) = h(x|s=1) \n",
        "$$\n",
        "\n",
        "This makes things \"easier\".\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "h(x|s=k)  &= \\frac{h(x)p(s=k|x)}{p(s=k)} \\\\\n",
        "\\hat w(x)  \n",
        "         &= \\frac{h(x)p(s=1|x)}{h(x)p(s=0|x)}\\frac{p(s=0)}{p(s=1)} \\\\\n",
        "         &=\\frac{p(s|x)}{1-p(s|x)} \\frac{1-p(s)}{p(s)}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Easier to estimate conditional probabilities, (logit probit or other) than Densities\n",
        "\n",
        "## Example {.scrollable}\n",
        "\n",
        "Goal: Evaluate the impact of an increase in Fines on # of citations. (using reweighting)"
      ],
      "id": "56c2860b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| classes: larger\n",
        "*| code-fold: false\n",
        "webuse dui, clear\n",
        "** Create Fake Sample\n",
        "gen id = _n\n",
        "expand 2\n",
        "bysort id:gen smp = _n ==2\n",
        "** Now you have two of ever person. So lets do some Policy\n",
        "** Fines increase lower fines more than higher ones, up to 12\n",
        "** Here we have a simulation of a policy that increases fines\n",
        "replace fines = 0.1*(12-fines)+fines if smp==1"
      ],
      "id": "a31a680a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Estimation of Logit (or Probit) to estimate $p(s|x)$\n",
        "\n",
        "And estimate IPW weights"
      ],
      "id": "a2aca395"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| classes: larger\n",
        "*| code-fold: false\n",
        "** Estimate logit \n",
        "qui:logit smp c.fines##c.fines taxes i.csize college\n",
        "predict pr_smp\n",
        "gen wgt = pr_smp / (1-pr_smp) \n",
        "replace wgt = 1 if smp==1"
      ],
      "id": "6c107f98",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Have the IPW weights helped simulate the policy? "
      ],
      "id": "59fadbe3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| classes: larger\n",
        "*| code-fold: false\n",
        "set scheme white2\n",
        "color_style tableau\n",
        "xi:tabstat fines i.csize college  taxes [w=wgt],  by(smp)"
      ],
      "id": "346e25d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I can now compare the distribution of fines before and after the policy\n"
      ],
      "id": "2f261dd9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "two (kdensity citations if smp==0 ) ///\n",
        "    (kdensity citations if smp==0 [w=wgt]) /// \n",
        "    , legend(order(1 \"Before Policy\" 2 \"After Policy\"))"
      ],
      "id": "910c7eb7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seems to be a contraction of # citations:\n"
      ],
      "id": "fdec5e96"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| classes: larger\n",
        "display \"Before Policy\"\n",
        "tabstat citations if smp ==0, stats(p10 p25 p50 mean p75 p90  )\n",
        "display \"After Policy\"\n",
        "tabstat citations if smp ==0 [w=wgt],  stats(p10 p25 p50 mean p75 p90  )"
      ],
      "id": "35fadca0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Increasing fines  may reduce citations in about 1.3., but have almost no effect at the bottom of the distribution.\n",
        "\n",
        "What about Standard errors? Bootstrap! (logit and estimation, probably clustering at individual level)\n",
        "\n",
        "Easy to extend to other Statistics, but, can only provide results \"within\" support.\n",
        "\n",
        "## Op2: Model Conditional Distribution\n",
        "\n",
        "Say that you are interested in the same Policy, but do not trust re-weighting. Instead you want to model the Outcome, using some parametric or nonparametric analysis\n",
        "\n",
        "1.  Define your model. Should be feasible enough to accommodate changes in the conditional distribution. (one \"model\" for each $X's$ combination?)\n",
        "2.  Use the model to make predictions of your outcome (quite a few times). and summarize all results.\n",
        "\n",
        "Options for flexible mode?\n",
        "\n",
        "-   You can use Heteroskedastic OLS $y\\sim N(x\\beta,x\\gamma)$ and predict from here\n",
        "\n",
        "-   You can use CQregressions to simulate the results.\n",
        "\n",
        "One of this is similar to what we do in simulation analysis, and imputation. The other is similar to the work of [Machado Mata (2005)](https://onlinelibrary.wiley.com/doi/10.1002/jae.788) and [Melly(2005)](https://www.sciencedirect.com/science/article/pii/S0927537105000382). Where you invert the whole distribution \"globally\"\n",
        "\n",
        "## \n",
        "### Recipe\n",
        "\n",
        "- Model $Y=G(X,\\theta)$\n",
        "\n",
        "- Create a \"policy\" $X'=H(X)$\n",
        "\n",
        "- Predict $Y'=G(X',\\theta)$ and identify effect:\n",
        "  \n",
        "  $$\\Delta V(Y) = V(Y')-V(Y)$$\n",
        "\n",
        "- Repeat many times, and summarize results.\n",
        "\n",
        "## Example #1: Hetregress {.scrollable}\n",
        "\n",
        "```stata\n",
        "** Example for OPT2\n",
        "webuse dui, clear\n",
        "** Modeling OLS with heteroskedastic errors\n",
        "    hetregress citations fines i.csize college taxes ,  het(fines i.csize college taxes )\n",
        "    \n",
        "    \n",
        "------------------------------------------------------------------------------\n",
        "   citations | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n",
        "-------------+----------------------------------------------------------------\n",
        "citations    |\n",
        "       fines |   -6.18443   .3018298   -20.49   0.000    -6.776006   -5.592855\n",
        "             |\n",
        "       csize |\n",
        "     Medium  |   4.683941   .5028377     9.32   0.000     3.698397    5.669484\n",
        "      Large  |   9.655742   .5261904    18.35   0.000     8.624428    10.68706\n",
        "             |\n",
        "     college |   4.495635   .5283579     8.51   0.000     3.460072    5.531197\n",
        "       taxes |  -3.640864   .4938209    -7.37   0.000    -4.608735   -2.672993\n",
        "       _cons |   79.48011   3.118008    25.49   0.000     73.36892    85.59129\n",
        "-------------+----------------------------------------------------------------\n",
        "lnsigma2     |\n",
        "       fines |  -.5261208    .082495    -6.38   0.000     -.687808   -.3644337\n",
        "             |\n",
        "       csize |\n",
        "     Medium  |    .331204   .1681709     1.97   0.049     .0015952    .6608129\n",
        "      Large  |   .5578834   .1662309     3.36   0.001     .2320768    .8836899\n",
        "             |\n",
        "     college |   .3186815   .1539424     2.07   0.038     .0169599    .6204032\n",
        "       taxes |  -.3988692   .1437708    -2.77   0.006    -.6806548   -.1170836\n",
        "       _cons |   8.257714   .8201063    10.07   0.000     6.650335    9.865093\n",
        "------------------------------------------------------------------------------\n",
        "LR test of lnsigma2=0: chi2(5) = 75.42                    Prob > chi2 = 0.0000\n",
        "\n",
        "\n",
        "**  make Policy\n",
        "clonevar fines_copy = fines\n",
        "replace fines = 0.1*(12-fines)+fines \n",
        "\n",
        "predict xb, xb\n",
        "predict xbs, sigma\n",
        "\n",
        "** Simulate results\n",
        "capture program drop sim1\n",
        "program sim1, eclass\n",
        "    capture drop cit_hat \n",
        "    gen cit_hat = rnormal(xb,xbs)   \n",
        "    qui:sum citations, d \n",
        "    local lp10 = r(p10)\n",
        "    local lp25 = r(p25)\n",
        "    local lp50 = r(p50) \n",
        "    local lpmn = r(mean)\n",
        "    local lp75 = r(p75)\n",
        "    local lp90 = r(p90)\n",
        "    qui:sum cit_hat, d \n",
        "    matrix b = r(p10)-`lp10',r(p25)-`lp25', r(p50)-`lp50' , r(mean) -`lpmn',r(p75)-`lp75',r(p90)-`lp90'\n",
        "    matrix colname b = p10 p25 p50 mean p75 p90\n",
        "    ereturn post b\n",
        "end\n",
        "\n",
        "simulate, reps(1000): sim1\n",
        "sum\n",
        "\n",
        "-------------+---------------------------------------------------------\n",
        "      _b_p10 |      1,000    -1.08147    .3913698   -2.31713   .1689796\n",
        "      _b_p25 |      1,000   -.3262908    .3230118  -1.817808   .6465259\n",
        "      _b_p50 |      1,000   -.2085465     .316455   -1.09237   .7785921\n",
        "     _b_mean |      1,000   -1.675626    .2234377  -2.400322   -1.03909\n",
        "      _b_p75 |      1,000   -1.541725    .4210822  -2.857586  -.2505198\n",
        "-------------+---------------------------------------------------------\n",
        "      _b_p90 |      1,000   -3.543298    .6079578  -5.464802  -1.682991\n",
        "```\n",
        "\n",
        "Effects larger than Reweigthing. Statistical inference here may be flawed. (first stage error not carried over)\n",
        "\n",
        "## Example #2: Qregress {.scrollable}\n",
        "\n",
        "```stata\n",
        "webuse dui, clear\n",
        "gen id = _n\n",
        "** Expand to 99 quantiles\n",
        "expand 99 \n",
        "bysor id:gen q=_n\n",
        "** make policy\n",
        "gen fines_policy=0.1*(12-fines)+fines \n",
        "gen fines_copy  =fines \n",
        "** Estimate 99 quantiles (in theory one should do more..but choose at random)\n",
        "ssc install qrprocess // Faster than qreg\n",
        "** Save Cit hat (prediction)\n",
        "** cit policy (with policy)\n",
        "gen cit_hat=.\n",
        "gen cit_pol=.\n",
        "\n",
        "forvalues  i = 1 / 99 {\n",
        "    if `i'==1   _dots 0 0\n",
        "    _dots `i' 0\n",
        "    qui {\n",
        "        local i100=`i'/100\n",
        "        capture drop aux\n",
        "        qrprocess citations c.fines##c.fines  (i.csize college taxes) if q==1, q(`i100')\n",
        "        ** predicts the values as if they were in q100\n",
        "        predict aux\n",
        "        replace cit_hat=aux if q==`i'\n",
        "        drop aux\n",
        "        replace fines = fines_policy\n",
        "        predict aux\n",
        "        replace cit_pol=aux if q==`i'   \n",
        "        replace fines = fines_copy \n",
        "    }   \n",
        "}\n",
        "\n",
        " tabstat citations cit_hat cit_pol, stats(p10 p25 p50 mean p75 p90)\n",
        " \n",
        "   Stats |  citati~s   cit_hat   cit_pol\n",
        "---------+------------------------------\n",
        "     p10 |      11.5  10.70744  9.911633\n",
        "     p25 |        15  15.42857  14.27302\n",
        "     p50 |        20  21.15557  19.68303\n",
        "    Mean |    22.018   22.0002  20.31824\n",
        "     p75 |        27  27.65936  25.56173\n",
        "     p90 |      34.5  34.03413  31.39192\n",
        "----------------------------------------\n",
        "```\n",
        "\n",
        "Very demanding (computationally) and may only capture effects to the extend that we have good coverage of the distribution.\n",
        "\n",
        "Standard Errors...Bootstrapping. Perhaps use random quantile assignment, and may have problems near boundaries.\n",
        "\n",
        "## Opt 1 and 2: Comments\n",
        "\n",
        "- The first option allow you to estimate effects of changes in $f(x)$ on the unconditional distribution of $y$, and in consequence, the distributional statistics of interest.\n",
        "\n",
        "- The second option allows you to estiamte those effects by modeling the conditional distribution of $y$ or $E(y|x)$.\n",
        "\n",
        "They have limitations:\n",
        "\n",
        "1.  They both are limited to a single experiment. A different policy requires a change in the setup.\n",
        "2.  Reweighing is simple to apply, but has limitation on the type of policies. They all need to be within the support of $X$\n",
        "3.  Modeling the conditional distribution is a more direct approach, but more computationally intensive, specially for obtaining Standard errors.\n",
        "\n",
        "## Opt 3. Local Approximation: RIF regression\n",
        "\n",
        "The third approach was first introduced by [Firpo, Fortin and Lemieux 2009](https://www.jstor.org/stable/40263848), as a computationally simple way to analyze how changes in $X's$ affect the unconditional quantiles of $y$.\n",
        "\n",
        "This strategy was later extended to analyze the effects on a myriad of distributional statistics and rank dependent indices, as well as an approach to estimate distributional treatment effects. \n",
        "\n",
        "See [Rios-Avila (2020)](https://journals.sagepub.com/doi/pdf/10.1177/1536867X20909690).\n",
        "\n",
        "In contrast with other approaches, it can be used to analyze multiple types of policies without re-estimating the model. However the identification and interpretation needs particular attention.\n",
        "\n",
        "It also allows you to easily make Statistical inference. (except for quantiles...)\n",
        "\n",
        "## Opt 3. From ground up\n",
        "\n",
        "Reconsider the Original question. How do you capture the effect of changes of distribution of $x$ on the distribution of $y$.\n",
        "\n",
        "$$\n",
        "\\Delta v=v(G_y) - v(F_y) \n",
        "$$\n",
        "\n",
        "Now, assume that $G_y$ is just marginally different from $F_y$ (different in a very particular way)\n",
        "\n",
        "$$\n",
        "G_y(y_i) = (1-\\epsilon)F_y+ \\epsilon 1(y>y_i)\n",
        "$$\n",
        "\n",
        "This function puts just a bit more weight on observation $y_i$. Think of it as \"dropping\" a new person in the pool.\n",
        "\n",
        "If this is the case, the $\\Delta v(y_i)$ Captures how would the Statistic $v$ changes if the distribution puts just a bit extra weight on 1 observation. (this would be very small)\n",
        "\n",
        "## Opt 3. One more thing\n",
        "\n",
        "Lets Rescale it:\n",
        "\n",
        "$$\n",
        "IF(v,F_y,y_i) =lim_{\\epsilon \\rightarrow 0} \\frac{v(G_y(y_i))-v(F_y)}{\\epsilon}\n",
        "$$\n",
        "\n",
        "The **influence function** is a measure of direction of change, we should expect the statistic $v$ will have as we change $F_y \\rightarrow G_y$ .\n",
        "\n",
        "From here the RIF is just $RIF(v,F_y,y_i) = v + IF(v,F_y,y_i)$\n",
        "\n",
        "Which has some properties:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\int IF(v,F_y,y_i)f_ydy=0 &; \n",
        "\\int RIF(v,F_y,y_i)f_y dy=v \\\\\n",
        "v(F_y) \\sim N \\left(v(F_y),\\frac{\\sigma^2_{IF}}{N} \\right) &;\n",
        "\\int IF^2f_ydy =\\sigma^2_{IF}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## Opt 3. RIF Regression\n",
        "\n",
        "First:\n",
        "\n",
        "$$\n",
        "v(F_y) = \\iint RIF(v,F_Y,y_i) f(y|x)f(x)dy = \\int E(RIF(.)|x) f(x)\n",
        "$$\n",
        "\n",
        "From here is similar to Opt 3. Use ***some*** econometric model to estimate $E(RIF(.)|X)$, and use that to make predictions on how $v(F_y)$ would change, when there is a **distributional change** in $X$.\n",
        "\n",
        "RIF-OLS: Unconditional effect!\n",
        "\n",
        "$$\n",
        "RIF(v,F_y,y_i) = X\\beta+e  \\ \\rightarrow\\ \n",
        "E(RIF) = v(F_y) = \\bar X \\beta \\\\\n",
        "\\frac{dv(F_y)}{d\\bar X}=\\beta\n",
        "$$\n",
        "\n",
        "Logic. When $F_x$ changes, it will change the distribution of $F_y$, which will affect how the statistic $v$ will change. But, we can only consider changes in means! (and Var)\n",
        "\n",
        "## Why it works, and why it may not\n",
        "\n",
        "RIF regressions works by using a linear approximation of the statistic $v$ with the changes in $F_y$ which are caused by changes in $F_x$, proxied by changes in $\\bar X$.\n",
        "\n",
        "-   Changes at the individual $x_i$ are not interesting (in a population of 1million, what happens to person 99 may not be large enough to matter)\n",
        "\n",
        "Depending on the model specification, however, we may only be able to identify changes in first and second moments of the distribution of $x$. (Mean and variance).\n",
        "\n",
        "\\-\n",
        "\n",
        "However, as any linear approximation to a non-linear function, the approximations are BAD when the changes in $F_x$ are too large. The most relevant example...Dummies and treatment!\n",
        "\n",
        "## RIF-Reg and dummies\n",
        "\n",
        "Dummies are a challenge. At individual or conditional level, we usually consider changes from 0 to 1 (off or on).\n",
        "\n",
        "-   For unconditional effects this is not correct (too large of a change) (No-one treated vs All treated). Thus you need to change the question...Not on and off changes, but Changes in proportion of treated!\n",
        "\n",
        "    -   Very important. a 1% increase in pop treated is different if current treatment is 10% or 90%.\n",
        "\n",
        "-   However, its possible to restructure RIF regressions to be partially conditional (Rios-Avila and Maroto 2023) (Combines CQREG with UQREG)\n",
        "\n",
        "-   Similar problems are experienced if the change in continuous variables is large!\n",
        "\n",
        "    -   Minor point. How do you construct RIFs? (analytically and Empirically)\n",
        "\n",
        "## Example {.scrollable}\n",
        "\n",
        "``` stata\n",
        "webuse dui, clear\n",
        "**  Consider the policy change\n",
        "gen change_fines= 0.1*(12-fines)\n",
        "**  consider average change in fines.Since we are only considering this effect\n",
        "sum change_fines\n",
        "\n",
        "rifhdreg citations fines i.csize college taxes, rif(q(10)) \n",
        "est sto m1\n",
        "rifhdreg citations fines i.csize college taxes, rif(q(50)) \n",
        "est sto m2\n",
        "rifhdreg citations fines i.csize college taxes, rif(q(90)) \n",
        "est sto m3\n",
        "** This are Rescaled to show true effect\n",
        "rifhdreg citations fines i.csize college taxes, rif(q(10)) scale(.21048)\n",
        "est sto m4\n",
        "rifhdreg citations fines i.csize college taxes, rif(q(50)) scale(.21048)\n",
        "est sto m5\n",
        "rifhdreg citations fines i.csize collegetaxes, rif(q(90)) scale(.21048)\n",
        "est sto m6\n",
        "\n",
        ". esttab m1 m2 m3 m4 m5 m6, se mtitle(q10 q50 q90 r-q10 r-q50 r-q90) compress nogaps\n",
        "\n",
        "----------------------------------------------------------------------------------------\n",
        "                 (1)          (2)          (3)          (4)          (5)          (6)   \n",
        "                 q10          q50          q90        r-q10        r-q50        r-q90   \n",
        "----------------------------------------------------------------------------------------\n",
        "fines         -4.476***    -6.700***    -9.887***    -0.942***    -1.410***    -2.081***\n",
        "             (0.491)      (0.493)      (0.978)      (0.103)      (0.104)      (0.206)   \n",
        "1.csize            0            0            0            0            0            0   \n",
        "                 (.)          (.)          (.)          (.)          (.)          (.)   \n",
        "2.csize        4.603***     7.325***     6.370***     0.969***     1.542***     1.341***\n",
        "             (0.963)      (0.966)      (1.917)      (0.203)      (0.203)      (0.404)   \n",
        "3.csize        6.504***     13.54***     12.97***     1.369***     2.851***     2.729***\n",
        "             (0.914)      (0.917)      (1.820)      (0.192)      (0.193)      (0.383)   \n",
        "college        2.922**      5.948***     9.973***     0.615**      1.252***     2.099***\n",
        "             (0.890)      (0.892)      (1.771)      (0.187)      (0.188)      (0.373)   \n",
        "taxes         -3.279***    -3.303***    -8.319***    -0.690***    -0.695***    -1.751***\n",
        "             (0.842)      (0.844)      (1.676)      (0.177)      (0.178)      (0.353)   \n",
        "_cons          53.71***     81.04***     129.2***     11.30***     17.06***     27.20***\n",
        "             (4.964)      (4.977)      (9.880)      (1.045)      (1.048)      (2.080)   \n",
        "----------------------------------------------------------------------------------------\n",
        "N                500          500          500          500          500          500   \n",
        "----------------------------------------------------------------------------------------\n",
        "```\n",
        "\n",
        "\n",
        "## How Do they Compare\n",
        "\n",
        "![](resources/image-1421892762.png)\n",
        "\n",
        "## Other Considerations  {.scrollable}\n",
        "\n",
        "RIF Regressions are useful, but again, one must use them with care.\n",
        "\n",
        "-   Only Small changes! Larger changes may be meaningless\n",
        "\n",
        "Except for `Stata` (see rif and rifhdreg), the applications of RIF regressions outside Mean, Variance and Quantiles are non-existent. (paper?)\n",
        "\n",
        "-   For most Common Statistics, RIF's automatically provide correct Standard errors (which can be Robustized!). In fact, a simple **LR** can be considered as a special case of **RIF's**\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        " RIF(mean,y_i,F_y) &= y_i \\\\ \n",
        " RIF(variance,y_i,F_y) &= (y_i-\\bar y)^2 \\\\\n",
        "RIF(Q,y_i,F_Y) &= Q_y(\\tau) + \\frac{\\tau-1(y_i \\leq Q_y(\\tau))}{f_Y(y_i)}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Except for quantile related functions! ($f_y$ also needs estimation, thus errors!)\n",
        "\n",
        "##\n",
        "### Other Considerations\n",
        "\n",
        "-   Accounting for \"local\" unconditional effects beyond means require Center Polynomials:\n",
        "\n",
        "$$\n",
        "RIF(.,y) = b_0 + b_1 x + b_2 (x-\\bar x)^2+\\varepsilon\n",
        "$$\n",
        "\n",
        "-   Quantile treatment effects (on and off) are possible using PC-RIF (When you condition the distribution on just 1 variable)\n",
        "\n",
        "$$\n",
        "RIF(.,F_{Y|D},y) = b_0 + b_1 D+b_2 x + b_3 (x-\\bar x)^2+\\varepsilon\n",
        "$$\n",
        "\n",
        "## Final words on RIF\n",
        "\n",
        "Because this implementation uses LR, you can add Multiple Fixed effects as well. (with limitations)\n",
        "\n",
        "And you can skip LR all together, and model RIF using Other approaches! (which may be even better than OLS).\n",
        "\n",
        "# NEXT\n",
        "\n",
        "Truly going nonlinear. When $\\beta$ is no longer linear in $y$ (nor is the error)"
      ],
      "id": "c0dd3fb4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "nbstata",
      "language": "stata",
      "display_name": "Stata (nbstata)",
      "path": "C:\\Users\\Fernando\\AppData\\Roaming\\jupyter\\kernels\\nbstata"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}