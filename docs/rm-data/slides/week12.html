<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-07ba0ad10f5680c660e360ac31d2f3b6.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.33">

  <meta name="author" content="Fernando Rios-Avila">
  <meta name="dcterms.date" content="2024-11-19">
  <title>Econometrics MSC Levy – Probability and Classification</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-97edfe54b73ff960639f8ac44205bcc0.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Probability and Classification</h1>
  <p class="subtitle">Am I a man, or am I a muppet?</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Fernando Rios-Avila 
</div>
        <p class="quarto-title-affiliation">
            Levy Economics Institute
          </p>
    </div>
</div>

  <p class="date">November 19, 2024</p>
</section>
<section id="motivation" class="slide level2">
<h2>Motivation</h2>
<ul>
<li>Say you work for a consultancy agency helping a bank. You are asked to predict which firms will default on their loans.
<ul>
<li>What would be better: a model that predicts probabilities or a model that classifies firms into default or not default?</li>
<li>How do you use to decide which firms should get a loan.</li>
</ul></li>
<li>Companies need to assess the likelihood of their suppliers or clients staying in business, as it impacts their own operations.
<ul>
<li>How to use historical data on company exits, along with key features, to predict the probability of a company’s exit.</li>
</ul></li>
</ul>
</section>
<section id="previously-on-da" class="slide level2">
<h2>Previously on DA</h2>
<ul>
<li>In the previous weeks, we have covered the basics of prediction when the target is quantitative.
<ul>
<li>Almost stright forward: predict the value of the target. Consider many specifications and pick the best one.</li>
</ul></li>
<li>We also cover the basic of probability modeling
<ul>
<li>LPM, Logit and probit models: When your dependent variable is Binary.</li>
</ul></li>
<li>However, we have not fully cover how to use these models for prediction.</li>
</ul>
</section>
<section id="prediction-with-qualitative-target" class="slide level2">
<h2>Prediction with qualitative target</h2>
<ul>
<li>Consider cases where <span class="math inline">\(Y\)</span> is qualitative
<ul>
<li>Whether a debtor defaults (will default) on their loan</li>
<li>Email is spam or not</li>
<li>Game result is win / lose (no draw).</li>
</ul></li>
<li>For all this cases, the target (dep variable) is binary.</li>
<li>The question is: Given this, What is the best way to predict the target?
<ul>
<li>Predict the probability of “success” (default, spam, win)</li>
<li>or make a classification (default, spam, win) based on a probability.</li>
</ul></li>
</ul>
</section>
<section>
<section id="classification-the-extra-step" class="title-slide slide level1 center">
<h1>Classification: The extra step</h1>

</section>
<section id="the-process" class="slide level2">
<h2>The process</h2>
<ul>
<li>Predict probability: We have done this.
<ul>
<li>Predicted probability between 0 and 1 (logit, probit or LPM in extreme cases)</li>
<li>For each observation we predicted a probability. Often that is it.</li>
</ul></li>
</ul>
<p>if logit: <span class="math display">\[\Pr[y_i = 1|x_i] = \Lambda \times (\beta_0 + \beta_1x_i) = \frac{\exp (\beta_0 + \beta_1x_i)}{1 + \exp (\beta_0 + \beta_1x_i)}\]</span></p>
<ul>
<li><p>Thats it! You can probably go couple of steps further and use various specifications, as well as LASSO (for logit) to pick the best model.</p></li>
<li><p>Best model can still be picked based on RMSE, brier score or Calibration.</p></li>
</ul>
</section>
<section id="refresher-probability-models" class="slide level2">
<h2>Refresher: Probability Models</h2>
<ul>
<li><p>LPM - not this time: Predicted value MUST be between 0 and 1</p></li>
<li><p>Logit or probit (or other non-linear probability models)</p></li>
<li><p>Nonlinear probability models <span class="math display">\[\Pr[y_i = 1|x_i] = \Lambda(\beta_0 + \beta_1x_i) = \frac{\exp (\beta_0 + \beta_1x_i)}{1 + \exp (\beta_0 + \beta_1x_i)}\]</span></p>
<ul>
<li>Predicted probability between 0 and 1</li>
<li>Starts with a linear combination of the explanatory variables</li>
<li>Multiplies them with coefficients, just like linear regression</li>
<li>And then transforms that into something that is always between 0 and 1, the predicted probability.</li>
</ul></li>
</ul>
</section>
<section id="whats-new-with-binary-target" class="slide level2">
<h2>What’s New with Binary target?</h2>
<ul>
<li>The predicted Probability is not a value.</li>
<li>Desire to classify
<ul>
<li>assign 0 or 1</li>
<li>based on a probability that comes from a model</li>
<li>But how?</li>
</ul></li>
<li>We also need new measures of fit
<ul>
<li>Some based on probabilities</li>
<li>Others based on classification</li>
</ul></li>
</ul>
</section>
<section id="whats-not-new-with-binary-target" class="slide level2">
<h2>What’s NOT new with Binary target?</h2>
<ul>
<li>Need best fit
<ul>
<li>With highest external validity</li>
</ul></li>
<li>Usual worries: overfit
<ul>
<li>Cross-validation helps avoid worst overfit</li>
</ul></li>
<li>Models similar to those used earlier
<ul>
<li>Regression-like models (probability models)</li>
<li>Tree-based models (CART, Random Forest) &lt;- We will not cover this</li>
</ul></li>
</ul>
</section>
<section id="probability-prediction-and-process" class="slide level2">
<h2>Probability prediction and process</h2>
<ul>
<li>We build models to predict probability when:
<ul>
<li>aim is to predict probabilities – (Duh!)</li>
<li>aim is to classify (predict 0 or 1) – (we need probabilities first)</li>
</ul></li>
<li>Build models
<ul>
<li>several Logit models by domain knowledge</li>
<li>LASSO - Logit LASSO</li>
</ul></li>
<li>Pick the best model via cross-validation using RMSE / Brier score
<ul>
<li>Or other LOSS function, if you have one</li>
</ul></li>
</ul>
</section>
<section id="classification-process" class="slide level2">
<h2>Classification process</h2>
<ul>
<li>After you predict your conditional probability, you can make classifications based on some threshold or Rule.
<ul>
<li>For example if <span class="math inline">\(\Pr[y = 1] &gt; 0.5\)</span> then predict 1, otherwise predict 0</li>
<li>But we can choose any threshold. but how? (say top 10%?)</li>
</ul></li>
<li>We need to consider that we can make errors
<ul>
<li>False negative</li>
<li>False positive</li>
</ul></li>
<li>Thus we need to consider a threshold that minimizes the expected errors</li>
</ul>
</section>
<section id="classification-table-confusion-matrix" class="slide level2">
<h2>Classification Table: Confusion Matrix</h2>
<table class="caption-top">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(y_j = 0\)</span></th>
<th><span class="math inline">\(y_j = 1\)</span></th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\hat{y}_j = 0\)</span></td>
<td>TN</td>
<td>FN</td>
<td>TN + FN</td>
</tr>
<tr class="even">
<td>Predicted negative</td>
<td>(true negative)</td>
<td>(false negative)</td>
<td>(all classified negative)</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\hat{y}_j = 1\)</span></td>
<td>FP</td>
<td>TP</td>
<td>FP + TP</td>
</tr>
<tr class="even">
<td>Predicted positive</td>
<td>(false positive)</td>
<td>(true positive)</td>
<td>(all classified positive)</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>TN + FP</td>
<td>FN + TP</td>
<td>TN + FN + FP + TP</td>
</tr>
<tr class="even">
<td>(all actual negative)</td>
<td>(all actual positive)</td>
<td>(N, all observations)</td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="classification-table-making-errors" class="slide level2">
<h2>Classification Table: making errors</h2>
<table class="caption-top">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(y_j = 0\)</span></th>
<th><span class="math inline">\(y_j = 1\)</span></th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\hat{y}_j = 0\)</span></td>
<td>Predict firm stay</td>
<td>Predict firm stay</td>
<td>TN + FN</td>
</tr>
<tr class="even">
<td>Predicted negative</td>
<td>(Firm did stay )</td>
<td>(Firm exited )</td>
<td>(all classified stay )</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\hat{y}_j = 1\)</span></td>
<td>Predict firm exit</td>
<td>Predict firm exit</td>
<td>FP + TP</td>
</tr>
<tr class="even">
<td>Predicted positive</td>
<td>(Firm stayed )</td>
<td>(Firm did exit)</td>
<td>(all classified exit)</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>TN + FP</td>
<td>FN + TP</td>
<td>TN + FN + FP + TP</td>
</tr>
<tr class="even">
<td>(all actual stay )</td>
<td>(all actual exit)</td>
<td>(N, all observations)</td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="measures-of-classification" class="slide level2">
<h2>Measures of classification</h2>
<p>There are several measures of classification, each with a different focus.</p>
<ul>
<li>Accuracy <span class="math inline">\(=(TP+TN)/N\)</span>
<ul>
<li>The proportion of rightly guessed observations</li>
<li>Hit rate</li>
</ul></li>
<li>Sensitivity <span class="math inline">\(=TP / (TP+FN)\)</span>
<ul>
<li>The proportion of true positives among all actual positives</li>
<li>Probability of predicted <span class="math inline">\(y\)</span> is 1 conditional on <span class="math inline">\(y = 1\)</span></li>
</ul></li>
<li>Specificity <span class="math inline">\(= TN/(TN+FP)\)</span>
<ul>
<li>The proportion of true negatives among all actual negatives</li>
<li>Probability predicted <span class="math inline">\(y\)</span> is 0 conditional on <span class="math inline">\(y = 0\)</span></li>
</ul></li>
</ul>
</section></section>
<section>
<section id="theory-the-roc" class="title-slide slide level1 center">
<h1>Theory: The ROC</h1>
<p>Sensitivity vs Specificity</p>
</section>
<section id="measures-of-classification-1" class="slide level2">
<h2>Measures of classification</h2>
<ul>
<li>The key point is that there is a trade-off between making false positive and false negative errors.</li>
<li>This is the essential insight in classification</li>
<li>This can be expressed with specificity and sensitivity.</li>
</ul>
</section>
<section id="roc-curve" class="slide level2">
<h2>ROC Curve</h2>
<ul>
<li>The ROC curve is a popular graphic for simultaneously displaying specificity and sensitivity for all possible thresholds.</li>
<li>ROC: Receiver operating characteristic curve
<ul>
<li>Name from engineering</li>
</ul></li>
<li>For each threshold, we can compute confusion table <span class="math inline">\(\rightarrow\)</span> calculate sensitivity and specificity</li>
<li>Then, we can plot sensitivity vs 1-specificity for all thresholds
<ul>
<li>Horizontal axis: False positive rate (one minus specificity) = the proportion of FP among actual negatives</li>
<li>Vertical axis: is true positive rate (sensitivity) = proportion of TP among actual positives</li>
</ul></li>
</ul>
</section>
<section id="roc-curve-intuition" class="slide level2">
<h2>ROC Curve Intuition</h2>
<ul>
<li>Consider this:
<ul>
<li>If the threshold is 0, we predict all observations as 1. The sensitivity is 1, but the specificity is 0.</li>
<li>If the threshold is 1, we predict all observations as 0. The sensitivity is 0, but the specificity is 1.</li>
<li>The “ideal” threshold is somewhere in between.</li>
</ul></li>
<li>ROC curve shows how true positives and false positives increases relative to each other.</li>
</ul>
</section>
<section id="roc-curve-intuition-1" class="slide level2">
<h2>ROC Curve Intuition</h2>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">Random Covariate</a></li><li><a href="#tabset-1-2">Nof Children</a></li><li><a href="#tabset-1-3">Full Model</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<p><img data-src="images/paste-9.png"></p>
</div>
<div id="tabset-1-2">
<p><img data-src="images/paste-10.png"></p>
</div>
<div id="tabset-1-3">
<p><img data-src="images/paste-11.png"></p>
</div>
</div>
</div>
</section>
<section id="area-under-roc-curve" class="slide level2">
<h2>Area Under ROC Curve</h2>
<ul>
<li>ROC curve: the closer it is to the top left column, the better the (insample) prediction.</li>
<li>Area under ROC (AUC) curve summarizes quality of probabilistic prediction
<ul>
<li>For all possible threshold choices</li>
<li>Area <span class="math inline">\(=\)</span> 0.5 if random classification</li>
<li>Area <span class="math inline">\(&gt;\)</span> 0.5 if curve mostly over 45 degree line</li>
</ul></li>
<li>AUC is a good statistic to compare models
<ul>
<li>Defined from a non-threshold dependent model (ROC)</li>
<li>The larger the better</li>
<li>Ranges between 0 and 1.</li>
</ul></li>
</ul>
</section>
<section id="stata-corner" class="slide level2">
<h2>Stata Corner</h2>
<ul>
<li>Logit estimation: <code>logit y x1 x2 x3</code></li>
<li>Predict probabilities: <code>predict yhat, pr</code></li>
<li>Classification:
<ul>
<li><code>gen yhat_class = (yhat &gt; 0.5)</code></li>
<li><code>estat classification</code></li>
</ul></li>
<li>ROC curve: <code>lroc</code></li>
</ul>
</section>
<section id="model-selection-nr.1-probability-models" class="slide level2">
<h2>Model selection Nr.1: Probability models</h2>
<ul>
<li>Model selection when we have no loss function, based on probability models only
<ul>
<li>Predict probabilities (No actual classification)</li>
<li>Use predicted probability to calculate RMSE</li>
<li>Pick by smallest RMSE</li>
</ul></li>
<li>Or
<ul>
<li>Draw up ROC curve and get AUC, Pick the model with the largest AUC</li>
<li>More frequently used in practice</li>
<li>Less sensitive to class imbalance</li>
</ul></li>
<li>In practice, AUC is more frequently used</li>
</ul>
</section></section>
<section>
<section id="theory-classification-and-loss-function" class="title-slide slide level1 center">
<h1>Theory: Classification and loss function</h1>

</section>
<section id="how-we-make-classification-from-predicted-probability" class="slide level2">
<h2>How we make classification from predicted probability?</h2>
<ul>
<li>We set a threshold!</li>
<li>The process of classification
<ul>
<li>If probability of event is higher than this threshold<span class="math inline">\(\rightarrow\)</span> assign (predict) class 1; and 0 otherwise.</li>
</ul></li>
<li>Who sets the threshold?
<ul>
<li>Usually approximated by 0.5</li>
<li>or by the frequency of the event in the data</li>
</ul></li>
</ul>
</section>
<section id="classification-select-the-threshold-with-loss-function" class="slide level2">
<h2>Classification: select the threshold with loss function</h2>
<ul>
<li>Find optimal threshold with loss function.
<ul>
<li>A loss function is a dollar value assigned to false positive and false negative.</li>
<li>Most often the costs of FP and FN are very different.</li>
</ul></li>
</ul>
<p>Consider loss function</p>
<p><span class="math display">\[E[loss] = \Pr[FN] \times loss(FN) + \Pr[FP] \times loss(FP)\]</span></p>
<ul>
<li>In ideal case, the minimization of this suggests that optimal threshold is:</li>
</ul>
<p><span class="math display">\[\text{Threshold} = \frac{loss(FP)}{loss(FN) + loss(FP)}\]</span></p>
<ul>
<li>Or we can try finding the threshold that minimizes the expected loss using Cross-validation. (Software issue)</li>
</ul>
</section>
<section id="when-to-use-formula" class="slide level2">
<h2>When to use Formula</h2>
<ul>
<li>Formula
<ul>
<li>When dataset is “large”</li>
<li>When our model has a “good” fit <span class="math inline">\(\text{Threshold}_{\min E (loss)} = \frac{loss(FP)}{loss(FN) + loss(FP)}\)</span></li>
</ul></li>
<li>In practice
<ul>
<li>Pro: easy to use, often close enough</li>
<li>Con: not the best cutoff, especially for smaller data, and poorer model</li>
</ul></li>
</ul>
<!--
## Theory: Now, with trees

## Classification tree

-   Classification tree, predict the class (0/1)
-   Same: Building trees with recursive binary splitting
-   Different: prediction is not the mean of values, but the share of $y = 1$
    -   Probability$\leftrightarrow$Frequency
    -   Based on threshold
-   Different: Loss function

## New loss function

-   In a classification tree, the measure of fit is node impurity.
-   Extent to which nodes contain observations with both $y = 0$ and $y = 1$ or only $y = 0$ or $y = 1$.
-   A widely used measure is the Gini index of node impurity.
-   Let's consider a split, for node $m$, and let $\hat{p}_m$ represent the share of observations with $y = 1$. $\text{Gini} = 2\hat{p}_m(1 - \hat{p}_m)$
-   The index is very small if all observations have either $y = 0$ or all have $y = 1$.
-   The closer $\hat{p}_m$ to 0.5 the larger the value of the index.
-   Thus, a small value implies that the node is made up entirely of a single class.

## New loss function

-   It turns out so using the Gini index of node impurity or using MSE to find the best fit leads to the same result.
-   See Appendix Ch17.U2

## Random forest

-   Similar approach to regression trees
-   Do classification trees, on bootstrapped datasets, and aggregate them.
-   Often perform better than logit models.
-   Similarly to OLS vs Random Forest
    -   No need for model building
    -   Better probability prediction
    -   Slower
-   Boosting can also be used for binary $y$.

## Random forest: two options

-   Similar approach to regression trees
-   Do classification trees, on bootstrapped datasets, and aggregate them
-   Technically two options:
    -   Probability forest + threshold search with algorithm
    -   Classification forest + threshold formula

## Random forest: probability forest

Probability forest + threshold search / algo

-   Predicted probabilities
-   Use them to find threshold or use formula to classify
-   Aggregates the probability predictions of each tree by averaging them across all trees.
-   The model's predicted probabilities are simply these averages.
-   For predicting probabilities – this is the version to use.
-   For classification – can be used, too, by simply applying the optimal classification threshold to the predicted probabilities.

## Random forest

## Random forest: classification forest

Classification forest + threshold formula

-   Carries out the classification at the end of each individual tree + aggregates those classifications $\rightarrow$ final classification
-   Input formula based threshold as tuning parameter
-   For predicting probabilities, this is not a good approach.
-   For classification, this is the right model
-   For classification, we can use probability or classification forest.
-   Results tend to be very similar
-   We have to find the optimal classification threshold using a loss function.

## Random forest : key technical insight

-   Two options yield results that are very close
-   Not the same
-   Both are okay to use
-   Do not use "majority voting"!!!
-   Default for R classification random forest is $t = 0.5$. Python is better.
-   $\text{Loss}(FN) = \text{Loss}(FP)$ - Called "majority voting"
-   Seems convincing. But it's misleading!
-   Loss function could be anything!!!

## Random Forest summary

-   Random Forest works well for prediction when target is binary
-   May always use for probability prediction
-   Use for classification only with an explicit loss function
-->
</section>
<section id="class-imbalance" class="slide level2">
<h2>Class imbalance</h2>
<ul>
<li>A potential issue for some dataset - relative frequency of the classes.</li>
<li>Class imbalance = the event we care about is very rare or very frequent (<span class="math inline">\(\Pr(y = 1)\)</span> or <span class="math inline">\(\Pr(y = 0)\)</span> is very small)
<ul>
<li>Fraud, Sport injury</li>
</ul></li>
<li>What is rare?
<ul>
<li>Something like 1%, 0.1%. (10% should be okay.)</li>
<li>Depends on size: in larger dataset we can identify rare patterns better.</li>
</ul></li>
<li>Consequence: Hard to find those rare events.
<ul>
<li>You may be able to identify some patterns by chance.</li>
</ul></li>
</ul>
</section>
<section id="class-imbalance-the-consequences" class="slide level2">
<h2>Class imbalance: the consequences</h2>
<ul>
<li>Methods we use are <strong>not</strong> good at handling it.
<ul>
<li>Both for the models to predict probabilities, and for the measures of fit used for model selection.</li>
</ul></li>
<li>The functional form assumptions behind the logit model tend to matter more, the closer the probabilities are to zero or one.</li>
<li>Cross-validation can be less effective at avoiding overfitting with very rare or very frequent events if the dataset is not very big. (Many samples will not even have the event.)</li>
<li>Usual measures of fit can be less good at differentiating models.</li>
<li>Consequence: Model fitting and selection setup not ideal</li>
</ul>
</section>
<section id="class-imbalance-what-to-do" class="slide level2">
<h2>Class imbalance: what to do</h2>
<ul>
<li>What to do? Two key insights.
<ol type="1">
<li>Know when it’s happening, and be ready for poor performance.</li>
<li>May need an action: rebalance sample to help build better models</li>
</ol></li>
<li>Downsampling – randomly drop observations from frequent class to balance out more
<ul>
<li>Before: 100,000 observations 1% event rate (99,000 <span class="math inline">\(y = 1\)</span>, 1,000 <span class="math inline">\(y = 0\)</span>)</li>
<li>After 10,000 observations 10% event rate (9,000 <span class="math inline">\(y = 1\)</span>, 1,000 <span class="math inline">\(y = 0\)</span>)</li>
</ul></li>
<li>Over-sampling of rare events</li>
<li>try Smart algorithms: Synthetic Minority Over-Sampling Technique (SMOTE)
<ul>
<li>Create synthetic observations that are similar to the rare events</li>
<li>synthetic rare = Combination of rare and infrequent events</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="case-study" class="title-slide slide level1 center">
<h1>Case study</h1>

</section>
<section id="firm-exit-case-study-case-study-background" class="slide level2">
<h2>Firm exit case study: Case study: background</h2>
<ul>
<li>Banks and business partners are often interested in the stability of their customers.</li>
<li>Predicting which firms will be around to do business with is an important part of many prediction projects.</li>
<li>Working with financial and non-financial information, your task may be to predict which firms are more likely to default than others.</li>
<li>Goal: Predict corporate default - exit from the market.
<ul>
<li>We have to figure out and decide on target, features, etc.</li>
</ul></li>
</ul>
</section>
<section id="firm-exit-case-study-bisnode-firms-dataset" class="slide level2">
<h2>Firm exit case study: <code>bisnode-firms</code> dataset</h2>
<ul>
<li>Firm data</li>
<li>Many different type of variables
<ul>
<li>Financial, Management, Ownership, Status (HQ)</li>
</ul></li>
<li>Dataset is a panel data</li>
<li>Rows are identified by company id (comp-id) and year.</li>
<li><strong>We’ll focus on a cross-section of 2012.</strong></li>
</ul>
</section>
<section id="firm-exit-case-study-label-target-engineering" class="slide level2">
<h2>Firm exit case study: Label (target) engineering</h2>
<ul>
<li>Defining our target. There is no “exit” - we have to define it!</li>
<li>Option: If a firm is operational in year <span class="math inline">\(t\)</span>, but is not in business in <span class="math inline">\(t + 2\)</span> -&gt; Exit.</li>
<li>This definition is broad
<ul>
<li>Defaults / forced exit</li>
<li>Orderly closure</li>
<li>Acquisitions</li>
</ul></li>
</ul>
</section>
<section id="firm-exit-case-study-sample-design" class="slide level2">
<h2>Firm exit case study: Sample design</h2>
<ul>
<li>Look at a cross section in 2012
<ul>
<li>If alive in Year=2014, status_alive=1</li>
</ul></li>
<li>Keep if established in 2012</li>
<li>We do not care about all firms. Not very small and very large
<ul>
<li>Below 10 million euros</li>
<li>Above 1000 euros</li>
</ul></li>
<li>Hardest call: keep when important variables are not missing
<ul>
<li>Balance sheet like liquid assets</li>
<li>Ownership like foreign</li>
<li>Industry classification</li>
</ul></li>
<li>End with 19K observation, 20% default rate</li>
</ul>
</section>
<section id="firm-exit-case-study-features---overview" class="slide level2">
<h2>Firm exit case study: Features - overview</h2>
<ul>
<li>Key predictors
<ul>
<li>size: sales, sales growth</li>
<li>management: foreign, female, young, number of managers</li>
<li>region, industry, firm age</li>
<li>other financial variables from the balance sheet and P&amp;L.</li>
</ul></li>
<li>For financial variables, we use ratios (to sales or size of balance sheet).</li>
<li>Here it will turn out be important to look at functional form carefully, especially regarding financial variables.</li>
<li>Mix domain knowledge and statistics.</li>
<li>Plenty of analyst calls.</li>
</ul>
</section>
<section id="firm-exit-case-study-feature-engineering" class="slide level2">
<h2>Firm exit case study: Feature engineering</h2>
<ul>
<li>Growth rates
<ul>
<li>1 year growth rate of sales. Log difference.</li>
<li>Could use longer time period, but Lose observations<br>
</li>
</ul></li>
<li>Ownership, management info
<ul>
<li>Keep if well covered, impute some, but drop if key vars missing</li>
<li>Sometimes simplify (unless big data): <code>ceo_young = ceo_age_mod &lt;40  &amp; ceo_age_mod &gt;15</code></li>
</ul></li>
<li>Industry categories - need simplify</li>
<li>Foreign ownership - above a threshold</li>
<li>Numerical variables from balance sheet: Check functional form - logs, polynomials</li>
</ul>
</section>
<section id="firm-exit-case-study-feature-engineering-tools" class="slide level2">
<h2>Firm exit case study: Feature engineering tools</h2>
<ul>
<li>Check coverage (missing values)</li>
<li>Decide on imputation vs drop</li>
<li>Categorical (factor) variables</li>
<li>Numerical variables
<ul>
<li>Check functional form - logs, polynomials</li>
<li>Look at relationships in scatterplot, loess and decide</li>
</ul></li>
</ul>
</section>
<section id="firm-exit-case-study-feature-engineering-1" class="slide level2">
<h2>Firm exit case study: Feature engineering</h2>
<ul>
<li>May need to make cleaning steps.</li>
<li>Create binary variables (flags) when implementing changes to values.</li>
<li>When financial values are negative: replace with zero and add a flag to capture imputation.
<ul>
<li>Zeros will not work with logs.</li>
</ul></li>
<li>Annual growth in sales (difference in log sales) vs default
<ul>
<li>Try editing variables by Winsorizing and adding flags for extreme values.</li>
<li>Some ODD shapes due to extreme values.</li>
</ul></li>
</ul>
</section>
<section id="the-weird-shape" class="slide level2">
<h2>The Weird Shape</h2>

<img data-src="images/paste-12.png" class="r-stretch"></section>
<section id="firm-exit-case-study-winsorizing" class="slide level2">
<h2><img data-src="images/paste-13.png">Firm exit case study: Winsorizing</h2>
<ul>
<li>When edge of a distribution is weird…</li>
<li>Winsorizing is a process to keep observations with extreme values in sample
<ul>
<li>for each variable, we
<ul>
<li>identify a threshold value, and replace values outside that threshold with the threshold value itself</li>
<li>and add a flag variable.</li>
</ul></li>
</ul></li>
<li>Two ways to do it:
<ul>
<li>an automatic approach, where the lowest and highest 1 percent or 5 percent is replaced and flagged.</li>
<li>Pick thresholds by domain knowledge as well as by looking at lowess. Preferred.</li>
</ul></li>
</ul>
</section>
<section id="firm-exit-case-study-firm-sales-growth" class="slide level2">
<h2>Firm exit case study: Firm sales growth</h2>

<img data-src="images/paste-15.png" class="r-stretch"><ul>
<li>The winsorized value simply equals original value in a range and flat below/after.</li>
</ul>
</section>
<section id="case-study-firm-exit-model-features-1" class="slide level2">
<h2>Case study: firm exit: Model features 1</h2>
<ul>
<li><strong>Firm</strong>: Age of firm, squared age, a dummy if newly established, industry categories, location regions for its headquarters, and dummy if located in a big city.</li>
<li><strong>Financial 1</strong>: Winsorized financial variables: fixed, liquid (incl current), intangible assets, current liabilities, inventories, equity shares, subscribed capital, sales revenues, income before tax, extra income, material, personal and extra expenditure.</li>
<li><strong>Financial 2</strong>: Flags (extreme, low, high, zero - when applicable) and polynomials: Quadratic terms are created for profit and loss, extra profit and loss, income before tax, and share equity.</li>
<li><strong>Growth</strong>: Sales growth is captured by a winsorized growth variable, its quadratic term and flags for extreme low and high values.</li>
</ul>
</section>
<section id="firm-exit-case-study-model-features-2" class="slide level2">
<h2>Firm exit case study: Model features 2</h2>
<ul>
<li><strong>HR</strong>: For the CEO: female dummy, winsorized age and flags, flag for missing information, foreign management dummy; and labor cost, and flag for missing labor cost information.</li>
<li><strong>Data Quality</strong>: Variables related to the data quality of the financial information flag for a problem, and the length of the year that the balance sheet covers.</li>
<li><strong>Interactions</strong>: Interactions with sales growth, firm size, and industry.</li>
</ul>
</section>
<section id="firm-exit-case-study-models" class="slide level2">
<h2>Firm exit case study: Models</h2>
<p>Models (number of predictors)</p>
<ul>
<li>Logit M1: handpicked few variables (<span class="math inline">\(p = 11\)</span>)</li>
<li>Logit M2: handpicked few variables + Firm (<span class="math inline">\(p = 18\)</span>)</li>
<li>Logit M3: Firm, Financial 1, Growth (<span class="math inline">\(p = 35\)</span>)</li>
<li>Logit M4: M3 + Financial 2 + HR + Data Quality (<span class="math inline">\(p = 79\)</span>)</li>
<li>Logit M5: M4 + interactions (<span class="math inline">\(p = 153\)</span>)</li>
<li>Logit LASSO: M5 + LASSO (<span class="math inline">\(p = 142\)</span>)</li>
<li>Number of coefficients = N of predictors +1 (constant)</li>
</ul>
</section>
<section id="firm-exit-case-study-data" class="slide level2">
<h2>Firm exit case study: Data</h2>
<ul>
<li><span class="math inline">\(N = 19,036\)</span></li>
<li><span class="math inline">\(N = 15,229\)</span> in work set (80%)</li>
<li>Cross validation 5x training + test sets
<ul>
<li>Used for cross-validation</li>
</ul></li>
<li><span class="math inline">\(N = 3,807\)</span> in holdout set (20%)
<ul>
<li>Used only for diagnostics of selected model.</li>
</ul></li>
</ul>
</section>
<section id="firm-exit-case-study-comparing-model-fit" class="slide level2">
<h2>Firm exit case study: Comparing model fit</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th></th>
<th>Variables</th>
<th>Coefficients</th>
<th>CV RMSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Logit M1</td>
<td>4</td>
<td>12</td>
<td>0.374</td>
</tr>
<tr class="even">
<td>Logit M2</td>
<td>9</td>
<td>19</td>
<td>0.366</td>
</tr>
<tr class="odd">
<td>Logit M3</td>
<td>22</td>
<td>36</td>
<td>0.364</td>
</tr>
<tr class="even">
<td><strong>Logit M4</strong></td>
<td><strong>30</strong></td>
<td><strong>80</strong></td>
<td><strong>0.362</strong></td>
</tr>
<tr class="odd">
<td>Logit M5</td>
<td>30</td>
<td>154</td>
<td>0.363</td>
</tr>
<tr class="even">
<td>Logit LASSO</td>
<td>30</td>
<td>143</td>
<td>0.362</td>
</tr>
</tbody>
</table>
<ul>
<li>5-fold cross-validated on work set, average RMSE</li>
<li>Will use Logit M4 model as benchmark</li>
</ul>
</section>
<section id="classification" class="slide level2">
<h2>Classification</h2>
<ul>
<li>Picked a model on RMSE/Brier score</li>
<li>For classification, we will need a threshold</li>
</ul>
</section>
<section id="firm-exit-case-study-roc-curve" class="slide level2">
<h2>Firm exit case study: ROC curve</h2>

<img data-src="images/paste-16.png" class="r-stretch"><ul>
<li>ROC curve shows trade-off for various values of the threshold</li>
<li>Go through values of the ROC curve for selected threshold values, between 0.05 and 0.75, by steps of 0.05</li>
</ul>
</section>
<section id="firm-exit-case-study-auc" class="slide level2">
<h2>Firm exit case study: AUC</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Model</th>
<th>RMSE</th>
<th>AUC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Logit M1</td>
<td>0.374</td>
<td>0.738</td>
</tr>
<tr class="even">
<td>Logit M2</td>
<td>0.366</td>
<td>0.771</td>
</tr>
<tr class="odd">
<td>Logit M3</td>
<td>0.364</td>
<td>0.777</td>
</tr>
<tr class="even">
<td><strong>Logit M4</strong></td>
<td><strong>0.362</strong></td>
<td><strong>0.782</strong></td>
</tr>
<tr class="odd">
<td>Logit M5</td>
<td>0.363</td>
<td>0.777</td>
</tr>
<tr class="even">
<td>Logit LASSO</td>
<td>0.362</td>
<td>0.768</td>
</tr>
</tbody>
</table>
<ul>
<li>Can calculate the AUC for all our models</li>
<li>Model selection by RMSE or AUC</li>
<li>Here: same (could be different if close)</li>
</ul>
</section>
<section id="firm-exit-case-study-comparing-two-thresholds" class="slide level2">
<h2>Firm exit case study: Comparing two thresholds</h2>
<ul>
<li>Take the Logit M4 model, predict probabilities and use that to classify on the holdout set</li>
<li>Two thresholds: 50% and 20%</li>
<li>Predict exit if probability &gt; threshold</li>
</ul>
</section>
<section id="firm-exit-case-study-comparing-two-thresholds-1" class="slide level2">
<h2>Firm exit case study: Comparing two thresholds</h2>
<table class="caption-top" style="width:100%;">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Threshold: 0.5</th>
<th></th>
<th></th>
<th>Threshold: 0.2</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td>Actual stay</td>
<td>Actual exit</td>
<td>Total</td>
<td>Actual stay</td>
<td>Actual exit</td>
<td>Total</td>
</tr>
<tr class="even">
<td>Predicted stay</td>
<td>75%</td>
<td>15%</td>
<td>90%</td>
<td>57%</td>
<td>7%</td>
<td>64%</td>
</tr>
<tr class="odd">
<td>Predicted exit</td>
<td>4%</td>
<td>6%</td>
<td>10%</td>
<td>22%</td>
<td>14%</td>
<td>36%</td>
</tr>
<tr class="even">
<td>Total</td>
<td>79%</td>
<td>21%</td>
<td>100%</td>
<td>79%</td>
<td>21%</td>
<td>100%</td>
</tr>
</tbody>
</table>
</section>
<section id="firm-exit-case-study-threshold-choice-consequences" class="slide level2">
<h2>Firm exit case study: Threshold choice consequences</h2>
<ul>
<li>Having a higher threshold leads to
<ul>
<li>fewer predicted exits:
<ul>
<li>10% when the threshold is 50% (36% for threshold 20%).</li>
</ul></li>
<li>fewer false positives (4% versus 22%)</li>
<li>more false negatives (15% versus 7%).</li>
</ul></li>
<li>The 50% threshold leads to a higher accuracy rate than the 20% threshold
<ul>
<li>50% threshold: 75% + 6% = 81%</li>
<li>20% threshold: 57% + 14% = 71%</li>
<li>even though the 20% threshold is very close to the actual proportion of exiting firms.</li>
</ul></li>
</ul>
</section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<p>First option: no loss fn</p>
<ul>
<li>On the work set, do 5 fold CV and loop over models</li>
<li>Do Probability predictions</li>
<li>Calculate average RMSE on test for each fold</li>
<li>Draw ROC Curve and calculate AUC for each fold</li>
<li>Pick best model based on avg RMSE</li>
<li>Take best model and estimate RMSE on holdout<span class="math inline">\(\rightarrow\)</span>best guess for live data performance</li>
<li>Output: probability ranking - most likely to least likely.</li>
<li>Show ROC curve and confusion table with logit on holdout 4 at <span class="math inline">\(t = 0.5\)</span> and <span class="math inline">\(t = 0.2\)</span> - to illustrate trade-off.</li>
</ul>
</section>
<section id="firm-exit-case-study-the-loss-function" class="slide level2">
<h2>Firm exit case study: The loss function</h2>
<ul>
<li>Loss function = FN, FP</li>
<li>What matters is FN/FP</li>
<li>FN=10
<ul>
<li>If the model predicts staying in business and the firm exits the market (a false negative), the bank loses all 10 thousand euros.</li>
</ul></li>
<li>FP=1
<ul>
<li>If predict exit and the bank denies the loan but the firm stays in business in fact (a false positive), the bank loses the profit opportunity of 1 thousand euros.</li>
</ul></li>
<li>With correct decisions, there is no loss.</li>
</ul>
</section>
<section id="firm-exit-case-study-finding-the-threshold" class="slide level2">
<h2>Firm exit case study: Finding the threshold</h2>
<ul>
<li>Find threshold by formula or algo</li>
<li>Formula: the optimal classification threshold is <span class="math inline">\(1/11 = 0.091\)</span></li>
<li>Algo: search thru possible cutoffs</li>
</ul>
</section>
<section id="firm-exit-case-study-finding-the-threshold-1" class="slide level2">
<h2>Firm exit case study: Finding the threshold</h2>
<ul>
<li>Consider all thresholds <span class="math inline">\(T = 0.01, 0.02—1\)</span></li>
<li>Calculate the expected loss for all thresholds</li>
<li>Pick when loss function has the minimum</li>
<li>Done in CV, this is fold Nr.5.</li>
</ul>
</section>
<section id="firm-exit-case-study" class="slide level2">
<h2>Firm exit case study</h2>
<ul>
<li>Model selection process
<ul>
<li>Predict probabilities</li>
<li>Use predicted probabilities and loss function to pick optimal threshold</li>
<li>Use that threshold to calculate expected loss</li>
<li>Pick model with smallest expected loss (in 5-fold CV)</li>
</ul></li>
<li>We run the threshold selection algorithm on the work set, with 5-fold cross-validation.</li>
<li>Best is model Logit M4</li>
<li>the optimal classification threshold by algo is 0.082. Close to formula (0.091)</li>
<li>The average expected loss of 0.64.</li>
</ul>
</section>
<section id="firm-exit-case-studysummary-of-process-with-loss-function" class="slide level2">
<h2>Firm exit case study:Summary of process with loss function</h2>
<ul>
<li>On the work set, do 5 fold CV and loop over models</li>
<li>Do Probability predictions</li>
<li>Calculate average RMSE on each test folds</li>
<li>Draw ROC Curve and find optimal threshold with loss function (1,10)
<ul>
<li>show: threshold search - loss plots and ROC curve for fold 5</li>
</ul></li>
<li>Summarize: for each model: average of optimal thresholds, threshold for fold 5, average expected loss, expected loss for fold Nr.5.</li>
<li>Pick best model based on average expected loss</li>
<li>Take best model, re-estimate it on work set + find optimal threshold and estimate expected loss on holdout set</li>
</ul>
<p>Here is the continued content in Quarto format:</p>
</section>
<section id="summary-1" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Decide whether the goal is predicting probabilities or classification.</li>
<li>The outcome of prediction with a binary target variable is always the predicted probabilities as a function of predictors.</li>
<li>When our goal is probability prediction, we should find the best model that predicts probabilities by cross-validation + RMSE/AUC.</li>
<li>When our goal is classification, we should find the best model that has the smallest expected loss.
<ul>
<li>With formula for threshold or search algorithm</li>
<li>Finding the optimal classification threshold needs a loss function.</li>
</ul></li>
</ul>
</section>
<section id="summary-2" class="slide level2">
<h2>Summary</h2>
<ul>
<li>Without a loss function, no classification.</li>
<li>If you don’t have one, make it up.</li>
<li>Don’t rely on default 0.5.</li>
</ul>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p><em>Rios-Avila and Cia</em></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1440,

        height: 810,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>