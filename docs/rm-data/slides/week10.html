<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.5.57">

  <meta name="author" content="Fernando Rios-Avila">
  <meta name="dcterms.date" content="2024-10-29">
  <title>Econometrics MSC Levy – Prediction Setup</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    padding-bottom: 0.5rem;
    margin-bottom: 0;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Prediction Setup</h1>
  <p class="subtitle">How far should we go?</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Fernando Rios-Avila 
</div>
        <p class="quarto-title-affiliation">
            Levy Economics Institute
          </p>
    </div>
</div>

  <p class="date">October 29, 2024</p>
</section>
<section id="motivation" class="slide level2">
<h2>Motivation</h2>
<ul>
<li><p>Imagine you want to sell your car soon and need to predict its price. You have data on similar used cars, and several regression models could help estimate its value now and in a year. How do you choose the best model?</p></li>
<li><p>Or, take an ice cream shop—using past sales and temperature data, you want to predict sales for the coming days. What factors should you consider to ensure your prediction is as accurate as possible?</p></li>
</ul>
</section>
<section id="prediction-basics" class="slide level2">
<h2>Prediction Basics</h2>
<ul>
<li><p>We start with original data (what we have) <span class="math inline">\(\rightarrow\)</span> to build a model</p></li>
<li><p>There is Live data (data we do not have yet)</p></li>
<li><p>The Target variable <span class="math inline">\(Y\)</span> (=dependent variable, response, outcome)</p></li>
<li><p>Predictor variables <span class="math inline">\(X\)</span> (= inputs, covariates, features, independent variables)</p></li>
<li><p>The goal is to predict value of <span class="math inline">\(Y\)</span> for target observation <span class="math inline">\(j\)</span> in live data</p>
<ul>
<li>Actual value for <span class="math inline">\(Y_j\)</span> unknown</li>
<li>but value for <span class="math inline">\(X_j\)</span> known</li>
<li>Need predicted value of <span class="math inline">\(Y\)</span> for each target observation <span class="math inline">\(j\)</span></li>
</ul></li>
</ul>
</section>
<section id="cs-price-cars" class="slide level2">
<h2>CS: Price cars</h2>
<ul>
<li>You want to sell your car through online advertising</li>
<li>Target is continuous (in dollars)</li>
<li>Features are continuous or categorical</li>
<li>The business question:
<ul>
<li>What price should you put into the ad?</li>
</ul></li>
</ul>
</section>
<section id="cs-price-apartments" class="slide level2">
<h2>CS: Price apartments</h2>
<ul>
<li>You are planning to run an AirBnB business
<ul>
<li>Maybe several rooms</li>
</ul></li>
<li>Target is continuous (in dollars)</li>
<li>Features are varied from text to binary</li>
<li>The business question:
<ul>
<li>How should you price apartments/houses?</li>
</ul></li>
</ul>
</section>
<section id="cs-predict-companys-exit-from-business" class="slide level2">
<h2>CS: Predict company’s exit from business</h2>
<ul>
<li>You have a consulting company</li>
<li>Predict which firms will go out of business (exit) from a pool of partners</li>
<li>Target is binary: exit / stay</li>
<li>Features of financial and management info</li>
<li>Business decision:
<ul>
<li>Which firms to give loan to?</li>
</ul></li>
</ul>
</section>
<section id="predictive-analysis-what-is-new" class="slide level2">
<h2>Predictive Analysis: what is new?</h2>
<ul>
<li>Most of econometrics focused on finding relationships between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>
<ul>
<li>What is the relationship like (+/-, linear, etc.)</li>
<li>Is it a robust relationship – true in the population /general pattern? (causal?)</li>
</ul></li>
<li>Now, we use <span class="math inline">\(x_1, x_2, \dots\)</span> to predict <span class="math inline">\(y\)</span>: <span class="math inline">\(\hat{y}_j = \hat{f}(x_j)\)</span></li>
<li>How is this different?</li>
</ul>
<div class="fragment">
<ul>
<li>We care less about
<ul>
<li>Individual coefficient values, multicollinearity</li>
</ul></li>
<li>We still care about the stability of our results.</li>
<li>Should we care about causality?
<ul>
<li>Not so much, we care more about making the best prediction.</li>
</ul></li>
</ul>
</div>
</section>
<section>
<section id="different-types-of-prediction" class="title-slide slide level1 center">
<h1>Different types of prediction</h1>

</section>
<section id="what-are-we-predicting" class="slide level2">
<h2>What are we predicting?</h2>
<ul>
<li><span class="math inline">\(Y\)</span> is quantitative (e.g price)
<ul>
<li>Quantitative prediction</li>
<li>“Regression” problem</li>
</ul></li>
<li><span class="math inline">\(Y\)</span> is binary (e.g.&nbsp;Default or nor)
<ul>
<li>Probability prediction</li>
<li>Classification problem</li>
<li>Broadly: <span class="math inline">\(Y\)</span> takes values in a finite set of (unordered) classes (survived/died, sold/not sold, car model)</li>
</ul></li>
<li>Time series prediction (Forecasting). Make predictions about the future based on historical and current data.</li>
</ul>
</section>
<section id="what-is-different" class="slide level2">
<h2>What is Different?</h2>
<ul>
<li>Feature engineering (variable selection) including variable selection, coding and functional form</li>
<li>Model building and prediction
<ul>
<li>Decision regarding model complexity and estimation
<ul>
<li>Remember splines, polynomials</li>
</ul></li>
<li>Machine learning methods
<ul>
<li>Automated model selection under some conditions</li>
</ul></li>
</ul></li>
<li>Model evaluation and selection
<ul>
<li>Compare models based on some measure of fit</li>
</ul></li>
<li>Key idea: Focus on systematically combine estimation and model selection</li>
</ul>
</section>
<section id="supervised-machine-learning-technique-regression" class="slide level2">
<h2>Supervised Machine Learning Technique: Regression</h2>
<ul>
<li>Linear regression produces a predicted value for the dependent variable.
<ul>
<li><strong>Predictions</strong>: are the expected value of <span class="math inline">\(y\)</span> if we know <span class="math inline">\(x\)</span>.</li>
</ul></li>
<li>Linear regression with <span class="math inline">\(y, x_1, x_2, etc.,\)</span>, is a model for the conditional expected value of <span class="math inline">\(y\)</span>, which provide us with <span class="math inline">\(\beta's\)</span>.</li>
<li>We need estimated coefficients <span class="math inline">\((\hat{\beta})\)</span> and actual <span class="math inline">\(x\)</span> values <span class="math inline">\((x_j)\)</span> to predict an actual value <span class="math inline">\(\hat{y}\)</span></li>
</ul>
<p><span class="math display">\[\begin{aligned}
y^E &amp;= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots \\
\hat{y}_j &amp;= \hat{\beta}_0 + \hat{\beta}_1 x_{1j} + \hat{\beta}_2 x_{2j} + \dots
\end{aligned}
\]</span></p>
</section>
<section id="the-prediction-error" class="slide level2">
<h2>The Prediction Error</h2>
<ul>
<li>The Regression model can produce a Predicted value <span class="math inline">\(\hat{y}_j\)</span> for target observation <span class="math inline">\(j\)</span></li>
<li>but, actual value <span class="math inline">\(y_j\)</span> is not known (that is why we are predicting)</li>
<li>Thus, there will be a prediction error</li>
</ul>
<p><span class="math display">\[e_j = \hat{y}_j - y_j
\]</span></p>
<ul>
<li>Error = actual value - predicted value</li>
</ul>
</section>
<section id="the-prediction-error-1" class="slide level2">
<h2>The Prediction Error</h2>
<ul>
<li>The <strong>ideal</strong> prediction error, is zero: our predicted value is right on target.</li>
<li>The prediction error is defined by the direction of miss and size.</li>
<li>Direction of miss:
<ul>
<li>Positive if we overpredict the value: we predict a higher value than actual value.</li>
<li>Negative if we underpredict the value: our prediction is too low.</li>
<li>Degree of wrongness depends on the decision problem.</li>
</ul></li>
<li>Size:
<ul>
<li>Larger in absolute value the further away our prediction is from the actual value.</li>
<li>It is smaller the closer we are.</li>
<li>It is always better to have a prediction with as small an error as possible.</li>
</ul></li>
</ul>
</section>
<section id="decomposing-the-prediction-error" class="slide level2">
<h2>Decomposing the prediction error</h2>
<p>Assume the best model for <span class="math inline">\(Y\)</span> is <span class="math inline">\(Y = f(X,Z,XZ) + \epsilon\)</span></p>
<ul>
<li>The prediction error can be decomposed into three parts:
<ol type="1">
<li><strong>estimation error</strong>: Difference between <span class="math inline">\(f(X,Z,XZ)\)</span> and <span class="math inline">\(\hat f(X,Z,XZ)\)</span></li>
<li><strong>model error</strong>: If we using <span class="math inline">\(f(X,Z)\)</span>, it would be the Difference between <span class="math inline">\(f(X,Z)\)</span> and <span class="math inline">\(f(X,Z,XZ)\)</span>.</li>
<li><strong>genuine error</strong>: error even if have the best possible model. <span class="math inline">\(\epsilon\)</span></li>
</ol></li>
</ul>
</section>
<section id="interval-prediction-for-quantitative-target-variables" class="slide level2">
<h2>Interval prediction for quantitative target variables</h2>
<ul>
<li>One advantage of regressions - it’s easy quantify uncertainty of prediction
<ul>
<li>This can be used to obtain <strong>Interval predictions</strong></li>
</ul></li>
<li>Interval predictions quantify 2-out-of-3 sources of prediction uncertainty: estimation error and genuine (or irreducible) error.</li>
<li>They do not include the third source, model uncertainty! (Bayesian methods can help with this)</li>
<li>The 95% prediction interval (PI) tells where to expect the actual value for the target observation.</li>
<li>The PI for linear regression requires homoskedasticity. (but could be relaxed)</li>
</ul>
</section></section>
<section>
<section id="the-loss-function" class="title-slide slide level1 center">
<h1>The Loss function</h1>
<p>Choosing the best</p>
</section>
<section id="loss-functions" class="slide level2">
<h2>Loss Functions</h2>
<ul>
<li>We use a Loss function to quantify the <strong>cost</strong> of prediction error
<ul>
<li>It attaches a value to the prediction error, specifying how <strong>bad</strong> it is</li>
<li>Thus, Loss function determines best predictor</li>
</ul></li>
<li>Ideally, it is derived from decision problem,
<ul>
<li>How much more costly is to overpredict than underpredict? (price is right!)</li>
<li>The shape and functional form could depent on the decision problem</li>
</ul></li>
<li>In practice, highly crafted loss functions are rare (Machine learning, Neural Networks, Etc), so we use common ones</li>
<li>Loss functions could be used to both estimate, but also to <strong>evaluate/compare</strong> models</li>
</ul>
</section>
<section id="loss-functions-1" class="slide level2">
<h2>Loss Functions</h2>
<ul>
<li>The most important Loss functions have the following characteristics:
<ul>
<li><strong>Symmetry</strong>: losses due to errors in opposing direction are similar
<ul>
<li><strong>Asymmetric loss</strong>: overprediction is more costly than underprediction</li>
</ul></li>
<li><strong>Convexity</strong>: Twice as large errors generate more than twice as large losses. (We penalize large errors more than small ones)
<ul>
<li><strong>Linear loss</strong>: Errors are penalized proportionally to their size</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="loss-functions-of-various-shapes" class="slide level2">
<h2>Loss Functions of Various Shapes</h2>
<div id="2d075875" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb1-1"><a></a><span class="kw">qui</span> {</span>
<span id="cb1-2"><a></a><span class="kw">clear</span></span>
<span id="cb1-3"><a></a><span class="kw">set</span> <span class="dv">scheme</span> white2</span>
<span id="cb1-4"><a></a>color_style tableau</span>
<span id="cb1-5"><a></a><span class="kw">set</span> <span class="kw">obs</span> 301</span>
<span id="cb1-6"><a></a><span class="kw">range</span> <span class="fu">r</span> -5 5 </span>
<span id="cb1-7"><a></a><span class="kw">gen</span> ll = <span class="fu">r</span>^2</span>
<span id="cb1-8"><a></a><span class="kw">gen</span> ll2 = 2*<span class="fu">abs</span>(<span class="fu">r</span>)</span>
<span id="cb1-9"><a></a><span class="kw">gen</span> ll3 = 1.5*<span class="fu">r</span>^2*(<span class="fu">r</span>&gt;0)+0.5*<span class="fu">r</span>^2*(<span class="fu">r</span>&lt;0)</span>
<span id="cb1-10"><a></a><span class="kw">drop</span> <span class="kw">if</span> ll&gt;30 | ll2&gt;30 | ll3&gt;30</span>
<span id="cb1-11"><a></a><span class="kw">line</span> ll ll2 ll3 <span class="fu">r</span>, lw(1 1 1) <span class="co">///</span></span>
<span id="cb1-12"><a></a>    <span class="bn">legend</span>(<span class="kw">order</span>(1 <span class="st">"Symetric-Convex"</span> 2 <span class="st">"Symetric-Linear"</span> 3 <span class="st">"Asymetric-Convex"</span>) )</span>
<span id="cb1-13"><a></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<style>div.jp-Notebook .datagrid-container {min-height: 448px; }</style>
</div>

</div>
<img data-src="week10_files/figure-revealjs/cell-2-output-2.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="examples-1-used-cars" class="slide level2">
<h2>Examples 1 – used cars</h2>
<ul>
<li>The loss function for predicting the value of our used car depends on how we value money and how we value how much time it takes to sell our car (value of your car).</li>
<li>A too low prediction may lead to selling our car cheap but fast;</li>
<li>A too high prediction may make us wait a long time and, possibly, revising the sales price downwards before selling our car.</li>
<li>What kind of loss function would make sense?</li>
</ul>
</section>
<section id="examples-2---creditors" class="slide level2">
<h2>Examples 2 - creditors</h2>
<ul>
<li>Creditors decide whether to issue a loan only to potential debtors that are predicted to pay it back with high likelihood.</li>
<li>Two kinds of errors are possible:
<ul>
<li>debtors that would pay back their loan don’t get a loan</li>
<li>debtors that would not pay back their loan get one nevertheless.</li>
</ul></li>
<li>The costs of the first error are due to missed business opportunity; the costs of the second error are due to direct loss of money.</li>
<li>These losses may be quantified in relatively straightforward ways.</li>
<li>What kind of loss function would make sense?</li>
</ul>
</section>
<section id="some-common-loss-functions" class="slide level2">
<h2>Some common loss functions</h2>
<p>Squared loss function:</p>
<p><span class="math display">\[L(e_j) = e^2_j = (\hat{y}_j - y_j)^2
\]</span></p>
<ul>
<li>The most widely used loss function</li>
<li>Symmetric: Losses due to errors in opposing direction are same</li>
<li>Convex: Twice as large errors generate more than twice (4x) as large losses</li>
</ul>
</section>
<section id="some-common-loss-functions-1" class="slide level2">
<h2>Some common loss functions</h2>
<p>Absolute loss function:</p>
<p><span class="math display">\[L(e_j) = e^2_j = Abs(\hat{y}_j - y_j)
\]</span></p>
<ul>
<li><p>Used for Median regression (Quantile regression)</p></li>
<li><p>Symmetric: Losses due to errors in opposing direction are same</p></li>
<li><p>Linear: Twice as large errors generate twice as large losses</p></li>
<li><p>Quantile Regressions use Asymetric loss functions</p></li>
</ul>
</section>
<section id="mean-squared-error-mse" class="slide level2">
<h2>Mean Squared Error: MSE</h2>
<ul>
<li>The most common way to quantify and aggregate the loss function is using the Mean Squared Error (MSE)</li>
<li>Squared loss <span class="math inline">\(\rightarrow\)</span> Mean Squared Error (MSE)</li>
</ul>
<p><span class="math display">\[\begin{align*}
\text{MSE} &amp;= \frac{1}{K} \sum_{k=1}^K (\hat{y}_k - y_k)^2 \\
\text{RMSE} &amp;= \sqrt{\text{MSE}} = \sqrt{\frac{1}{K} \sum_{k=1}^K (\hat{y}_k - y_k)^2}
\end{align*}
\]</span></p>
<ul>
<li>Using this function typically implies we are interested in the Mean as the best predictor</li>
</ul>
</section>
<section id="mse-decomposition-bias-and-variance" class="slide level2">
<h2>MSE decomposition : Bias and Variance</h2>
<ul>
<li><p>The MSE can be decomposed into two parts: <strong>Bias</strong> and <strong>Variance</strong> <span class="math display">\[\begin{align*}
MSE &amp;= \frac{1}{J}\sum_{j=1}^J (\hat{y}_j - y_j)^2 \\
&amp;= \left(\frac{1}{J}\sum_{j=1}^J (\hat{y}_j - y_j)\right)^2 + \frac{1}{J}\sum_{j=1}^J (\hat y_j - \bar{\hat y})^2 \\
&amp;= \text{Bias}^2 + \text{PredictionVariance}
\end{align*}
\]</span></p></li>
<li><p>The bias of a prediction is the average of its prediction error.</p>
<ul>
<li>How far off is the average prediction from the actual value?</li>
</ul></li>
<li><p>The variance of a prediction describes shows how it varies around its average.</p></li>
</ul>
</section>
<section id="mse-decomposition-bias-and-variance-1" class="slide level2">
<h2>MSE decomposition : Bias and Variance</h2>
<p><span class="math display">\[\begin{align*}
\text{MSE} &amp;= \frac{1}{K} \sum_{k=1}^K (\hat{y}_k - y_k)^2 \\
         &amp;= \left(\frac{1}{K} \sum_{k=1}^K (\hat{y}_k - \bar{y})\right)^2 + \frac{1}{K} \sum_{k=1}^K (y_k - \bar{y})^2 \\
         &amp;= \text{Bias}^2 + \text{PredictionVariance}
\end{align*}\]</span></p>
<ul>
<li>OLS is unbiased. Some other methods will allow for some bias in return for lower variance.</li>
</ul>
</section>
<section id="case-study-used-cars-data" class="slide level2">
<h2>Case study: used cars data</h2>
<ul>
<li>Suppose you want to sell your car of a certain make, type, year, miles, condition and other features.</li>
<li>The prediction analysis helps uncover the average advertised price of cars with these characteristics</li>
<li>That helps decide what price you may want to put on your ad.</li>
</ul>
</section>
<section id="case-study-used-cars-data-1" class="slide level2">
<h2>Case study: used cars data</h2>
<ul>
<li>Scraped from a website</li>
<li>Year of make (age), Odometer (miles)</li>
<li>Tech specifications such as fuel and drive</li>
<li>Dealer or private seller</li>
</ul>
</section>
<section id="case-study-loss-function" class="slide level2">
<h2>Case study: Loss function</h2>
<ul>
<li>The loss function for predicting the value of our used car depends on how we value money and how we value how much time it takes to sell our car.</li>
<li>A too low prediction may lead to selling our car cheap but fast;</li>
<li>A too high prediction may make us wait a long time and, possibly, revising the sales price downwards before selling our car.</li>
<li>Symmetric</li>
<li>Sensitive to big deviations</li>
<li>RMSE and OLS</li>
</ul>
</section>
<section id="case-study---used-cars-features" class="slide level2">
<h2>Case study - used cars: features</h2>
<ul>
<li>Odometer, measuring miles the car traveled (Continuous, linear)</li>
<li>More specific type of the car: LE, XLE, SE (missing in about 30% of the observations). (Factor – set of dummies , incl N/A)</li>
<li>Good condition, excellent condition or it is like new (missing for about one third of the ads). (Factor – set of dummies, incl N/A)</li>
<li>Car’s engine has 6 cylinders (20% of ads say this; 43% says 4 cylinders, and the rest has no information on this). (Binary for 6 cylinders)</li>
</ul>
</section>
<section id="case-study-models-by-hand" class="slide level2">
<h2>Case study: models by hand</h2>
<ul>
<li>Model 1: age, age squared</li>
<li>Model 2: age, age squared, odometer, odometer squared</li>
<li>Model 3: age, age squared, odometer, odometer squared, LE, excellent condition, good condition, dealer</li>
<li>Model 4: age, age squared, odometer, odometer squared, LE, excellent condition, good condition, dealer, LE, XLE, cylinder</li>
<li>Model 5: same as Model 4 but with all variables interacted with age (won’t show in next table)</li>
</ul>
</section>
<section id="case-study-car-price-model-results" class="slide level2">
<h2>Case study: Car price model results</h2>
<pre><code>(1)   (2)   (3)   (4)
Variables Model 1 Model 2 Model 3 Model 4
age     -1,530.09 -1,149.22 -873.47 -836.64
agesq    35.05   27.65   18.21   17.63
odometer           -303.84 -779.90 -788.70
odometersq                 18.81   19.20
LE                         28.11  -20.48
XLE                                301.69
SE                                1,338.79
cond_likenew                       558.67
cond_excellent                     176.49  190.40
cond_good                          293.36  321.56
cylind6                           -370.27
dealer                            572.98  822.65
Constant 18,365.45 18,860.20 19,431.89 18,963.35</code></pre>
</section>
<section id="case-study-results" class="slide level2">
<h2>Case study: Results</h2>
<ul>
<li>When doing prediction, coefficients are less important.</li>
<li>But we shall use them for sanity check: age negative, convex (flattens out)</li>
<li>SE may not be even displayed. It is helpful for model selection, but only along with other measures</li>
<li>and values of the predictor variables for our car: age = 10 (years), odometer= 12 (10 thousand miles), type= LE, excellent condition=1.</li>
<li>A point prediction, Model 3: age: -873.47, age squared=18.21, odometer -799.90, odometer sq = 18.81, LE=28.11, cond excellent: 176.49+ C=19.431.89</li>
<li>Predicted is price is 6073.</li>
</ul>
</section>
<section id="case-study-prediction-interval" class="slide level2">
<h2>Case study: Prediction Interval</h2>
<ul>
<li>Calculating prediction intervals for the baseline models</li>
<li>Very wide interval despite high R2</li>
<li>Prediction is hard!</li>
<li>Even with a good model, you’ll make plenty of errors</li>
<li>Should be aware</li>
<li>Let your clients know in advance…</li>
</ul>
</section>
<section id="case-study-prediction-interval-1" class="slide level2">
<h2>Case study: Prediction Interval</h2>
<p>Based on the third model, we have a point prediction of <span class="math inline">\(6073\)</span> Have a 80% prediction intervals (PI) – Ads for cars just like ours may ask a price ranging from <span class="math inline">\(4,317\)</span> to <span class="math inline">\(7,829\)</span> with a 80% chance.</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Model 1</th>
<th>Model 3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Point prediction 6,569</td>
<td>6,073</td>
</tr>
<tr class="even">
<td>Prediction Interval (80%) [4,296-8,843]</td>
<td>[4,317-7,829]</td>
</tr>
<tr class="odd">
<td>Prediction Interval (95%) [3,085-10,053]</td>
<td>[3,382-8,763]</td>
</tr>
</tbody>
</table>
<p>Note: Chicago cars. Prices in dollars. Source: used-cars dataset.</p>
</section>
<section id="model-selection" class="slide level2">
<h2>Model selection</h2>
</section>
<section id="data-for-prediction" class="slide level2">
<h2>Data for prediction</h2>
<ul>
<li>We have a dataset</li>
<li>We wanna make some prediction</li>
</ul>
</section>
<section id="model-selection-1" class="slide level2">
<h2>Model selection</h2>
<p>Model selection is finding the best fit while avoiding overfitting and aiming for high external validity</p>
</section>
<section id="external-validity-avoiding-overfitting-and-model-selection" class="slide level2">
<h2>External validity, avoiding overfitting and model selection</h2>
<ul>
<li>Have a dataset and a target variable. Compare various models of prediction.</li>
<li>How to choose a model?</li>
<li>Pick a model that can predict well….</li>
<li>Best prediction - best model that would produce the smallest prediction error.</li>
<li>Context of squared loss function <span class="math inline">\(\rightarrow\)</span> finding the regression that would produce the smallest RMSE for the target observations.</li>
<li>Pick a model that can predict well on the live data</li>
</ul>
</section>
<section id="underfit-overfit" class="slide level2">
<h2>Underfit, overfit</h2>
<ul>
<li>Comparing two models (model 1 and model 2)</li>
<li>Model 1 can give a worse fit in the live data than model 2 in two ways.
<ul>
<li>Model 1 may give a worse fit both in the original data and the live data. In this case, we say that model 1 underfits the original data.
<ul>
<li>Simple: we should build a better model.</li>
</ul></li>
<li>Model 1 may actually give a better fit in the original, but a worse fit in the live data. In this case, we say that model 1 overfits the original data.</li>
</ul></li>
</ul>
</section>
<section id="overfitting" class="slide level2">
<h2>Overfitting</h2>
<ul>
<li>Overfitting is a key aspect of external validity</li>
<li>finding a model that fits the data better than alternative models</li>
<li>but makes worse actual prediction.</li>
<li>Thus, the problem of overfitting the original data is best split into two problems:
<ul>
<li>fitting patterns in the original data that are not there in the population, or general pattern, it represents;</li>
<li>fitting patterns in the world of the original data that will not be there in the world of the live data.</li>
</ul></li>
</ul>
</section>
<section id="reason-for-overfitting" class="slide level2">
<h2>Reason for overfitting</h2>
<ul>
<li>The typical reason for overfitting is fitting a model that is too complex on the dataset.</li>
<li>Complexity: number of estimated coefficients</li>
<li>Often: fitting a model with too many predictor variables.</li>
<li>Including too many variables from the dataset that do not really add to the predictive power of the regression,</li>
<li>often because they are strongly correlated with other predictor variables.</li>
<li>Specifying too many interactions,</li>
<li>Too detailed nonlinear patterns
<ul>
<li>as piecewise linear splines with many knots</li>
<li>polynomials of high degree.</li>
</ul></li>
</ul>
</section>
<section id="increasing-model-complexity" class="slide level2">
<h2>Increasing model complexity</h2>
<ul>
<li>As we increase model complexity
<ul>
<li>Such as number of features (variables)</li>
<li>By adding interactions, etc.</li>
</ul></li>
<li>We will see
<ul>
<li>RMSE within dataset to fall monotonously</li>
<li>RMSE for target observations (ie. not in our dataset) to fall and then rise as we overfit</li>
</ul></li>
<li>example to come in class 2</li>
</ul>
</section>
<section id="finding-the-best-model-by-best-fit-and-penalty-the-bic" class="slide level2">
<h2>Finding the best model by best fit and penalty: The BIC</h2>
<ul>
<li>Approach 1: Indirectly</li>
<li>Estimate it by an adjustment</li>
<li>Use a method based on some distributional assumptions</li>
<li>Need to pick an evaluation criterion</li>
<li>=In-sample evaluation with penalty</li>
<li>Specify and estimate model using all data</li>
<li>Use a measure of fit that helps avoid overfitting
<ul>
<li>Such as
<ul>
<li>adjusted <span class="math inline">\(R^2\)</span></li>
<li>BIC = Bayesian Information Criterion, or Schwarz criterion</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="indirect-evaluation-criteria" class="slide level2">
<h2>Indirect evaluation criteria</h2>
<ul>
<li>Main methods: AIC, BIC and adjusted <span class="math inline">\(R^2\)</span></li>
<li>Advantage: easy to compute</li>
<li>Disadvantage: assumptions</li>
<li>Adjusted <span class="math inline">\(R^2\)</span> – just add a penalty for having many RHS vars
<ul>
<li>corrects with <span class="math inline">\((n - 1)/(n - p - 1)\)</span></li>
</ul></li>
<li>Akaike Information Criterion
<ul>
<li>AIC = <span class="math inline">\(-2 \times \ln(\text{likelihood}) + 2 \times k\)</span></li>
</ul></li>
<li>Schwarz – Bayesian Information Criterion
<ul>
<li>BIC = <span class="math inline">\(-2 \times \ln(\text{likelihood}) + \ln(N) \times k\)</span></li>
</ul></li>
<li>Both quantities that take the log likelihood and apply a penalty for the number of parameters being estimated.Both are based on information loss theory from the fifties.</li>
<li>BIC puts heavier penalty on models with many RHS variables, than AIC.</li>
</ul>
</section>
<section id="model-fit-evaluation" class="slide level2">
<h2>Model fit evaluation</h2>
<ul>
<li>Use a good measure of fit to compare models.</li>
<li>Don’t
<ul>
<li>Don’t use MSE or R-squared (the two very closely related).</li>
<li>They choose best fit in data and don’t care about overfitting.</li>
</ul></li>
<li>In practice, use BIC.</li>
<li>BIC good approximation of what more sophisticated methods would pick. Or even more conservative…</li>
<li>That introduces a “penalty term”</li>
<li>More predictor variables leads to worse value</li>
<li>Even more so in large samples.</li>
</ul>
</section>
<section id="finding-the-best-model-by-training-and-test-samples" class="slide level2">
<h2>Finding the best model by training and test samples</h2>
<ul>
<li>Approach Nr.2: Directly</li>
<li>Estimate it using a test (validation) set approach.</li>
<li>Needs cutting the dataset into training and test sample</li>
<li>No assumption</li>
<li>Need to pick evaluation criterion (loss function) = RMSE (root mean squared error)</li>
<li>Estimate the model in part of the data (say, 80%).
<ul>
<li>Training sample</li>
</ul></li>
<li>Evaluate predictive performance on the rest of the data.
<ul>
<li>Test sample</li>
</ul></li>
<li>Avoid overfitting in training data by evaluating on test data.</li>
</ul>
</section>
<section id="training-and-test-samples" class="slide level2">
<h2>Training and Test Samples</h2>
<ul>
<li>Creating two sub-samples</li>
<li>Randomly! (ie. not 1—80 and 81—100)</li>
<li>Randomly generate an ID, sort and create two sub-samples.</li>
<li>Training sample 80%
<ul>
<li>Regressions will be on run on this sample</li>
<li>Coefficients estimated</li>
</ul></li>
<li>Test (validation) sample 20%
<ul>
<li>Using estimated coefficients, we predict values for flats in the validation sample</li>
<li>Calculate residual, RMSE in the test sample</li>
</ul></li>
<li>RMSE rather than MSE – smaller numbers….</li>
</ul>
</section>
<section id="fold-cross-validation" class="slide level2">
<h2>5-fold cross-validation</h2>
<ul>
<li>Split sample <span class="math inline">\(k=5\)</span> times to train and test</li>
<li>For each folds:
<ul>
<li>Estimate model on training.</li>
<li>Get coefficients.</li>
<li>Use them to estimate on Test</li>
<li>Calculate test MSE</li>
</ul></li>
<li>Average and take Sqrt</li>
<li>Repeat for models</li>
<li>Pick model w lowest avg RMSE</li>
</ul>
</section>
<section id="bic-vs-test-rmse" class="slide level2">
<h2>BIC vs test RMSE</h2>
<ul>
<li>In our experience, in practice, BIC is the best indirect criterion – closest to test sample.</li>
<li>The advantage of BIC is that it needs no sample splitting which may be a problem in small samples.</li>
<li>The advantage of test MSE is that it makes no assumption.</li>
<li>BIC is a good first run, quick, is often not very wrong.</li>
<li>Ultimately, you want to do a test MSE.</li>
</ul>
</section>
<section id="case-study-model-selection" class="slide level2">
<h2>Case study: Model selection</h2>
<ul>
<li>We have the ingredients, we need to pick a model.</li>
<li>This process involves variable selection and a decision rule of choosing the model based on some loss function.</li>
<li>BIC on the actual data</li>
<li>Test-sample RMSE</li>
<li>Cross-validated (CV) RMSE</li>
<li>If enough data / computer power, use CV RMSE</li>
<li>With larger dataset, overfit becomes less of an issue.</li>
</ul>
</section>
<section id="case-study-model-selection-1" class="slide level2">
<h2>Case study: Model selection</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Model</th>
<th>N vars</th>
<th>N coeff</th>
<th>R-squared</th>
<th>RMSE</th>
<th>BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1 Model 1</td>
<td>3</td>
<td>0.85</td>
<td>1,755</td>
<td>5,018</td>
<td></td>
</tr>
<tr class="even">
<td>2 Model 2</td>
<td>5</td>
<td>0.90</td>
<td>1,433</td>
<td>4,910</td>
<td></td>
</tr>
<tr class="odd">
<td>3 Model 3</td>
<td>9</td>
<td>0.91</td>
<td>1,322</td>
<td>4,893</td>
<td></td>
</tr>
<tr class="even">
<td>4 Model 4</td>
<td>12</td>
<td>0.92</td>
<td>1,273</td>
<td>4,894</td>
<td></td>
</tr>
<tr class="odd">
<td>5 Model 5</td>
<td>22</td>
<td>0.92</td>
<td>1,239</td>
<td>4,935</td>
<td></td>
</tr>
</tbody>
</table>
<p>Note: In sample values. Model 1: age, age squared, Model 2= Model 1 +odometer, odometer squared, Model 3= Model2 + SE, excellent condition, good condition, dealer, Model 4= Model 3 + LE, XLE, like new condition, 6cylinder, Model 5 = Model 4 + many interactions. Source: used-cars dataset.</p>
</section>
<section id="case-study-model-selection-2" class="slide level2">
<h2>Case study: Model selection</h2>
<ul>
<li>Cross-validate using 4-fold cross validation.</li>
<li>Run the regression on 3/4 of the sample, predicting on the remaining 1/4 of the sample, get RMSE on test sample.</li>
<li>We then average out RMSE values over the 4 test samples</li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th>Fold No.</th>
<th>Model 1</th>
<th>Model 2</th>
<th>Model 3</th>
<th>Model 4</th>
<th>Model 5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1 Fold1</td>
<td>1,734</td>
<td>1,428</td>
<td>1,331</td>
<td>1,395</td>
<td>1,391</td>
</tr>
<tr class="even">
<td>2 Fold2</td>
<td>2,010</td>
<td>1,781</td>
<td>1,692</td>
<td>1,638</td>
<td>1,693</td>
</tr>
<tr class="odd">
<td>3 Fold3</td>
<td>1,465</td>
<td>1,251</td>
<td>1,256</td>
<td>1,253</td>
<td>1,436</td>
</tr>
<tr class="even">
<td>4 Fold4</td>
<td>1,823</td>
<td>1,325</td>
<td>1,250</td>
<td>1,246</td>
<td>1,307</td>
</tr>
<tr class="odd">
<td>5 Average</td>
<td>1,769</td>
<td>1,460</td>
<td>1,394</td>
<td>1,392</td>
<td>1,464</td>
</tr>
</tbody>
</table>
<p>Source: used-cars dataset.</p>
</section>
<section id="case-study-model-selection-3" class="slide level2">
<h2>Case study: Model selection</h2>
<ul>
<li>Model 3 has lowest BIC, lowest average RMSE on test samples. Model 4 is close.</li>
<li>Interestingly, both approaches suggests that Model 3 is the one that has the best prediction properties</li>
<li>Small sample, simple model.</li>
</ul>
</section>
<section id="external-validity-and-stable-patterns" class="slide level2">
<h2>External validity and stable patterns</h2>
<ul>
<li>BIC, Training-test, k-fold cross-validation…</li>
<li>All very nice</li>
<li>But, in the end, they all use the information in the data.</li>
<li>How would things look for the target observation(s)?</li>
<li>The issue of stationarity – how our data is related to other datasets we may use our model</li>
<li>We may have some ideas</li>
<li>We may use non-random test samples that may mimic the difference in our data and the target observations</li>
<li>In the end we can’t know but need to think about it.</li>
<li>Plus be aware, that some difference is likely, so your model fit in an outside data source is likely to be worse…</li>
</ul>
</section>
<section id="external-validity-and-stable-patterns-1" class="slide level2">
<h2>External validity and stable patterns</h2>
<ul>
<li>Most predictions will be on future data</li>
<li>High external validity requires that the environment is stationary.</li>
<li>Stationarity means that the way variables are distributed remains the same over time.</li>
<li>Here that distribution is to be understood in a general way: the joint distribution of predictor variables and target variable are required to remain the same throughout the time covered in the data and the time of the forecast.</li>
<li>Stationarity ensures that the relationship between predictors and the target variable is the same in the data and the forecasted future.</li>
<li>If the relationship breaks down whatever we establish in our data won’t be true in the future, leading to wrong forecasts.</li>
</ul>
</section>
<section id="external-validity-and-stable-patterns-2" class="slide level2">
<h2>External validity and stable patterns</h2>
<ul>
<li>External validity and stable patterns - Very broad concept</li>
<li>It’s about representativeness of actual data <span class="math inline">\(\rightarrow\)</span> to live data</li>
<li>Often hard to know.</li>
<li>Remember hotels (other dates, other cities).</li>
<li>Domain knowledge can help.</li>
<li>Study if patterns were stable in the past / other locations were stable can help.</li>
</ul>
</section>
<section id="algorithms" class="slide level2">
<h2>Algorithms</h2>
</section>
<section id="machine-learning-and-the-role-of-algorithms" class="slide level2">
<h2>Machine Learning and the Role of Algorithms</h2>
<ul>
<li>Predictive analytics is often used for data analysis whose goal is prediction. But a more popular, and related, term is machine learning.</li>
<li>Machine learning is an umbrella concept for methods that use algorithms to find patterns in data and use them for prediction purposes.</li>
<li>An algorithm is a set of rules and steps that defines how to generate an output (predicted values) using various inputs (variables, observations in the original data).</li>
<li>A formula is an example of an algorithm – one that can be formulated in terms of an equation.</li>
<li>OLS formula for estimating the coefficients of a linear regression is an algorithm.</li>
</ul>
</section>
<section id="machine-learning-algorithms" class="slide level2">
<h2>Machine Learning Algorithms</h2>
<ul>
<li>Machine learning is about algorithms, machines and learning</li>
<li>Algorithms specify each and every step to follow in a clear way.</li>
<li>Not all algorithms can be translated into a formula.
<ul>
<li>The bootstrap estimation of a standard error (Chapter 5, Section 5.6) is an example.</li>
<li>K-fold cross-validation.</li>
</ul></li>
<li>Heavy use of machines = computers. Steps of algorithm translated into computer code and make the computer follow those steps. Fast.</li>
<li>Learning - learn something from the data with data and an algorithms.
<ul>
<li>Predicted value of <span class="math inline">\(y =?\)</span> If combine <span class="math inline">\(x\)</span> variables using a particular model.</li>
<li>learning which model is best for predicting <span class="math inline">\(y\)</span> as well as what that predicted value is.</li>
</ul></li>
</ul>
</section>
<section id="what-is-machine-learning" class="slide level2">
<h2>What is, machine learning?</h2>
<ul>
<li>Many definitions, discussions.</li>
<li>Here: Machine learning is an approach to predictive data analysis – achieving the best possible prediction from available data.</li>
<li>Consequence 1: understanding the patterns of associations between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> is of secondary importance.</li>
<li>We need stable patterns for good prediction in live data, but that is it.</li>
<li>The machine learning attitude - a preference for evaluating methods based on data as opposed to abstract principles.</li>
<li>Original data to live data</li>
<li>Not a general rule or philosophy</li>
<li>Machine learning broadly: all prediction models including OLS</li>
<li>Machine learning narrowly: prediction models with no formula, ie not OLS</li>
</ul>
</section>
<section id="main-takeaways" class="slide level2">
<h2>Main takeaways</h2>
<ul>
<li>Prediction uses the original data with <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> to predict the value of <span class="math inline">\(y\)</span> for observations in the live data, in which <span class="math inline">\(x\)</span> is observed but <span class="math inline">\(y\)</span> is not</li>
<li>Prediction uses a model that describes the patterns of association between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> in the original data</li>
<li>Cross-validation can help find the best model in the population, or general pattern, represented by the original data</li>
<li>Stability of the patterns of association is needed for a prediction with high external validity</li>
</ul>

<div class="quarto-auto-generated-content">
<div class="footer footer-default">
<p><em>Rios-Avila and Cia</em></p>
</div>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1200,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>