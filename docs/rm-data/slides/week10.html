<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-07ba0ad10f5680c660e360ac31d2f3b6.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.33">

  <meta name="author" content="Fernando Rios-Avila">
  <meta name="dcterms.date" content="2024-11-06">
  <title>Econometrics MSC Levy – Prediction Setup</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-97edfe54b73ff960639f8ac44205bcc0.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

  

  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Prediction Setup</h1>
  <p class="subtitle">How far should we go?</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Fernando Rios-Avila 
</div>
        <p class="quarto-title-affiliation">
            Levy Economics Institute
          </p>
    </div>
</div>

  <p class="date">November 6, 2024</p>
</section>
<section id="motivation" class="slide level2">
<h2>Motivation</h2>
<ul>
<li><p>Imagine you want to sell your car soon and need to predict its price. You have data on similar used cars, and several regression models could help estimate its value now and in a year. How do you choose the best model?</p></li>
<li><p>Or, take an ice cream shop—using past sales and temperature data, you want to predict sales for the coming days. What factors should you consider to ensure your prediction is as accurate as possible?</p></li>
</ul>
</section>
<section id="prediction-basics-the-process" class="slide level2">
<h2>Prediction Basics: The Process</h2>
<ul>
<li>The idea of behind prediction is that we want to assign a value of <span class="math inline">\(y\)</span>(<span class="math inline">\(\hat y\)</span>) (target or outcome) for observations we do not have the value.</li>
<li>What we have, in our original data or working sample, is a set of observations with <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> values. We use them to “learn” the patterns of association between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>.</li>
<li>But for the target observations, we only have <span class="math inline">\(x\)</span> values.</li>
</ul>
</section>
<section id="prediction-basics-the-process-1" class="slide level2">
<h2>Prediction Basics: The Process</h2>
<ul>
<li>The process of prediction involves:
<ul>
<li>Determine what is the <strong>target</strong> variable <span class="math inline">\(y\)</span> and the <strong>features</strong> <span class="math inline">\(x\)</span>.</li>
<li>Using the original data to estimate a model that describes the patterns of association between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>.</li>
<li>Using the estimated model to predict the value of <span class="math inline">\(y\)</span> for the target observations.</li>
</ul></li>
<li>Evaluation of the prediction (how actual data compares to predicted data)</li>
<li>Rinse and repeat: Choose a different model, evaluate, choose the best model.
<ul>
<li>Best model for the Live data not the original data.</li>
</ul></li>
</ul>
</section>
<section id="cs-price-cars" class="slide level2">
<h2>CS: Price cars</h2>
<ul>
<li>You want to sell your car through online advertising</li>
<li>Target is continuous (in dollars)</li>
<li>Features are continuous or categorical</li>
<li>The business question:
<ul>
<li>What price should you put into the ad?</li>
</ul></li>
</ul>
</section>
<section id="cs-price-apartments" class="slide level2">
<h2>CS: Price apartments</h2>
<ul>
<li>You are planning to run an AirBnB business</li>
<li>Target is continuous (in dollars)</li>
<li>Features are varied from text to binary</li>
<li>The business question:
<ul>
<li>How should you price apartments/houses?</li>
</ul></li>
</ul>
</section>
<section id="cs-predict-companys-exit-from-business" class="slide level2">
<h2>CS: Predict company’s exit from business</h2>
<ul>
<li>You have a consulting company</li>
<li>Predict which firms will go out of business (exit) from a pool of partners</li>
<li>Target is binary: exit / stay</li>
<li>Features of financial and management info</li>
<li>Business decision:
<ul>
<li>Which firms to give loan to?</li>
</ul></li>
</ul>
</section>
<section id="predictive-analysis-what-is-new" class="slide level2">
<h2>Predictive Analysis: what is new?</h2>
<ul>
<li>Most of econometrics focused on finding relationships between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>
<ul>
<li>What is the relationship like (+/-, linear, etc.)</li>
<li>Is it a robust relationship – true in the population /general pattern? (causal?)</li>
</ul></li>
<li>Now, we use <span class="math inline">\(x_1, x_2, \dots\)</span> to predict <span class="math inline">\(y\)</span>: <span class="math inline">\(\hat{y}_j = \hat{f}(x_j)\)</span>, How is this different?</li>
</ul>
<div class="fragment">
<ul>
<li>We care less about
<ul>
<li>Individual coefficient values, multicollinearity</li>
</ul></li>
<li>We still care about the stability of our results.</li>
<li>But, should we care about causality?
<ul>
<li>Not so much, we care more about making the best prediction.</li>
</ul></li>
</ul>
</div>
</section>
<section>
<section id="different-types-of-prediction" class="title-slide slide level1 center">
<h1>Different types of prediction</h1>
<p>Target variables</p>
</section>
<section id="what-are-we-predicting" class="slide level2">
<h2>What are we predicting?</h2>
<ul>
<li><span class="math inline">\(Y\)</span> is quantitative (e.g price)
<ul>
<li>Quantitative prediction. Expected price of a car given its characteristics.</li>
<li>its a “Regression” problem</li>
<li>We could obtain a point prediction or an interval prediction (As before)</li>
</ul></li>
<li><span class="math inline">\(Y\)</span> is binary (e.g.&nbsp;Default or nor)
<ul>
<li><span class="math inline">\(Y\)</span> takes values in a finite set of (unordered) classes (survived/died, sold/not sold, car model)</li>
<li>We may want to types of predictions: Probability prediction (<span class="math inline">\(\hat P(y|x=1)\)</span>) or classification (<span class="math inline">\(\hat y = 1 \text{ or }0| x\)</span>)</li>
</ul></li>
<li>Time series prediction (<strong>Forecasting</strong>).
<ul>
<li>Make predictions about the future based on historical and current data.</li>
<li><span class="math inline">\(\hat y_t = f(x_{t-1}, x_{t-2}, \dots)\)</span></li>
</ul></li>
</ul>
</section>
<section id="what-is-different" class="slide level2">
<h2>What is Different?</h2>
<ul>
<li>In principle, the process is the same as before, but we have a diffent goal.
<ul>
<li>We need to pay more attention to other aspects of the process.</li>
</ul></li>
<li>Label Engeneering: What transformation is suitable for the target variable?</li>
<li>Feature engineering (variable selection): What variables and functional forms should be included</li>
<li>Model estimation and prediction, based on variable selection
<ul>
<li>Decisions regarding model complexity and Specification (Know-How or Machine Learning)</li>
</ul></li>
<li>Model evaluation considering complexity and loss</li>
<li>Key idea: Focus on systematically combine estimation and model selection</li>
</ul>
</section>
<section id="the-tool-supervised-machine-learning" class="slide level2">
<h2>The Tool: Supervised Machine Learning</h2>
<ul>
<li>Supervised Machine Learning is a set of tools that help us predict the value of a target variable <span class="math inline">\(Y\)</span> based on a set of features <span class="math inline">\(X\)</span>.</li>
<li>We will use one of the oldest and most commonly used method:</li>
</ul>
<div class="fragment">
<ul>
<li>Linear Regression</li>
</ul>
</div>
</section>
<section id="the-prediction-error" class="slide level2">
<h2>The Prediction Error</h2>
<ul>
<li>We have seen this.</li>
<li>The Regression model can produce a Predicted value <span class="math inline">\(\hat{y}_j\)</span> for target observation <span class="math inline">\(j\)</span></li>
<li>but, actual value <span class="math inline">\(y_j\)</span> is not known (that is why we are predicting)</li>
<li>Thus, there will be a prediction error</li>
</ul>
<p><span class="math display">\[e_j = \hat{y}_j - y_j
\]</span></p>
<ul>
<li>Error = actual value - predicted value</li>
</ul>
</section>
<section id="the-prediction-error-1" class="slide level2">
<h2>The Prediction Error</h2>
<ul>
<li>The <strong>ideal</strong> prediction error, is zero: our predicted value is right on target.
<ul>
<li>Rare…</li>
</ul></li>
<li>The prediction error carries information: direction and size.</li>
<li>Direction of miss:
<ul>
<li>Positive if we overpredict</li>
<li>Negative if we underpredict</li>
<li>Degree of wrongness depends on the decision problem. (price is right?)</li>
</ul></li>
<li>Size:
<ul>
<li>magnitude of the error may depend on the nature of the problem and the loss function.</li>
</ul></li>
</ul>
</section>
<section id="decomposing-the-prediction-error" class="slide level2">
<h2>Decomposing the prediction error</h2>
<p>Assume the best model for <span class="math inline">\(Y\)</span> is <span class="math inline">\(Y= f(X,Z)+\epsilon\)</span>, but we estimate <span class="math inline">\(Y^E = g(X,Z)\)</span>, and obtain <span class="math inline">\(\hat g(X,Z)\)</span></p>
<ul>
<li>The prediction error can be decomposed into three parts:
<ol type="1">
<li><strong>estimation error</strong>: Difference between <span class="math inline">\(g(X)\)</span> and <span class="math inline">\(\hat g(X)\)</span></li>
<li><strong>model error</strong>: Difference between <span class="math inline">\(f(X)\)</span> and <span class="math inline">\(g(X)\)</span>.</li>
<li><strong>genuine error</strong>: error that cant be eliminated even if have the best possible model. <span class="math inline">\(\epsilon\)</span></li>
</ol></li>
</ul>
</section>
<section id="interval-prediction-for-quantitative-target-variables" class="slide level2">
<h2>Interval prediction for quantitative target variables</h2>
<ul>
<li><p>One advantage of regressions - it’s easy quantify uncertainty of prediction</p>
<ul>
<li>This can be used to obtain <strong>Interval predictions</strong></li>
</ul></li>
<li><p>Interval predictions quantify 2-out-of-3 sources of prediction uncertainty: estimation error and genuine (or irreducible) error.</p></li>
<li><p>They do not include the third source, model uncertainty! (Bayesian methods can help with this)</p></li>
<li><p>The 95% prediction interval (PI) tells where to expect the actual value for the target observation.</p></li>
<li><p>The PI for linear regression requires homoskedasticity. (but could be relaxed)</p></li>
</ul>
</section></section>
<section>
<section id="the-loss-function" class="title-slide slide level1 center">
<h1>The Loss function</h1>
<p>Not all errors are created equal</p>
</section>
<section id="loss-functions" class="slide level2">
<h2>Loss Functions</h2>
<ul>
<li><p>We use a <strong>Loss</strong> function to quantify the <strong>cost</strong> of prediction error</p>
<ul>
<li>It attaches a value to the prediction error, specifying how <strong>bad</strong> it is</li>
<li>Thus, Loss function determines best predictor</li>
</ul></li>
<li><p>Ideally, it is derived from decision problem,</p>
<ul>
<li>How much more costly is to overpredict than underpredict?</li>
</ul></li>
<li><p>In practice, highly crafted loss functions are rare (Machine learning, Neural Networks, Etc), so we use common ones</p></li>
<li><p>Loss functions could be used to both estimate, but also to <strong>evaluate/compare</strong> models</p></li>
<li><p>Plot Twist: Loss function for OLS is the L2 Square loss function</p></li>
</ul>
</section>
<section id="loss-functions-1" class="slide level2">
<h2>Loss Functions</h2>
<ul>
<li>The most important Loss functions have the following characteristics:
<ul>
<li><strong>Symmetry</strong>: losses due to errors in opposing direction are similar
<ul>
<li><strong>Asymmetric loss</strong>: overprediction is more costly than underprediction</li>
</ul></li>
<li><strong>Convexity</strong>: Twice as large errors generate more than twice as large losses. (We penalize large errors more than small ones)
<ul>
<li><strong>Linear loss</strong>: Errors are penalized proportionally to their size</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="loss-functions-of-various-shapes" class="slide level2">
<h2>Loss Functions of Various Shapes</h2>
<div id="448f0684" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb1-1"><a></a><span class="kw">qui</span> {</span>
<span id="cb1-2"><a></a><span class="kw">clear</span></span>
<span id="cb1-3"><a></a><span class="kw">set</span> <span class="dv">scheme</span> white2</span>
<span id="cb1-4"><a></a>color_style tableau</span>
<span id="cb1-5"><a></a><span class="kw">set</span> <span class="kw">obs</span> 301</span>
<span id="cb1-6"><a></a><span class="kw">range</span> <span class="fu">r</span> -5 5 </span>
<span id="cb1-7"><a></a><span class="kw">gen</span> ll = <span class="fu">r</span>^2</span>
<span id="cb1-8"><a></a><span class="kw">gen</span> ll2 = 2*<span class="fu">abs</span>(<span class="fu">r</span>)</span>
<span id="cb1-9"><a></a><span class="kw">gen</span> ll3 = 1.5*<span class="fu">r</span>^2*(<span class="fu">r</span>&gt;0)+0.5*<span class="fu">r</span>^2*(<span class="fu">r</span>&lt;0)</span>
<span id="cb1-10"><a></a><span class="kw">drop</span> <span class="kw">if</span> ll&gt;30 | ll2&gt;30 | ll3&gt;30</span>
<span id="cb1-11"><a></a><span class="kw">line</span> ll ll2 ll3 <span class="fu">r</span>, lw(1 1 1) <span class="co">///</span></span>
<span id="cb1-12"><a></a>    <span class="bn">legend</span>(<span class="kw">order</span>(1 <span class="st">"Symetric-Convex"</span> 2 <span class="st">"Symetric-Linear"</span> 3 <span class="st">"Asymetric-Convex"</span>) )</span>
<span id="cb1-13"><a></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<style>div.jp-Notebook .datagrid-container {min-height: 448px; }</style>
</div>

</div>
<img data-src="week10_files/figure-revealjs/cell-2-output-2.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="examples-1-used-cars" class="slide level2">
<h2>Examples 1 – used cars</h2>
<ul>
<li>The loss function for predicting the value of our used car depends on how we value money and how we value how much time it takes to sell our car (value of your car).</li>
<li>A too low prediction may lead to selling our car cheap but fast;</li>
<li>A too high prediction may make us wait a long time and, possibly, revising the sales price downwards before selling our car.</li>
<li>What kind of loss function would make sense?</li>
</ul>
</section>
<section id="examples-2---creditors" class="slide level2">
<h2>Examples 2 - creditors</h2>
<ul>
<li>Creditors decide whether to issue a loan only to potential debtors that are predicted to pay it back with high likelihood.</li>
<li>Two kinds of errors are possible:
<ul>
<li>debtors that would pay back their loan don’t get a loan</li>
<li>debtors that would not pay back their loan get one nevertheless.</li>
</ul></li>
<li>The costs of the first error are due to missed business opportunity; the costs of the second error are due to direct loss of money.</li>
<li>These losses may be quantified in relatively straightforward ways.</li>
<li>What kind of loss function would make sense?</li>
</ul>
</section>
<section id="common-loss-functions" class="slide level2">
<h2>Common loss functions</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><span class="math display">\[SQR: L(e_j) = e^2_j = (\hat{y}_j - y_j)^2
\]</span></p>
<ul>
<li>The most widely used loss function</li>
<li>Symmetric: Losses due to errors in opposing direction are same</li>
<li>Convex: Twice as large errors generate more than twice (4x) as large losses</li>
</ul>
</div><div class="column" style="width:50%;">
<p><span class="math display">\[ABS: L(e_j) = |e_j| = Abs(\hat{y}_j - y_j)
\]</span></p>
<ul>
<li><p>Used for Median regression (Quantile regression)</p></li>
<li><p>Symmetric: Losses due to errors in opposing direction are same</p></li>
<li><p>Linear: Twice as large errors generate twice as large losses</p></li>
<li><p>Quantile Regressions use <strong>Asymetric</strong> loss functions</p></li>
</ul>
</div></div>
</section>
<section id="mean-squared-error-mse" class="slide level2">
<h2>Mean Squared Error: MSE</h2>
<ul>
<li>The most common way to quantify and aggregate the loss function is using the Mean Squared Error (MSE)</li>
<li>Squared loss <span class="math inline">\(\rightarrow\)</span> Mean Squared Error (MSE)</li>
</ul>
<p><span class="math display">\[\begin{align*}
\text{MSE} &amp;= \frac{1}{K} \sum_{k=1}^K (\hat{y}_k - y_k)^2 \\
\text{RMSE} &amp;= \sqrt{\text{MSE}} = \sqrt{\frac{1}{K} \sum_{k=1}^K (\hat{y}_k - y_k)^2}
\end{align*}
\]</span></p>
<ul>
<li>Using this function typically implies we are interested in the Mean as the best predictor</li>
</ul>
</section>
<section id="mse-decomposition-bias-and-variance" class="slide level2">
<h2>MSE decomposition : Bias and Variance</h2>
<ul>
<li><p>The MSE can be decomposed into two parts: <strong>Bias</strong> and <strong>Variance</strong> <span class="math display">\[\begin{align*}
MSE &amp;= \frac{1}{J}\sum_{j=1}^J (\hat{y}_j - y_j)^2 \\
&amp;= \left(\frac{1}{J}\sum_{j=1}^J (\hat{y}_j - y_j)\right)^2 + \frac{1}{J}\sum_{j=1}^J (\hat y_j - \bar{\hat y})^2 \\
&amp;= \text{Bias}^2 + \text{PredictionVariance}
\end{align*}
\]</span></p></li>
<li><p>The bias of a prediction is the average of its prediction error.</p>
<ul>
<li>How far off is the average prediction from the actual value?</li>
</ul></li>
<li><p>The variance of a prediction describes shows how it varies around its average.</p></li>
</ul>
</section>
<section id="mse-decomposition-bias-and-variance-1" class="slide level2">
<h2>MSE decomposition : Bias and Variance</h2>
<p><span class="math display">\[\begin{align*}
\text{MSE} &amp;= \frac{1}{K} \sum_{k=1}^K (\hat{y}_k - y_k)^2 \\
         &amp;= \left(\frac{1}{K} \sum_{k=1}^K (\hat{y}_k - \bar{y})\right)^2 + \frac{1}{K} \sum_{k=1}^K (y_k - \bar{y})^2 \\
         &amp;= \text{Bias}^2 + \text{PredictionVariance}
\end{align*}\]</span></p>
<ul>
<li>OLS is unbiased. Some other methods will allow for some bias in return for lower variance.</li>
</ul>
<!-- ## Case study: used cars data

- Suppose you want to sell your car of a certain make, type, year, miles, condition and other features.
- The prediction analysis helps uncover the average advertised price of cars with these characteristics
- That helps decide what price you may want to put on your ad.

What to do?

- Scraped from a website
- Year of make (age), Odometer (miles)
- Tech specifications such as fuel and drive
- Dealer or private seller

## Case study: Loss function

- The loss function for predicting the value of our used car depends on how we value money and how we value how much time it takes to sell our car.
- A too low prediction may lead to selling our car cheap but fast;
- A too high prediction may make us wait a long time and, possibly, revising the sales price downwards before selling our car.
- Symmetric
- Sensitive to big deviations
- RMSE and OLS

## Case study - used cars: features

- Odometer, measuring miles the car traveled (Continuous, linear)
- More specific type of the car: LE, XLE, SE (missing in about 30% of the observations). (Factor – set of dummies , incl N/A)
- Good condition, excellent condition or it is like new (missing for about one third of the ads). (Factor – set of dummies, incl N/A)
- Car's engine has 6 cylinders (20% of ads say this; 43% says 4 cylinders, and the rest has no information on this). (Binary for 6 cylinders)

## Case study: models by hand

- Model 1: age, age squared
- Model 2: age, age squared, odometer, odometer squared
- Model 3: age, age squared, odometer, odometer squared, LE, excellent condition, good condition, dealer
- Model 4: age, age squared, odometer, odometer squared, LE, excellent condition, good condition, dealer, LE, XLE, cylinder
- Model 5: same as Model 4 but with all variables interacted with age (won't show in next table)

## Case study: Car price model results

```
(1)   (2)   (3)   (4)
Variables Model 1 Model 2 Model 3 Model 4
age     -1,530.09 -1,149.22 -873.47 -836.64
agesq    35.05   27.65   18.21   17.63
odometer           -303.84 -779.90 -788.70
odometersq                 18.81   19.20
LE                         28.11  -20.48
XLE                                301.69
SE                                1,338.79
cond_likenew                       558.67
cond_excellent                     176.49  190.40
cond_good                          293.36  321.56
cylind6                           -370.27
dealer                            572.98  822.65
Constant 18,365.45 18,860.20 19,431.89 18,963.35
```

## Case study: Results

- When doing prediction, coefficients are less important.
- But we shall use them for sanity check: age negative, convex (flattens out)
- SE may not be even displayed. It is helpful for model selection, but only along with other measures
- and values of the predictor variables for our car: age = 10 (years), odometer= 12 (10 thousand miles), type= LE, excellent condition=1.
- A point prediction, Model 3: age: -873.47, age squared=18.21, odometer -799.90, odometer sq = 18.81, LE=28.11, cond excellent: 176.49+ C=19.431.89
- Predicted is price is 6073.

## Case study: Prediction Interval

- Calculating prediction intervals for the baseline models
- Very wide interval despite high R2
- Prediction is hard!
- Even with a good model, you'll make plenty of errors
- Should be aware
- Let your clients know in advance...

## Case study: Prediction Interval

Based on the third model, we have a point prediction of $6073$
Have a 80% prediction intervals (PI) – Ads for cars just like ours may ask a price ranging from $4,317$ to $7,829$ with a 80% chance.

| Model 1 | Model 3 |
|---------|---------|
| Point prediction 6,569 | 6,073 |
| Prediction Interval (80%) [4,296-8,843] | [4,317-7,829] |
| Prediction Interval (95%) [3,085-10,053] | [3,382-8,763] |

Note: Chicago cars. Prices in dollars.
Source: used-cars dataset.
-->
</section></section>
<section>
<section id="finding-the-best-model" class="title-slide slide level1 center">
<h1>Finding the best model</h1>
<p>Too hot nor too cold, but just right</p>
</section>
<section id="model-selection" class="slide level2">
<h2>Model selection</h2>
<ul>
<li>Model selection is finding the best fit while avoiding overfitting, and aiming for high external validity.</li>
<li>To do this, we aim to choose a model that is flexible enough to capture the patterns in the data but not too flexible to capture noise.
<ul>
<li>Bias-Variance tradeoff</li>
<li>Balancing the complexity of the model</li>
</ul></li>
<li>Consider two models. They could be different for two reasons:
<ul>
<li>different functional forms (spline vs.&nbsp;quadratic)</li>
<li>different number of variables (simple vs.&nbsp;complex)</li>
</ul></li>
</ul>
</section>
<section id="how-to-choose-a-model" class="slide level2">
<h2>How to choose a model?</h2>
<ul>
<li><p>Typically, we would say that the best model is the one that has the highest <span class="math inline">\(R^2\)</span> or the lowest MSE.</p>
<ul>
<li>This may be true for the original data, but not for the <strong>target</strong> observations.</li>
<li>Also, <span class="math inline">\(R^2\)</span> and MSE always increase when we add more variables.</li>
</ul></li>
<li><p>So, what we need is a way to check how well the models predict the target observations. (unobserved cases)</p></li>
<li><p>We want to avoid overfitting at all costs.</p></li>
</ul>
</section>
<section id="example" class="slide level2">
<h2>Example</h2>
<ul>
<li>Assume the true model is <span class="math inline">\(y = 1 + x -.5 x^2 + \epsilon\)</span>, with <span class="math inline">\(\epsilon ~ N(0,1.5)\)</span></li>
<li>we create 100 observations from the above process but use only 30 for modeling. We try running regressions with ever more complex models</li>
<li>Make predictions, and see how well we did.</li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;"><span class="math inline">\(R^2\)</span></th>
<th style="text-align: center;">MSE</th>
<th style="text-align: center;">OoS MSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>^1</td>
<td style="text-align: center;">.3224669</td>
<td style="text-align: center;">1.934762</td>
<td style="text-align: center;">2.949084</td>
</tr>
<tr class="even">
<td>^2</td>
<td style="text-align: center;">.6255072</td>
<td style="text-align: center;">1.069401</td>
<td style="text-align: center;">2.93478</td>
</tr>
<tr class="odd">
<td>^3</td>
<td style="text-align: center;">.6344791</td>
<td style="text-align: center;">1.043781</td>
<td style="text-align: center;">2.978827</td>
</tr>
<tr class="even">
<td>^4</td>
<td style="text-align: center;">.713217</td>
<td style="text-align: center;">.8189369</td>
<td style="text-align: center;">4.138006</td>
</tr>
<tr class="odd">
<td>^5</td>
<td style="text-align: center;">.7259535</td>
<td style="text-align: center;">.7825666</td>
<td style="text-align: center;">3.557651</td>
</tr>
</tbody>
</table>
<p>See how <span class="math inline">\(R^2\)</span> increases monotonously, improving “in-sample fit”. But, the OoS MSE worsens after a certain point.</p>
</section>
<section id="example-2" class="slide level2">
<h2>Example 2</h2>

<img data-src="images/paste-8.png" class="r-stretch"></section>
<section id="underfit-vs-overfit" class="slide level2">
<h2>Underfit vs overfit</h2>
<ul>
<li>A model that fits the data worse in the “working/original” data compared to the “live/target” data is said to “underfit” the model.
<ul>
<li>Simple: we should build a better model.</li>
</ul></li>
<li>If the model fits the data working better than target data, then it over-fits it. Needs to be corrected.</li>
</ul>
<h3 id="overfitting">Overfitting</h3>
<ul>
<li>Overfitting is a key aspect of external validity
<ul>
<li>Finding a model that fits the data better than alternative models, but makes worse actual prediction.</li>
</ul></li>
<li>Overfitting is a common problem in prediction analysis</li>
</ul>
</section>
<section id="reason-for-overfitting" class="slide level2">
<h2>Reason for overfitting</h2>
<p>The typical reason for overfitting is fitting a model that is too complex on the dataset. - Complexity: number of estimated coefficients - Often: fitting a model with too many predictor variables. - Including too many variables from the dataset that do not really add to the predictive power of the regression. - Problems of multicollinearity, too many interactions, etc. - Too detailed nonlinear patterns - as piecewise linear splines with many knots - polynomials of high degree.</p>
</section>
<section id="finding-the-best-model-by-best-fit-and-penalty" class="slide level2">
<h2>Finding the best model by best fit and penalty</h2>
<ul>
<li>As shown earlier, traditional measures of fit, such as <span class="math inline">\(R^2\)</span> and MSE, are not good for finding the best model. They always increase with the number of variables.</li>
<li>We were only able to conclude model fitness because we had the true model (and the Out-of-Sample data)
<ul>
<li>This is not the case in practice.</li>
</ul></li>
<li>So, how do we find the best model?
<ul>
<li>Indirectly: Penalize the number of variables</li>
<li>Directly: Use a training-test sample</li>
</ul></li>
</ul>
</section>
<section id="indirect-evaluation-criteria" class="slide level2">
<h2>Indirect evaluation criteria</h2>
<ul>
<li>Main methods: AIC, BIC and adjusted <span class="math inline">\(R^2\)</span>
<ul>
<li>Advantage: easy to compute</li>
<li>Disadvantage: assumptions. They may not penalize enough.</li>
</ul></li>
<li>Adjusted <span class="math inline">\(R^2\)</span> – just add a penalty for having many RHS vars
<ul>
<li>corrects with <span class="math inline">\((n - 1)/(n - k - 1)\)</span></li>
</ul></li>
<li>AIC = <span class="math inline">\(-2 \times \ln(\text{likelihood}) + 2 \times k\)</span></li>
<li>BIC = <span class="math inline">\(-2 \times \ln(\text{likelihood}) + \ln(N) \times k\)</span>
<ul>
<li>Both are based on information loss theory</li>
<li>BIC puts heavier penalty on models with many RHS variables, than AIC.</li>
</ul></li>
</ul>
</section>
<section id="example-redone" class="slide level2">
<h2>Example, redone</h2>
<div id="3d0133a6" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb2-1"><a></a>* This is the full code <span class="kw">for</span> previous and current example</span>
<span id="cb2-2"><a></a><span class="kw">clear</span></span>
<span id="cb2-3"><a></a><span class="kw">set</span> <span class="dv">seed</span> 10</span>
<span id="cb2-4"><a></a><span class="kw">set</span> <span class="kw">obs</span> 100</span>
<span id="cb2-5"><a></a><span class="kw">gen</span> x = runiform(-2 ,2)</span>
<span id="cb2-6"><a></a><span class="kw">gen</span> <span class="fu">y</span> = 1 + x - 0.5 * x^2 + 1.5* rnormal()</span>
<span id="cb2-7"><a></a> </span>
<span id="cb2-8"><a></a><span class="kw">capture</span> <span class="kw">program</span> <span class="kw">drop</span> fit_stat1</span>
<span id="cb2-9"><a></a><span class="kw">program</span> fit_stat1, rclass</span>
<span id="cb2-10"><a></a>    <span class="kw">tempvar</span> yhat smp</span>
<span id="cb2-11"><a></a>    <span class="kw">gen</span> <span class="ot">`smp'</span> = <span class="fu">e</span>(<span class="kw">sample</span>)</span>
<span id="cb2-12"><a></a>    <span class="kw">predict</span> <span class="ot">`yhat'</span></span>
<span id="cb2-13"><a></a>    <span class="kw">replace</span> <span class="ot">`yhat'</span>=(<span class="fu">y</span>-<span class="ot">`yhat'</span>)^2</span>
<span id="cb2-14"><a></a>    </span>
<span id="cb2-15"><a></a>    <span class="fu">matrix</span> result=<span class="fu">e</span>(r2)</span>
<span id="cb2-16"><a></a>    <span class="kw">sum</span> <span class="ot">`yhat'</span> <span class="kw">if</span> <span class="ot">`smp'</span>, <span class="kw">meanonly</span></span>
<span id="cb2-17"><a></a>    <span class="fu">matrix</span> result=result, <span class="fu">r</span>(<span class="kw">mean</span>)</span>
<span id="cb2-18"><a></a>    <span class="kw">sum</span> <span class="ot">`yhat'</span> <span class="kw">if</span> !<span class="ot">`smp'</span>, <span class="kw">meanonly</span></span>
<span id="cb2-19"><a></a>    <span class="fu">matrix</span> result=result, <span class="fu">r</span>(<span class="kw">mean</span>)</span>
<span id="cb2-20"><a></a>    <span class="fu">return</span> <span class="fu">matrix</span> result = result</span>
<span id="cb2-21"><a></a><span class="kw">end</span></span>
<span id="cb2-22"><a></a></span>
<span id="cb2-23"><a></a><span class="kw">reg</span> <span class="fu">y</span> c.x <span class="kw">if</span> <span class="dt">_n</span>&lt;=30</span>
<span id="cb2-24"><a></a>fit_stat1</span>
<span id="cb2-25"><a></a><span class="fu">matrix</span> rr2=<span class="fu">r</span>(result)</span>
<span id="cb2-26"><a></a><span class="kw">reg</span> <span class="fu">y</span> c.x##c.x <span class="kw">if</span> <span class="dt">_n</span>&lt;=30</span>
<span id="cb2-27"><a></a>fit_stat1</span>
<span id="cb2-28"><a></a><span class="fu">matrix</span> rr2=rr2\<span class="fu">r</span>(result)</span>
<span id="cb2-29"><a></a><span class="kw">reg</span> <span class="fu">y</span> c.x##c.x##c.x <span class="kw">if</span> <span class="dt">_n</span>&lt;=30</span>
<span id="cb2-30"><a></a>fit_stat1</span>
<span id="cb2-31"><a></a><span class="fu">matrix</span> rr2=rr2\<span class="fu">r</span>(result)</span>
<span id="cb2-32"><a></a><span class="kw">reg</span> <span class="fu">y</span> c.x##c.x##c.x##c.x <span class="kw">if</span> <span class="dt">_n</span>&lt;=30</span>
<span id="cb2-33"><a></a>fit_stat1</span>
<span id="cb2-34"><a></a><span class="fu">matrix</span> rr2=rr2\<span class="fu">r</span>(result)</span>
<span id="cb2-35"><a></a><span class="kw">reg</span> <span class="fu">y</span> c.x##c.x##c.x##c.x##c.x <span class="kw">if</span> <span class="dt">_n</span>&lt;=30</span>
<span id="cb2-36"><a></a>fit_stat1</span>
<span id="cb2-37"><a></a><span class="fu">matrix</span> rr2=rr2\<span class="fu">r</span>(result)</span>
<span id="cb2-38"><a></a></span>
<span id="cb2-39"><a></a><span class="kw">capture</span> <span class="kw">program</span> <span class="kw">drop</span> fit_stat2</span>
<span id="cb2-40"><a></a><span class="kw">program</span> fit_stat2, rclass</span>
<span id="cb2-41"><a></a>    <span class="kw">tempvar</span> yhat smp</span>
<span id="cb2-42"><a></a>    <span class="kw">gen</span> <span class="ot">`smp'</span> = <span class="fu">e</span>(<span class="kw">sample</span>)</span>
<span id="cb2-43"><a></a>    <span class="kw">predict</span> <span class="ot">`yhat'</span></span>
<span id="cb2-44"><a></a>    <span class="kw">replace</span> <span class="ot">`yhat'</span>=(<span class="fu">y</span>-<span class="ot">`yhat'</span>)^2    </span>
<span id="cb2-45"><a></a>    <span class="fu">matrix</span> result=<span class="fu">e</span>(r2), <span class="fu">e</span>(r2_a)</span>
<span id="cb2-46"><a></a>    <span class="kw">sum</span> <span class="ot">`yhat'</span> <span class="kw">if</span> <span class="ot">`smp'</span>, <span class="kw">meanonly</span></span>
<span id="cb2-47"><a></a>    <span class="fu">matrix</span> result=result, <span class="fu">r</span>(<span class="kw">mean</span>)</span>
<span id="cb2-48"><a></a>    <span class="kw">sum</span> <span class="ot">`yhat'</span> <span class="kw">if</span> !<span class="ot">`smp'</span>, <span class="kw">meanonly</span></span>
<span id="cb2-49"><a></a>    <span class="fu">matrix</span> result=result, <span class="fu">r</span>(<span class="kw">mean</span>)</span>
<span id="cb2-50"><a></a>    <span class="kw">qui</span>: <span class="kw">estat</span> <span class="kw">ic</span></span>
<span id="cb2-51"><a></a>    <span class="fu">matrix</span> result=result, <span class="fu">r</span>(S)[1,5..6]</span>
<span id="cb2-52"><a></a>    <span class="fu">return</span> <span class="fu">matrix</span> result = result</span>
<span id="cb2-53"><a></a><span class="kw">end</span></span>
<span id="cb2-54"><a></a></span>
<span id="cb2-55"><a></a><span class="kw">reg</span> <span class="fu">y</span> c.x <span class="kw">if</span> <span class="dt">_n</span>&lt;=30</span>
<span id="cb2-56"><a></a>fit_stat2</span>
<span id="cb2-57"><a></a><span class="fu">matrix</span> rr2=<span class="fu">r</span>(result)</span>
<span id="cb2-58"><a></a><span class="kw">reg</span> <span class="fu">y</span> c.x##c.x <span class="kw">if</span> <span class="dt">_n</span>&lt;=30</span>
<span id="cb2-59"><a></a>fit_stat2</span>
<span id="cb2-60"><a></a><span class="fu">matrix</span> rr2=rr2\<span class="fu">r</span>(result)</span>
<span id="cb2-61"><a></a><span class="kw">reg</span> <span class="fu">y</span> c.x##c.x##c.x <span class="kw">if</span> <span class="dt">_n</span>&lt;=30</span>
<span id="cb2-62"><a></a>fit_stat2</span>
<span id="cb2-63"><a></a><span class="fu">matrix</span> rr2=rr2\<span class="fu">r</span>(result)</span>
<span id="cb2-64"><a></a><span class="kw">reg</span> <span class="fu">y</span> c.x##c.x##c.x##c.x <span class="kw">if</span> <span class="dt">_n</span>&lt;=30</span>
<span id="cb2-65"><a></a>fit_stat2</span>
<span id="cb2-66"><a></a><span class="fu">matrix</span> rr2=rr2\<span class="fu">r</span>(result)</span>
<span id="cb2-67"><a></a><span class="kw">reg</span> <span class="fu">y</span> c.x##c.x##c.x##c.x##c.x <span class="kw">if</span> <span class="dt">_n</span>&lt;=30</span>
<span id="cb2-68"><a></a>fit_stat2</span>
<span id="cb2-69"><a></a><span class="fu">matrix</span> rr2=rr2\<span class="fu">r</span>(result)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<table class="caption-top" style="width:100%;">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;"><span class="math inline">\(R^2\)</span></th>
<th style="text-align: center;"><span class="math inline">\(aR^2\)</span></th>
<th style="text-align: center;">MSE</th>
<th style="text-align: center;">OoS MSE</th>
<th style="text-align: center;">AIC</th>
<th style="text-align: center;">BIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>^1</td>
<td style="text-align: center;">0.3225</td>
<td style="text-align: center;">0.2983</td>
<td style="text-align: center;">1.9348</td>
<td style="text-align: center;">2.9491</td>
<td style="text-align: center;">108.9358</td>
<td style="text-align: center;">111.7382</td>
</tr>
<tr class="even">
<td>^2</td>
<td style="text-align: center;">0.6255</td>
<td style="text-align: center;">0.5978</td>
<td style="text-align: center;">1.0694</td>
<td style="text-align: center;">2.9348</td>
<td style="text-align: center;">93.1493</td>
<td style="text-align: center;">97.3529</td>
</tr>
<tr class="odd">
<td>^3</td>
<td style="text-align: center;">0.6345</td>
<td style="text-align: center;">0.5923</td>
<td style="text-align: center;">1.0438</td>
<td style="text-align: center;">2.9788</td>
<td style="text-align: center;">94.4218</td>
<td style="text-align: center;">100.0266</td>
</tr>
<tr class="even">
<td>^4</td>
<td style="text-align: center;">0.7132</td>
<td style="text-align: center;">0.6673</td>
<td style="text-align: center;">0.8189</td>
<td style="text-align: center;">4.1380</td>
<td style="text-align: center;">89.1439</td>
<td style="text-align: center;">96.1499</td>
</tr>
<tr class="odd">
<td>^5</td>
<td style="text-align: center;">0.7260</td>
<td style="text-align: center;">0.6689</td>
<td style="text-align: center;">0.7826</td>
<td style="text-align: center;">3.5577</td>
<td style="text-align: center;">89.7810</td>
<td style="text-align: center;">98.1882</td>
</tr>
</tbody>
</table>
</section>
<section id="finding-the-best-model-by-training-and-test-samples" class="slide level2">
<h2>Finding the best model by training and test samples</h2>
<ul>
<li>Similar to bootstrapping (brute force approach for SE), its also possible to use a “bute-force” approach to find the best model.</li>
<li>This would require “imitating” the process of out-of-sample prediction.
<ol type="1">
<li><strong>Cut</strong> the dataset into training and test sample (80-20 ?)</li>
<li>Choose Some evaluation criterion (loss function)</li>
<li>Estimate the model on the training sample</li>
<li>Predict and evaluate the model on the test sample</li>
</ol></li>
<li>Problem: 80% (or less), may be too small training. And 20% (one shoot) could be different from the rest of the data.</li>
</ul>
</section>
<section id="lets-make-things-better-k-fold-cross-validation" class="slide level2">
<h2>Lets make things Better: K-fold cross-validation</h2>
<ul>
<li>If one is not enough, why not use more?</li>
<li>Split sample into <span class="math inline">\(k=5\)</span> groups (equal size)</li>
<li>Now, assume that each “fold” is the test sample, and the rest is the training sample.
<ul>
<li>Do the excercise k times, and every observation will be in the test sample once.</li>
</ul></li>
<li>Add up the MSEs, or get the average MSE.</li>
<li>Still has a random component, but less so than a single split.</li>
</ul>
</section>
<section id="k-fold-cross-validation" class="slide level2">
<h2>K-fold cross-validation</h2>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb3-1"><a></a>* This is the full code <span class="kw">for</span> previous and current example</span>
<span id="cb3-2"><a></a><span class="kw">clear</span></span>
<span id="cb3-3"><a></a><span class="kw">set</span> <span class="dv">seed</span> 10</span>
<span id="cb3-4"><a></a><span class="kw">qui</span>: <span class="kw">set</span> <span class="kw">obs</span> 30</span>
<span id="cb3-5"><a></a><span class="kw">gen</span> x = runiform(-2 ,2)</span>
<span id="cb3-6"><a></a><span class="kw">gen</span> <span class="fu">y</span> = 1 + x - 0.5 * x^2 + 1.5* rnormal()</span>
<span id="cb3-7"><a></a></span>
<span id="cb3-8"><a></a>** Create 5 folds</span>
<span id="cb3-9"><a></a><span class="kw">gen</span> fold = <span class="fu">mod</span>(<span class="dt">_n</span>,5)+1</span>
<span id="cb3-10"><a></a></span>
<span id="cb3-11"><a></a><span class="kw">capture</span> <span class="kw">program</span> <span class="kw">drop</span> fit_stat3</span>
<span id="cb3-12"><a></a><span class="kw">program</span> fit_stat3, rclass</span>
<span id="cb3-13"><a></a>    <span class="kw">tempvar</span> yhat aux</span>
<span id="cb3-14"><a></a>    <span class="kw">qui</span>:<span class="kw">gen</span> <span class="ot">`yhat'</span> = .</span>
<span id="cb3-15"><a></a>    <span class="kw">qui</span>:<span class="kw">forvalues</span> i = 1/5 {</span>
<span id="cb3-16"><a></a>        <span class="kw">reg</span> <span class="ot">`0'</span> <span class="kw">if</span> fold!=<span class="ot">`i'</span></span>
<span id="cb3-17"><a></a>        <span class="kw">predict</span> <span class="ot">`aux'</span></span>
<span id="cb3-18"><a></a>        <span class="kw">replace</span> <span class="ot">`yhat'</span> = <span class="ot">`aux'</span> <span class="kw">if</span> fold==<span class="ot">`i'</span></span>
<span id="cb3-19"><a></a>        <span class="kw">drop</span> <span class="ot">`aux'</span></span>
<span id="cb3-20"><a></a>    }</span>
<span id="cb3-21"><a></a>    <span class="kw">qui</span>: <span class="kw">replace</span> <span class="ot">`yhat'</span>=(<span class="fu">y</span>-<span class="ot">`yhat'</span>)^2    </span>
<span id="cb3-22"><a></a>    <span class="kw">sum</span> <span class="ot">`yhat'</span>, <span class="kw">meanonly</span></span>
<span id="cb3-23"><a></a>    <span class="fu">return</span> <span class="fu">scalar</span> <span class="kw">mse</span> = <span class="fu">r</span>(<span class="kw">mean</span>)</span>
<span id="cb3-24"><a></a><span class="kw">end</span></span>
<span id="cb3-25"><a></a></span>
<span id="cb3-26"><a></a>fit_stat3 <span class="fu">y</span> c.x </span>
<span id="cb3-27"><a></a><span class="kw">display</span> <span class="st">"^1, mse: "</span> %5.3f <span class="ot">`r(mse)'</span> <span class="dt">_n</span></span>
<span id="cb3-28"><a></a>fit_stat3 <span class="fu">y</span> c.x##c.x </span>
<span id="cb3-29"><a></a><span class="kw">display</span> <span class="st">"^2, mse: "</span> %5.3f <span class="ot">`r(mse)'</span> <span class="dt">_n</span></span>
<span id="cb3-30"><a></a>fit_stat3 <span class="fu">y</span> c.x##c.x##c.x </span>
<span id="cb3-31"><a></a><span class="kw">display</span> <span class="st">"^3, mse: "</span> %5.3f <span class="ot">`r(mse)'</span> <span class="dt">_n</span></span>
<span id="cb3-32"><a></a>fit_stat3 <span class="fu">y</span> c.x##c.x##c.x##c.x </span>
<span id="cb3-33"><a></a><span class="kw">display</span> <span class="st">"^4, mse: "</span> %5.3f <span class="ot">`r(mse)'</span> <span class="dt">_n</span></span>
<span id="cb3-34"><a></a>fit_stat3 <span class="fu">y</span> c.x##c.x##c.x##c.x##c.x </span>
<span id="cb3-35"><a></a><span class="kw">display</span> <span class="st">"^5, mse: "</span> %5.3f <span class="ot">`r(mse)'</span> <span class="dt">_n</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<p>^1, mse: 4.851</p>
<p>^2, mse: 3.196</p>
<p>^3, mse: 2.805</p>
<p>^4, mse: 3.085</p>
<p>^5, mse: 3.160</p>
</section>
<section id="when-k-rightarrow-n.-loocv" class="slide level2">
<h2>When K <span class="math inline">\(\rightarrow\)</span> N. LooCV</h2>
<ul>
<li>K-fold cross-validation has two weaknesses:
<ol type="1">
<li>Randomness: different splits may lead to different results</li>
<li>Small sample size for training may be too small</li>
</ol></li>
<li>An alternative to address both is increasing K … until K=N
<ul>
<li>This is the Leave-one-out cross-validation (LOOCV)</li>
<li>Train on N-1 observations, predict on the left-out (N=1) observation</li>
</ul></li>
<li>This can be computationally expensive, unless you are estimating Linear regression models.
<ul>
<li>LOOCV its really fast for OLS</li>
</ul></li>
</ul>
</section>
<section id="bic-vs-test-rmse" class="slide level2">
<h2>BIC vs test RMSE</h2>
<ul>
<li>In practice, BIC is the best indirect criterion – closest to test sample.</li>
<li>The advantage of BIC is that it needs no sample splitting which may be a problem in small samples.</li>
<li>The advantage of test MSE is that it makes no assumption.</li>
<li>BIC is a good first run, quick, is often not very wrong.</li>
<li>Test MSE is the best, but may be computationally expensive.</li>
</ul>
</section>
<section id="external-validity-and-stable-patterns" class="slide level2">
<h2>External validity and stable patterns</h2>
<ul>
<li>BIC, Training-test, k-fold cross-validation… All very nice
<ul>
<li>In the end, they all use the information in the data.</li>
</ul></li>
<li>How would things look for the target observation(s)? unknown!!</li>
<li>The issue of stationarity – how our data is related to other datasets we may use our model</li>
<li>In the end we can’t know but need to think about it.
<ul>
<li>Plus, if there is no external validity, your model fit in an outside data source is likely to be worse…</li>
</ul></li>
</ul>
</section>
<section id="external-validity-and-stable-patterns-1" class="slide level2">
<h2>External validity and stable patterns</h2>
<ul>
<li>Most predictions will be on future data</li>
<li>High external validity requires that the environment is stationary.</li>
<li>Stationarity means that the way variables are distributed remains the same over time.
<ul>
<li>Ensures that the relationship between predictors and the target variable is the same in the data and the forecasted future.</li>
</ul></li>
<li>If the relationship breaks down whatever we establish in our data won’t be true in the future, leading to wrong forecasts.</li>
</ul>
</section>
<section id="external-validity-and-stable-patterns-2" class="slide level2">
<h2>External validity and stable patterns</h2>
<ul>
<li>External validity and stable patterns - Very broad concept</li>
<li>It’s about representativeness of actual data <span class="math inline">\(\rightarrow\)</span> to live data
<ul>
<li>Remember hotels? (other dates, other cities).</li>
</ul></li>
<li>Domain knowledge can help. Inner knowledge of the process can help.</li>
<li>Study if patterns were stable in the past / other locations were stable can help.</li>
</ul>
</section>
<section id="main-takeaways" class="slide level2">
<h2>Main takeaways</h2>
<ul>
<li>Prediction uses the original data with <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> to predict the value of <span class="math inline">\(y\)</span> for observations in the live data, in which <span class="math inline">\(x\)</span> is observed but <span class="math inline">\(y\)</span> is not</li>
<li>Prediction uses a model that describes the patterns of association between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> in the original data</li>
<li>Cross-validation can help find the best model in the population, or general pattern, represented by the original data</li>
<li>Stability of the patterns of association is needed for a prediction with high external validity</li>
</ul>
</section>
<section id="cs-predicting-the-price-of-used-cars" class="slide level2">
<h2>CS: Predicting the price of used cars</h2>
<ul>
<li>SUse data from <a href="data_slides/used-cars.dta">here</a> for replication.</li>
<li>Drop car with price&gt;20k or those price = 1$.</li>
<li>While distribution is skewed, Log(price) is not normal either. We will keep it as is.</li>
<li>Two areas, we keep Chicago only.</li>
<li>drop if odometer&gt;100K miles</li>
<li>Variables: price, age, odometer, type, condition, cylinders, dealer</li>
</ul>
</section>
<section id="cs-competing-models" class="slide level2">
<h2>CS: Competing models:</h2>
<ul>
<li>Model 1 age, age squared</li>
<li>Model 2 age, age squared, odometer, odometer squared</li>
<li>Model 3 age, age squared, odometer, odometer squared, LE, condition , dealer</li>
<li>Model 4 age, age squared, odometer, odometer squared, LE, condition , dealer, SE, XLE, cylinder</li>
<li>Model 5 same as Model 4 but with all variables interacted with age</li>
<li>Model 6 same as Model 4 but with all variables interacted with condition</li>
</ul>
<div id="7042ea2c" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb4-1"><a></a>* setup</span>
<span id="cb4-2"><a></a><span class="kw">use</span> data_slides/used-cars.dta, <span class="kw">clear</span></span>
<span id="cb4-3"><a></a><span class="kw">global</span> model1 age c.age#c.age</span>
<span id="cb4-4"><a></a><span class="kw">global</span> model2 <span class="ot">$model1</span> lnodometer c.lnodometer#c.lnodometer</span>
<span id="cb4-5"><a></a><span class="kw">global</span> model3 <span class="ot">$model2</span> LE i.condition_recode i.dealer</span>
<span id="cb4-6"><a></a><span class="kw">global</span> model4 <span class="ot">$model3</span> <span class="kw">SE</span> XLE cylinder</span>
<span id="cb4-7"><a></a><span class="kw">global</span> model5 c.(<span class="ot">$model4</span>)##c.age</span>
<span id="cb4-8"><a></a><span class="kw">global</span> model6 c.(<span class="ot">$model4</span>)##i.condition_recode</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="cs-test-data" class="slide level2">
<h2>CS: Test Data</h2>
<ul>
<li>Assume that 20% of the data is “target” data.</li>
<li>Lets run all models, using different evaluation criteria. And see which one is the best.</li>
<li>See below for the program..Rather long</li>
</ul>
<div id="53816d9d" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb5-1"><a></a><span class="kw">gen</span> rnd = runiform()</span>
<span id="cb5-2"><a></a><span class="kw">sort</span> rnd</span>
<span id="cb5-3"><a></a><span class="kw">gen</span> <span class="kw">test</span> = <span class="dt">_n</span>/_N&lt;=.2</span>
<span id="cb5-4"><a></a></span>
<span id="cb5-5"><a></a><span class="kw">capture</span> <span class="kw">program</span> <span class="kw">drop</span> fit_stat4</span>
<span id="cb5-6"><a></a><span class="kw">program</span> fit_stat4, rclass</span>
<span id="cb5-7"><a></a>    <span class="kw">reg</span> <span class="ot">`0'</span> <span class="kw">if</span> <span class="kw">test</span>==0</span>
<span id="cb5-8"><a></a>    <span class="kw">tempvar</span> yxhat</span>
<span id="cb5-9"><a></a>    <span class="kw">predict</span> <span class="ot">`yxhat'</span> <span class="kw">if</span> <span class="kw">test</span>==1</span>
<span id="cb5-10"><a></a>    <span class="kw">replace</span> <span class="ot">`yxhat'</span> = (price-<span class="ot">`yxhat'</span>)^2  <span class="kw">if</span> <span class="kw">test</span>==1</span>
<span id="cb5-11"><a></a>    <span class="fu">matrix</span> result = <span class="fu">e</span>(r2), <span class="fu">e</span>(r2_a)</span>
<span id="cb5-12"><a></a>    <span class="kw">estat</span> <span class="kw">ic</span></span>
<span id="cb5-13"><a></a>    <span class="fu">matrix</span> result = result, <span class="fu">r</span>(S)[1,5..6]</span>
<span id="cb5-14"><a></a>    ** K-fold <span class="kw">cross</span>-validation</span>
<span id="cb5-15"><a></a>    <span class="kw">capture</span> <span class="kw">drop</span> fold</span>
<span id="cb5-16"><a></a>    <span class="kw">gen</span> fold = runiform() <span class="kw">if</span> <span class="kw">test</span>==0</span>
<span id="cb5-17"><a></a>    <span class="kw">sort</span> fold </span>
<span id="cb5-18"><a></a>    <span class="kw">drop</span> fold</span>
<span id="cb5-19"><a></a>    <span class="kw">gen</span> fold = <span class="fu">mod</span>(<span class="dt">_n</span>,5)+1 <span class="kw">if</span> <span class="kw">test</span>==0</span>
<span id="cb5-20"><a></a>    </span>
<span id="cb5-21"><a></a>    *** Kfold1</span>
<span id="cb5-22"><a></a>    <span class="kw">tempvar</span> yhat aux</span>
<span id="cb5-23"><a></a>    <span class="kw">qui</span>:<span class="kw">gen</span> <span class="ot">`yhat'</span> = .</span>
<span id="cb5-24"><a></a>    <span class="kw">qui</span>:<span class="kw">forvalues</span> i = 1/5 {</span>
<span id="cb5-25"><a></a>        <span class="kw">reg</span> <span class="ot">`0'</span> <span class="kw">if</span> fold!=<span class="ot">`i'</span> &amp; <span class="kw">test</span>==0</span>
<span id="cb5-26"><a></a>        <span class="kw">predict</span> <span class="ot">`aux'</span></span>
<span id="cb5-27"><a></a>        <span class="kw">replace</span> <span class="ot">`yhat'</span> = <span class="ot">`aux'</span> <span class="kw">if</span> fold==<span class="ot">`i'</span> &amp; <span class="kw">test</span>==0</span>
<span id="cb5-28"><a></a>        <span class="kw">drop</span> <span class="ot">`aux'</span></span>
<span id="cb5-29"><a></a>    }</span>
<span id="cb5-30"><a></a>    <span class="kw">qui</span>: <span class="kw">replace</span> <span class="ot">`yhat'</span>=(price-<span class="ot">`yhat'</span>)^2     </span>
<span id="cb5-31"><a></a>    <span class="kw">sum</span> <span class="ot">`yhat'</span> <span class="kw">if</span> <span class="kw">test</span>==0, <span class="kw">meanonly</span></span>
<span id="cb5-32"><a></a>    <span class="fu">matrix</span> result = result, <span class="fu">sqrt</span>(<span class="fu">r</span>(<span class="kw">mean</span>))</span>
<span id="cb5-33"><a></a>    *** Kfold2</span>
<span id="cb5-34"><a></a>    <span class="kw">capture</span> <span class="kw">drop</span> fold</span>
<span id="cb5-35"><a></a>    <span class="kw">gen</span> fold = runiform() <span class="kw">if</span> <span class="kw">test</span>==0</span>
<span id="cb5-36"><a></a>    <span class="kw">sort</span> fold </span>
<span id="cb5-37"><a></a>    <span class="kw">drop</span> fold</span>
<span id="cb5-38"><a></a>    <span class="kw">gen</span> fold = <span class="fu">mod</span>(<span class="dt">_n</span>,5)+1 <span class="kw">if</span> <span class="kw">test</span>==0</span>
<span id="cb5-39"><a></a>    </span>
<span id="cb5-40"><a></a>    <span class="kw">drop</span> <span class="ot">`yhat'</span>  </span>
<span id="cb5-41"><a></a>    <span class="kw">qui</span>:<span class="kw">gen</span> <span class="ot">`yhat'</span> = .</span>
<span id="cb5-42"><a></a>    <span class="kw">qui</span>:<span class="kw">forvalues</span> i = 1/5 {</span>
<span id="cb5-43"><a></a>        <span class="kw">reg</span> <span class="ot">`0'</span> <span class="kw">if</span> fold!=<span class="ot">`i'</span> &amp; <span class="kw">test</span>==0</span>
<span id="cb5-44"><a></a>        <span class="kw">predict</span> <span class="ot">`aux'</span></span>
<span id="cb5-45"><a></a>        <span class="kw">replace</span> <span class="ot">`yhat'</span> = <span class="ot">`aux'</span> <span class="kw">if</span> fold==<span class="ot">`i'</span> &amp; <span class="kw">test</span>==0</span>
<span id="cb5-46"><a></a>        <span class="kw">drop</span> <span class="ot">`aux'</span></span>
<span id="cb5-47"><a></a>    }</span>
<span id="cb5-48"><a></a>    <span class="kw">qui</span>: <span class="kw">replace</span> <span class="ot">`yhat'</span>=(price-<span class="ot">`yhat'</span>)^2    </span>
<span id="cb5-49"><a></a>    <span class="kw">sum</span> <span class="ot">`yhat'</span> <span class="kw">if</span> <span class="kw">test</span>==0, <span class="kw">meanonly</span></span>
<span id="cb5-50"><a></a>    <span class="fu">matrix</span> result = result, <span class="fu">sqrt</span>(<span class="fu">r</span>(<span class="kw">mean</span>))</span>
<span id="cb5-51"><a></a>    ** <span class="kw">test</span> <span class="kw">on</span> live <span class="kw">data</span></span>
<span id="cb5-52"><a></a>    <span class="kw">sum</span> <span class="ot">`yxhat'</span> <span class="kw">if</span> <span class="kw">test</span>==1, <span class="kw">meanonly</span></span>
<span id="cb5-53"><a></a>    <span class="fu">matrix</span> result = result, <span class="fu">sqrt</span>(<span class="fu">r</span>(<span class="kw">mean</span>))</span>
<span id="cb5-54"><a></a>    <span class="fu">matrix</span> colname result = r2 r2_a AIC BIC Kfold1 Kfold2 <span class="kw">test</span></span>
<span id="cb5-55"><a></a>    ** </span>
<span id="cb5-56"><a></a>    <span class="fu">return</span> <span class="fu">matrix</span> result = result</span>
<span id="cb5-57"><a></a><span class="kw">end</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="cs-results" class="slide level2">
<h2>CS: Results</h2>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource stata number-lines code-with-copy"><code class="sourceCode stata"><span id="cb6-1"><a></a><span class="kw">qui</span>: fit_stat4 price <span class="ot">$model1</span></span>
<span id="cb6-2"><a></a><span class="fu">matrix</span> fresults = <span class="fu">r</span>(result)</span>
<span id="cb6-3"><a></a><span class="kw">qui</span>: fit_stat4 price <span class="ot">$model2</span></span>
<span id="cb6-4"><a></a><span class="fu">matrix</span> fresults = fresults\<span class="fu">r</span>(result)</span>
<span id="cb6-5"><a></a><span class="kw">qui</span>: fit_stat4 price <span class="ot">$model3</span></span>
<span id="cb6-6"><a></a><span class="fu">matrix</span> fresults = fresults\<span class="fu">r</span>(result)</span>
<span id="cb6-7"><a></a><span class="kw">qui</span>: fit_stat4 price <span class="ot">$model4</span></span>
<span id="cb6-8"><a></a><span class="fu">matrix</span> fresults = fresults\<span class="fu">r</span>(result)</span>
<span id="cb6-9"><a></a><span class="kw">qui</span>: fit_stat4 price <span class="ot">$model5</span></span>
<span id="cb6-10"><a></a><span class="fu">matrix</span> fresults = fresults\<span class="fu">r</span>(result)</span>
<span id="cb6-11"><a></a><span class="kw">qui</span>: fit_stat4 price <span class="ot">$model6</span></span>
<span id="cb6-12"><a></a><span class="fu">matrix</span> fresults = fresults\<span class="fu">r</span>(result)</span>
<span id="cb6-13"><a></a><span class="fu">matrix</span> rowname fresults = Model1 Model2 Model3 Model4 Model5 Model6</span>
<span id="cb6-14"><a></a><span class="kw">set</span> <span class="dv">linesize</span> 250</span>
<span id="cb6-15"><a></a>esttab <span class="fu">matrix</span>(fresults, fmt(%8.3f)) , md  nomtitle</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<table class="caption-top">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: center;">r2</th>
<th style="text-align: center;">r2_a</th>
<th style="text-align: center;">AIC</th>
<th style="text-align: center;">BIC</th>
<th style="text-align: center;">Kfold1</th>
<th style="text-align: center;">Kfold2</th>
<th style="text-align: center;">test</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Model1</td>
<td style="text-align: center;">0.711</td>
<td style="text-align: center;">0.708</td>
<td style="text-align: center;">4823.338</td>
<td style="text-align: center;">4834.032</td>
<td style="text-align: center;">2472.245</td>
<td style="text-align: center;">2470.654</td>
<td style="text-align: center;">1697.617</td>
</tr>
<tr class="even">
<td>Model2</td>
<td style="text-align: center;">0.776</td>
<td style="text-align: center;">0.772</td>
<td style="text-align: center;">4760.551</td>
<td style="text-align: center;">4778.374</td>
<td style="text-align: center;">2185.247</td>
<td style="text-align: center;">2204.960</td>
<td style="text-align: center;">1345.265</td>
</tr>
<tr class="odd">
<td>Model3</td>
<td style="text-align: center;">0.779</td>
<td style="text-align: center;">0.771</td>
<td style="text-align: center;">4766.944</td>
<td style="text-align: center;">4802.590</td>
<td style="text-align: center;">2270.672</td>
<td style="text-align: center;">2307.392</td>
<td style="text-align: center;">1346.395</td>
</tr>
<tr class="even">
<td>Model4</td>
<td style="text-align: center;">0.785</td>
<td style="text-align: center;">0.775</td>
<td style="text-align: center;">4765.275</td>
<td style="text-align: center;">4811.613</td>
<td style="text-align: center;">2388.426</td>
<td style="text-align: center;">2259.348</td>
<td style="text-align: center;">1381.180</td>
</tr>
<tr class="odd">
<td>Model5</td>
<td style="text-align: center;">0.797</td>
<td style="text-align: center;">0.778</td>
<td style="text-align: center;">4772.246</td>
<td style="text-align: center;">4857.794</td>
<td style="text-align: center;">2605.005</td>
<td style="text-align: center;">2425.626</td>
<td style="text-align: center;">1481.571</td>
</tr>
<tr class="even">
<td>Model6</td>
<td style="text-align: center;">0.851</td>
<td style="text-align: center;">0.824</td>
<td style="text-align: center;">4724.611</td>
<td style="text-align: center;">4867.191</td>
<td style="text-align: center;">2555.466</td>
<td style="text-align: center;">2670.216</td>
<td style="text-align: center;">1523.569</td>
</tr>
</tbody>
</table>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p><em>Rios-Avila and Cia</em></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1200,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        // For code content inside modals, clipBoardJS needs to be initialized with a container option
        // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>