{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Multiple Regression Analysis: Inference and Asymptotics\"\n",
        "subtitle: \"Are they Significant?\"\n",
        "author: Fernando Rios-Avila\n",
        "jupyter: nbstata\n",
        "format: \n",
        "  revealjs: \n",
        "    slide-number: true\n",
        "    width: 1600\n",
        "    height: 900\n",
        "    code-fold: true\n",
        "    echo: true\n",
        "    css: styles.css \n",
        "---\n",
        "\n",
        "\n",
        "# {background-image=\"https://i.imgflip.com/7u1i0l.jpg\" background-size=\"contain\"}\n",
        "\n",
        "## How do you know if what you see is relevant?\n",
        "\n",
        "- Last time, we talk a bit about the estimation of MLRM. For those who do not remember:\n",
        "\n",
        "$$\\hat\\beta=(X'X)^{-1}X'y\n",
        "$$\n",
        "\n",
        "- We also defined how, under A5 (homoskedasticity), we can estimate the variance covariance of coefficients:\n",
        "\n",
        "$$Var(\\beta) = \\frac{\\sum \\hat e^2}{N-K-1} (X'X)^{-1}\n",
        "$$\n",
        "\n",
        "- The next question: how to know how precise your estimates are?\n",
        "\n",
        "- That *should* be simple, just divide coefficient by its Standard error. The larger this is, the more precise, and more significant.  \n",
        "\n",
        "- Is this enough to say something about the population coefficients?\n",
        "\n",
        "(lets assume A1-A5 holds)\n",
        "\n",
        "## Distribution of coefficients\n",
        "\n",
        "- The right answer is...Perhaps.\n",
        "\n",
        "- Unless you know something about the distribution of $\\beta's$, it would be hard to make any inferences from the estimates. Why?\n",
        "\n",
        "- Because not all distributions are made equal!\n"
      ],
      "id": "d82dd12c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| output: false\n",
        "*| code-fold: true\n",
        "\n",
        "clear\n",
        "range x -4 4 1000\n",
        "gen funiform = 0 \n",
        "replace funiform = 1/(2*sqrt(3)) if inrange(x,-sqrt(3),sqrt(3))\n",
        "\n",
        "gen fnormal = 0 \n",
        "replace fnormal = normalden(x)\n",
        "\n",
        "gen fchi2 = 0 \n",
        "replace fchi2 = sqrt(8)*chi2den(4,x*sqrt(8)+4)\n",
        "\n",
        "integ funiform x, gen(F1)\n",
        "integ fnormal x, gen(F2)\n",
        "integ fchi2 x, gen(F3)\n",
        "\n",
        "set scheme white2\n",
        "color_style egypt\n",
        "replace x = x + 1.5\n",
        "two (area funiform x           , pstyle(p1) color(%20)) ///\n",
        "    (area funiform x if F1<0.05, pstyle(p1) color(%80)) /// \n",
        "    (area funiform x if F1>0.95, pstyle(p1) color(%80)) /// \n",
        "    (area fnormal  x           , pstyle(p2) color(%20)) ///  \n",
        "    (area fnormal  x if F2<0.05, pstyle(p2) color(%80)) /// \n",
        "    (area fnormal  x if F2>0.95, pstyle(p2) color(%80)) /// \n",
        "    (area fchi2    x           , pstyle(p3) color(%20)) /// \n",
        "    (area fchi2    x if F3>0.95, pstyle(p3) color(%80)) /// \n",
        "    (area fchi2    x if F3<0.05, pstyle(p3) color(%80)), ///\n",
        "    xlabel(-4 / 4) legend(order(2 \"Uniform\" 5 \"Normal\" 8 \"C-Chi2\")) /// \n",
        "    xtitle(\"Beta hat Distribution\") ///\n",
        "\txline( 0, lstyle(1) lwidth(1)) xline(1.5)\n",
        "\n",
        "graph export images/f4_1.png, replace width(1200)  "
      ],
      "id": "68958131",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Not all Distributions are the Same\n",
        "\n",
        "![](images/f4_1.png){size=\"contained\" fig-align=\"center\"}\n",
        "\n",
        "## New Assumption\n",
        "\n",
        "- A6: Errors are normal $e\\sim N(0,\\sigma^2_e)$.\n",
        "  - A1-A6 are the Classical Linear Model Assumption\n",
        "  - This assumes the outcome is \"conditionally\" normal. $y|X \\sim N(X\\beta,\\sigma^2_e)$\n",
        "  - And with this assumption OLS is no longer [blue]{.bluetxt}. Its now **BUE**!\n",
        "\n",
        "## \n",
        "\n",
        "### Why does it matter?\n",
        "\n",
        "  - If you combine two variables with the same distributions, the combined variable will not have the same distributions as the \"parents\"\n",
        "  - Except with normals! if you add two -normal- distributions together. The outcome will also be normal. (Dont believe me try it)\n",
        "\n",
        "Recall:\n",
        "\n",
        "$$\\hat \\beta=\\beta + (X'X)^{-1}X'e\n",
        "$$\n",
        "\n",
        "If $e$ is normal, then $\\beta's$ will also be normal\n",
        "\n",
        "And this works for ANY Sample size!\n",
        "\n",
        "##\n",
        "### If $e$ normal then $\\beta$ is normal\n",
        "\n",
        "- If $\\hat \\beta's$ are normal, then we can use this distribution to make inferences about $\\beta's$ using normal distribution.\n",
        "\n",
        "- This is good, because we know how to do math with Normal distributions. And can used the modified Ratio:\n",
        "  \n",
        "$$z_j = \\frac{\\hat \\beta_j - \\beta_j}{sd(\\hat\\beta)}\\sim N(0,1)\n",
        "$$\n",
        "\n",
        "- Where $\\beta_j$ is what you think the True Population parameter is (your hypothesis), and $\\hat\\beta_j$ is what you estimate in your data. \n",
        "- Depending on the size of this, you can either reject your hypothesis, or **not** Reject it.\n",
        "\n",
        "but do we \"know\"   $sd(\\beta)$?\n",
        "\n",
        "## \n",
        "\n",
        "### Do we \"know\" $sd(\\beta)$?\n",
        "\n",
        "We don't, which is why we can use a normal directly. Instead we use a t-distribution, which uses $se(\\hat\\beta )$\n",
        "\n",
        "$$t_j = \\frac{\\hat \\beta_j - \\beta_j}{se(\\hat\\beta)}\\sim t_{N-k-1}\n",
        "$$\n",
        "\n",
        "Then \n",
        "\n",
        "- If $e$ is normal, $\\beta$ will be normal.\n",
        "- When Samples are \"small\" Standardized $\\beta$ will follow a t-distribution\n",
        "- But, as $N\\rightarrow \\infty$, $t_{N-k-1}\\sim N(0,1)$\n",
        "\n",
        "## Testing Hypothesis\n",
        "\n",
        "- The idea of hypothesis testing is contrasting the \"evidence\" from your data (estimates) with the beliefs we have about the population.\n",
        "\n",
        "$$y=\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + e\n",
        "$$\n",
        "\n",
        "Say I have two hypothesis. \n",
        "\n",
        "- $x_2$ has no effect on $y$. ie $H_0: \\beta_2 = 0$ \n",
        "- $x_1$ has an effect equal to 1. ie $H_0: \\beta_1 = 1$ \n",
        "\n",
        "    - Notice we make hypothesis about the population coefficients not the estimates\n",
        "\n",
        "I can \"test\" each hypothesis separately using a \"t-statistic\"\n",
        "\n",
        "$$ \\color{green}{t_2=\\frac{\\hat \\beta_2 - 0}{se(\\hat \\beta_2)}} ;\n",
        "t_1=\\frac{\\hat \\beta_1 - 1}{se(\\hat \\beta_1)} \n",
        "$$\n",
        "\n",
        "## Types of Hypothesis:\n",
        "\n",
        "When talking about hypothesis testing there are two types:\n",
        "\n",
        "- **One sided**: when your alternative hypothesis compares your null to something either strictly larger, or strictly smaller than your hypothesis.\n",
        "\t- Education has **no effect** on wages vs Returns to education are positive.\n",
        "\t- Skipping class has **no effect** on grades vs Skiping class reduces grades.\n",
        "- **Two sided**: When your alternative hypothesis is to say, \"its different than\"\n",
        "    - Returns to education is 10%, vs is not 10%\n",
        "    - Skipping class reduces grades in 0.5 points, vs not 0.5points\n",
        "\n",
        "In both cases, you use the same t-statistic. \n",
        "\n",
        "$$t_\\beta=\\frac{\\hat\\beta - \\beta_{hyp}}{se(\\hat \\beta)} \\sim t_{N-k-1}\n",
        "$$\n",
        "\n",
        "##\n",
        "\n",
        "What changes are the \"thresholds\" to Judge something significant or not.\n",
        "\n",
        "#### One sided test:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "H_0: & \\beta_k=\\beta^{hyp}_k \\text{ vs } H_1: \\beta_k>\\beta^{hyp}_k \\\\\n",
        " & t_{\\beta_k}>t_{N-k-1}(1-\\alpha) \\\\\n",
        "H_0: & \\beta_k=\\beta^{hyp}_k \\text{ vs } H_1: \\beta_k<\\beta^{hyp}_k \\\\\n",
        " & t_{\\beta_k}<-t_{N-k-1}(1-\\alpha)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- Where $\\alpha$ is your level of **significance**, and $t_{N-k-1}(1-\\alpha)$ is the critical value.\n",
        " \n",
        "- $\\alpha$ determines the \"risk\" of commiting an **error type I**: Rejecting the Null when its true.\n",
        "\n",
        "- Intuitively, the smaller $\\alpha$ is, the more possitive (negative) \"t\" needs to be reject the Null.\n",
        "\n",
        "##\n",
        "\n",
        "#### Two sided test:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "H_0: & \\beta_k=\\beta^{hyp}_k \\text{ vs } H_1: \\beta_k \\neq \\beta^{hyp}_k \\\\\n",
        " & | t_{\\beta_k} | >t_{N-k-1}(1-\\alpha/2) \n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- Similar to before, except the one needs to consider both tails of the distribution to determine critical values (see $t_{N-k-1}(1-\\alpha/2)$)\n",
        " \n",
        "- Intuitively, the smaller $\\alpha$ is, the larger the absolute value of \"t\" needs to be reject the Null.\n",
        "\n",
        "#### But, what is an error type I? and why we don't we \"accept\" $H_0$ s?\n",
        "\n",
        "# {background-image=\"https://i.imgflip.com/7u2hqd.jpg\" background-size=\"contain\"}\n",
        "\n",
        "## Why we never accept?:\n",
        "\n",
        "- As stated few times before, $\\hat \\beta$ are just approximations to the true $\\beta$ coefficients. Its the \"evidence\" you have based on the data available.\n",
        "- With this evidence, you can **reject** some hypothesis. (Some more strongly than others) \n",
        "- However, there could exists many scenarios that would fit the evidence.\n",
        "\n",
        "##\n"
      ],
      "id": "d2011c8c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| output: false\n",
        "*| code-fold: true\n",
        "clear\n",
        "range x -5 5 1000\n",
        "gen fx = normalden(x) \n",
        "set scheme white2\n",
        "color_style tableau\n",
        "gen xx = x+1\n",
        "two (area fx x , pstyle(p1) color(%20)) ///\n",
        "\t(area fx x if x<invnormal(.025), pstyle(p1) color(%80) ) ///\n",
        "\t(area fx x if x>invnormal(.975), pstyle(p1) color(%80) ) ///\n",
        "\t(area fx xx , pstyle(p2) color(%20)) ///\n",
        "\t(area fx xx if x<invnormal(.025), pstyle(p2) color(%80) ) /// \n",
        "\t(area fx xx if x>invnormal(.975), pstyle(p2) color(%80) ) ///\n",
        "    , xline(1.8) legend(order(1 \"H0: b=0\" 4 \"H0: b=1\"))\t ///\n",
        "\txlabel(-4(2)4)\tylabel(0(.1).5)  xsize(8) ysize(4)\n",
        "graph export images/f4_2.png, height(1000)\treplace"
      ],
      "id": "943b845b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](images/f4_2.png){fig-align=\"center\"}\n",
        "\n",
        "## What about Type error I and II?\n",
        "\n",
        ":::{.incremental}\n",
        "\n",
        "- Because we do not know the truth, we are bound to commit errors in our assessment of the data.\n",
        "\n",
        "- So given the data evidence and the hypothesis, there could be 2 scenarios:\n",
        "\n",
        "  - GOOD: You either reject when $H_0$ is false, or not reject when $H_0$ is true.\n",
        "  - $TE-I$: You reject $H_0$ when it is true, \n",
        "  - $TE-II$: Not reject $H_0$ when it is false (Something else was true)\n",
        "\n",
        ":::\n",
        "\n",
        "## "
      ],
      "id": "d097336c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| output: false\n",
        "*| code-fold: true\n",
        "clear\n",
        "range x -5 5 1000\n",
        "gen fx = normalden(x) \n",
        "\n",
        "gen xxx=x+3\t\n",
        "two (area fx x , pstyle(p1) color(%20)) ///\n",
        "    (area fx xxx, pstyle(p2) color(%20)) ///\n",
        "\t(area fx x if x>2, pstyle(p1) color(%80)) ///\n",
        "    (area fx xxx if xxx <2, pstyle(p2) color(%80))  ///\n",
        "    ,legend(order(1 \"H0\"3 \"Type I \" 2 \"H1\"  4 \"Type II \") cols(2))\t ///\n",
        "\txlabel(-4(2)7)\tylabel(0(.1).5) xsize(8) ysize(4)  \n",
        "graph export images/f4_3.png, height(1000)\treplace\n"
      ],
      "id": "e6777ed6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](images/f4_3.png){fig-align=\"center\"}\n",
        "\n",
        "## Example: Determinants of College GPA {.scrollable}\n"
      ],
      "id": "24e4099e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| echo: true\n",
        "\n",
        "frause gpa1, clear\n",
        "reg colgpa hsgpa act skipped"
      ],
      "id": "51ffb1bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Hypothesis: Skipping classes has no effect on College GPA.\n",
        "\n",
        "$$H_0: \\beta_{skip} = 0 \\text{ vs } H_1: \\beta_{skip} \\neq 0\n",
        "$$\n",
        "\n",
        "- Test, $a=95%$, $|t_{skip}|=3.2$ vs $t_{n-k-1}(0.975)$: \n"
      ],
      "id": "8b4e8b5a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "code-folde": false
      },
      "source": [
        "*| output: asis\n",
        "*| echo: true\n",
        "display invt(141-4,0.975)"
      ],
      "id": "2e7a9957",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Conclusion: $H_0$ is rejected.\n",
        "\n",
        "## \n",
        "\n",
        "- Hyp: Skipping college has no effect on College GPA vs has a negative effect\n",
        " \n",
        "$$H_0: \\beta_{skip} = 0 \\text{ vs } H_1: \\beta_{skip}<0\n",
        "$$\n",
        "\n",
        "- Test, $a=95\\%$, $|t_{skip}|=3.2$ vs $t_{n-k-1}(0.95)=1.6560$\n",
        "- Also Reject $H_0$\n",
        "\n",
        "##\n",
        "\n",
        "- $t_{ACT}=1.39$\n",
        "- Hyp: ACT has no effect on College GPA vs It has a non-zero effect\n",
        "- Hyp: ACT has no effect on College GPA vs it has a positive effect\n",
        "- Critical: \n",
        "  - $t_{137}(0.95)=1.6560$ Donot Reject$H_0$ with $\\alpha = 5\\%$\n",
        "  - $t_{137}(0.90)=1.2878$ Reject $H_0$ with $\\alpha = 10\\%$ \n",
        "  \n",
        "- Each GPA point in highschool translates into half a point in College GPA. vs Is less than .5\n"
      ],
      "id": "7cfd3cd7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| echo: true\n",
        "*| code-fold: false\n",
        "test hsgpa = 0.5\n",
        "lincom hsgpa - 0.5"
      ],
      "id": "583a7eb2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Critical at 5%: $t=-1.6560$\n",
        "- Cannot Reject $H_0$\n",
        "\n",
        "## p-values\n",
        "\n",
        "- Something you may or may not have noticed. The significance level $\\alpha$ can be choosen by the researcher.\n",
        "  - Conventional levels are 10%, 5% and 1%. \n",
        "- This may lead to researchers choosing any value that would make their theory fit.  \n",
        "- There is a better alternative. Using $p-values$ to capture the smallest significance level that you could use to reject your Null.\n",
        "\n",
        "$$p-value = P(|t|>|t-stat|) \\text{ or } p-value = 2*P(|t|>|t-stat|)\n",
        "$$\n",
        "\n",
        "  - The smallest the better! (for rejection)\n",
        "- How? \n",
        "  - One tail : `display 1-t(df = n-k-1, |t-stat|)`\n",
        "  - two tails: `display 2-2*t(df = n-k-1, |t-stat|)`\n",
        "\n",
        "## \n"
      ],
      "id": "23a42865"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| output: false\n",
        "clear\n",
        "range x -5 5 1000\n",
        "gen fx = normalden(x) \n",
        "local p1:display %5.1f 100*2*(1-normal(1.5)) \n",
        "local p2:display %5.1f 100*2*(1-normal(2.5)) \n",
        "two (area fx x , pstyle(p1) color(%20)) ///\n",
        "\t(area fx x if x<-1.5, pstyle(p3) color(%80) ) ///\n",
        "\t(area fx x if x>+1.5, pstyle(p3) color(%80) ) ///\n",
        "\t(area fx x if x<invnormal(.025), pstyle(p1) color(%80) ) ///\n",
        "\t(area fx x if x>invnormal(.975), pstyle(p1) color(%80) ) ///\n",
        "\t(area fx x if x<-2.5, pstyle(p2) color(%80) ) ///\n",
        "\t(area fx x if x>+2.5, pstyle(p2) color(%80) ) , ///\n",
        "\txline(-1.5 2.5) legend(order(4 \"{&alpha}=5%\" 6 \"p-value = `p2'%\" 2 \"p-value = `p1'%\")) ///\n",
        "\tylabel(0(.1).5) xlabel(-5 0 5 -1.5 2.5)\n",
        "graph export images/f4_4.png, replace width(1200)"
      ],
      "id": "e52382f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](images/f4_4.png){fig-align=\"center\"}\n",
        "\n",
        "## Note on Statistical Significance\n",
        "\n",
        "1. Statistically significant doesnt mean meaninful. And lack of it, doesnt mean is not important\n",
        "   - Keep in mind that SE may be larger or smaller due to other factors (N or Mcollinearity)\n",
        "2. Be careful of discussing the effect size. (a 1US increase in min wage is different from 1chp in min Wage)\n",
        "3. If non-significant, pay attention to the magnitude and relevance for your research. Does it have the correct sign?\n",
        "4. Incorrect signs with significant results. Either there is something wrong, or you found something interesting.\n",
        "\n",
        "# {background-image=\"https://i.imgflip.com/6qvajf.jpg\" background-size=\"contain\"}\n",
        "\n",
        "## Confidence Intervals\n",
        "\n",
        "- This is the third approach to assess how precise or significant an estimate is. You provide a Range of possible values, given the level of coverage, and SE.\n",
        "\n",
        "$$CI(\\beta_i) = [\\hat \\beta_i - \\hat \\sigma_{\\beta_i} t_{n-k-1}(1-\\alpha),\\hat \\beta_i +\\hat \\sigma_{\\beta_i} t_{n-k-1}(1-\\alpha)]\n",
        "$$\n",
        "\n",
        "- Interpretation:\n",
        "  - If we were to draw M samples, the true beta would be in this interval $1-\\alpha\\%$ of the time.\n",
        "- It allows you to see what other \"hypothesis\" would be consistent with the evidence of the estimate (you wouldnt be able to reject the Null)\n",
        "\n",
        "## CI vs T-critical and P values\n",
        "\n",
        "1. t-stat and p-values are calculated based on standardized coefficients (ratio of coefficient and SE)\n",
        "2. CI are calculated based on the actual coefficient and SE.\n",
        "\n",
        "If the p-value of a t-statistic is exactly 0.05, then the 95% CI will not include 0 (at the limit), and the t-critical ($\\alpha=5\\%$) will be the same as the t-statistic.\n",
        "\n",
        "In other words. If you use the same $\\alpha$, your conclusions would be the same regardless of using t-stat, p-value or CI. \n",
        "\n",
        "##\n"
      ],
      "id": "7e4ee66f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| output: false\n",
        "\n",
        "clear\n",
        "range x -5 5 1000\n",
        "gen fx = normalden(x) \n",
        "local p1:display %5.1f 100*2*(1-normal(1.5)) \n",
        "local p2:display %5.1f 100*2*(1-normal(2.5)) \n",
        "gen xx = x+2\n",
        "\n",
        "two (area fx x , pstyle(p1) color(%10)) ///\n",
        "\t(area fx x if x<invnormal(.025), pstyle(p1) color(%60) ) ///\n",
        "\t(area fx x if x>invnormal(.975), pstyle(p1) color(%60) ) ///\n",
        "\t(area fx xx , color(gs1%10) ) ///\n",
        "\t(area fx xx if x<invnormal(.005),  color(gs1%80) ) ///\n",
        "\t(area fx xx if x>invnormal(.995),  color(gs1%80) ) ///\n",
        "\t(area fx xx if x<invnormal(.025),  color(gs1%60) ) ///\n",
        "\t(area fx xx if x>invnormal(.975),  color(gs1%60) ) ///\n",
        "\t(area fx xx if x<invnormal(.05),  color(gs1%40) ) ///\n",
        "\t(area fx xx if x>invnormal(.95),  color(gs1%40) ), ///\n",
        "\txline(2) legend(order(5 \"CI-1%\" 7 \"CI-5%\" 9 \"CI-10%\")) ///\n",
        "\tylabel(0(.1).5) xlabel(-5 0 5 )  \n",
        "graph export images/f4_5.png, replace width(1000)"
      ],
      "id": "dbb4fc3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](images/f4_5.png){fig-align=\"center\"}\n",
        "\n",
        "# Lets make things interestings (Harder)\n",
        "\n",
        "## Testing Linear Combinations:\n",
        "\n",
        "- You may be interested in testing particular linear combinations of coefficients:\n",
        "\n",
        "$b_1 - b_2 =0 ; b_2+b_3=1 ; 2*b_4-b_5=b_6$\n",
        "\n",
        "- Doing this is \"simple\". Because is a single linear combination, you can still use \"t-stat\".\n",
        "\n",
        "$t-stat = \\frac{2*\\hat b_4 -\\hat b_5 -\\hat b_6}{se(2*\\hat b_4 -\\hat b_5 -\\hat b_6)}$\n",
        "\n",
        "- Just need SE for combined coefficients (requires knowing Variances and Covariances)\n",
        "\n",
        "- Easy way, you could use `Stata`:\n",
        "\n",
        "```{stata}{style=\"font-size: 50px\"}\n",
        "reg y x1 x2 x3 x4 x5 x6\n",
        "lincom x1-x2 or lincom 2*x4-x5-x6\n",
        "test (x1-x2=0) (x2+x3=1) (2*x4-x5=x6), mtest\n",
        "```\n",
        "\n",
        "## \n",
        "\n",
        "### Harder Way: (if you dare)\n",
        "\n",
        "**Matrix Multiplication**\n",
        "\n",
        "Assume Constant is the last coefficient:\n",
        "$$V( 2*b_4-b_5- b_6) = R' V R ; R = [0,0,0,2,-1,-1]\n",
        "$$\n",
        "\n",
        "where R are the restrictions, and V is the variance covariance matrix of $\\beta's$.\n",
        "\n",
        "Then your t-stat\n",
        "\n",
        "$$t-stat = \\frac{2*b_4-b_5- b_6}{\\sqrt{V(2*b_4-b_5- b_6)}}\n",
        "$$\n",
        "\n",
        "## \n",
        "\n",
        "### Alternative: Substitution\n",
        "\n",
        "- One can manipulate the regression model to consider a model with the contrained coefficient.\n",
        "- Once model is estimated, it simplifies testing:\n",
        "\n",
        "$$\\begin{aligned}\n",
        " & y = b_0 + b_1 x_1 + b_2  x_2 + b_3 x_3 + e  \\\\\n",
        "h0: & b_1 - 2b_2 +b_3=0 \\rightarrow \\theta = b_1 - 2b_2 +b_3 \\rightarrow b_1 = \\theta + 2b_2 - b_3 \\\\\n",
        "& y = b_0 + ( \\theta + 2b_2 - b_3) x_1 + b_2 x_2 + b_3 x_3 + e \\\\\n",
        "& y = b_0 +  \\theta x_1 + b_2( x_2 +2 x_1) + b_3 (x_3-x_1) + e \\\\\n",
        "& y = b_0 +  \\theta x_1 + b_2 \\tilde x_2 + b_3 \\tilde x_3 + e \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Here testing for $\\theta=0$ is the same as testing for $b_1 - 2b_2 +b_3$ in the original model.\n",
        "\n",
        ":::{.callout-note}\n",
        "\n",
        "Always ask something like this in Midterm, so brush up your math.\n",
        "\n",
        ":::\n",
        "\n",
        "## Testing Multiple Restrictions\n",
        "\n",
        "What if you are interested in testing multiple restrictions:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "y &= b_0 + b_1 x_1 + b_2 x_2 +b_3 x_3 + e \\\\\n",
        "& H_0: b_1 = 0 ; b_2 - b_3 =0 \\\\\n",
        "& H_1: H_0 \\text{ is false}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Easy way: `Stata` command `test` allows you to do this\n",
        "\n",
        "Otherwise, you can do it by hand:\n",
        "\n",
        "##\n",
        "\n",
        "  1. Estimate unrestricted model (original) and \"save\" $SSR_{ur}$ or $R_{ur}^2$\n",
        "  2. Impose restrictions on the model and \"save\" $SSR_r$ or $R_{r}^2$\n",
        "  3. Estimate F-stat:\n",
        "\n",
        "$$F_{q,n-k-1} = \\frac{(SSR_r - SSR_{ur})/q}{SSR_{ur}/(n-k-1)}  \\text{ or }\n",
        "\\frac{(R^2_{ur}-R^2_r)/q}{(1-R^2_{ur})/(n-k-1)} \\sim F(q,n-k-1)\n",
        "$$\n",
        "\n",
        "$SSR$ Sum of Squared Residuals, $q$ number of restrictions\n",
        "\n",
        "- Idea, you are comparing how the overall fitness of the model changes with restrictions.\n",
        "- If restrictions slightly decreases the model Fitness, you cannot be rejected them.\n",
        "- Otherwise, They are rejected! (you just dont know which)\n",
        "\n",
        "## Overall Model Significance\n",
        "\n",
        "One test, we often don't do anymore, is testing the overall fitness of a model:\n",
        "\n",
        "$$H_0: x_1, x_2, \\dots , x_k \\text{ do not explain y}\n",
        "$$\n",
        "\n",
        "$$H_0: \\beta_1=\\beta_2=\\dots=\\beta_k =0\n",
        "$$\n",
        "\n",
        "Where we kind of suggest that a model with only an intercept is better than the one with covariates.\n",
        "\n",
        "$$F_{q,n-k-1} = \\frac{(R^2_{ur}-\\color{red}{R^2_r})/q}{(1-R^2_{ur})/(n-k-1)} \\sim F(q,n-k-1)\n",
        "$$\n",
        "\n",
        "In this case $\\color{red}{R^2_r}=0$\n",
        "\n",
        "## **Not** For the faint for heart\n",
        "\n",
        "Matrix form for F-Stat!\n",
        "Restrictions:\n",
        "\n",
        "$$H_0: R_{q,k+1}\\beta_{k+1,1}=c_{q,1}\n",
        "$$\n",
        "\n",
        "First. Define matrix with all Matrix Restriction\n",
        "$$\n",
        "\\Sigma_R = R_{q,k+1} V_\\beta R'_{q,k+1}\n",
        "$$\n",
        "\n",
        "Second: F-statistic\n",
        "\n",
        "$$\n",
        "F-stat = \\frac 1 q (R\\beta-c)' \\Sigma_R^{-1} (R\\beta-c) \n",
        "$$\n",
        "\n",
        "## Example {.scrollable}\n"
      ],
      "id": "49d9389a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| code-fold: false\n",
        "frause hprice1, clear\n",
        "reg lprice lasses bdrms llotsize lsqrft"
      ],
      "id": "3176c3c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| code-fold: false\n",
        "test (lasses=1)\n",
        "test (lasses=1) (bdrms=llotsize=lsqrft=0)"
      ],
      "id": "2bd6ac59",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| code-fold: false\n",
        "frause mlb1, clear\n",
        "reg lsalary years gamesyr bavg hrunsyr rbisy"
      ],
      "id": "996b6bb4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| code-fold: false\n",
        "test bavg hrunsyr rbisy"
      ],
      "id": "b25e6625",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lets take one more Step: What if errors are not normal? \n",
        "There we go A6\n",
        "\n",
        "# {background-image=\"https://i.imgflip.com/6qwgsh.jpg\" background-size=\"contain\"}\n",
        "\n",
        "## Introduction\n",
        "\n",
        "- When considering the topic of asymptotic theory, there are few concepts that are important ton consider.\n",
        "\n",
        "  1. Asymtotics refer to properties of OLS when $N\\rightarrow \\infty$\n",
        "  2. When samples grow, we are more concern about consistency rather than \"just\" unbiased estimators.\n",
        "  3. We are also concern with how flexible is the normality assumption when samples grow large.\n",
        "\n",
        "## What is consistency?\n",
        "\n",
        "- Up until now, we have been concerned with Unbiased estimates\n",
        "\n",
        "$$E(\\hat\\beta)=\\beta\n",
        "$$\n",
        "\n",
        "- In large samples, this is no longer enough. One requires Consistency!\n",
        "  - Consistency says that as $N\\rightarrow \\infty$ then $plim \\hat \\beta = \\beta$.\n",
        "  - $p(|\\hat \\beta - \\beta|<\\varepsilon) = 1$ or that The variance shrinks to zero, or we can estimate $\\beta$ almost surely.\n",
        "  - This is also known as asymptotic unbiasness.\n",
        "  \n",
        "- In linear regression analysis, consistency can be achieved with a weaker A4': $Cov(e,x)=0$, assuming that we require only linear independence.\n",
        "\n",
        "## Consistency vs Bias\n"
      ],
      "id": "cd5bb8fa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| echo: false\n",
        "*| output: false\n",
        "*| code-fold: true\n",
        "\n",
        "clear\n",
        "set scheme white2\n",
        "set obs 21\n",
        "gen n=2^(_n-1)\n",
        "gen vr = 1/sqrt(n)\n",
        " \n",
        "\n",
        "gen ll=invnormal(0.005)*vr\n",
        "gen uu=invnormal(0.995)*vr\n",
        "\n",
        "gen n2=_n\n",
        "two rcap ll uu n2, horizontal ///\n",
        "ylabel( 1 \"1\" 3 \"`=2^2'\" 5 \"`=2^4'\" 7 \"`=2^6'\" ///\n",
        "9 \"`=2^8'\"  11 \"`=2^10'\" 13 \"`=2^12'\" 15 \"`=2^14'\" ///\n",
        "17 \"`=2^16'\" 19 \"`=2^18'\" 21 \"`=2^20'\") ///\n",
        "ytitle(\"Sample Size\") xtitle(\"99% CI\") \n",
        "\n",
        "graph export images/f4_6.png, width(1200) replace\n",
        "\n",
        "gen mn=invnormal((0.005+.75)/2)*vr\n",
        "gen uu2=invnormal(0.75)*vr\n",
        "\n",
        "two (rcap ll uu2 n2, horizontal) (line n2 mn),  ///\n",
        "ylabel( 1 \"1\" 3 \"`=2^2'\" 5 \"`=2^4'\" 7 \"`=2^6'\" ///\n",
        "9 \"`=2^8'\"  11 \"`=2^10'\" 13 \"`=2^12'\" 15 \"`=2^14'\" ///\n",
        "17 \"`=2^16'\" 19 \"`=2^18'\" 21 \"`=2^20'\") ///\n",
        "ytitle(\"Sample Size\") xtitle(\"99% CI\")  legend(off) \n",
        "graph export images/f4_7.png, width(1200) replace"
      ],
      "id": "d614ea42",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.panel-tabset}\n",
        "\n",
        "## Consistent and Unbiased\n",
        "\n",
        "![](images/f4_6.png){fig-align=\"center\" width=70%}\n",
        "\n",
        "## Consistent and Biased\n",
        "\n",
        "![](images/f4_7.png){fig-align=\"center\" width=70%}\n",
        "\n",
        ":::\n",
        "\n",
        "## What about Normality Assumption?\n",
        "\n",
        "- Everything we have seen so far was possible under the normality assumption of the errors.\n",
        "  - if $e$ is normal, then $b$ is normal (even in small samples), thus we can use $t$, $F$, etc\n",
        "\n",
        "- But what if this assumption fails? would we care?\n",
        "\n",
        "::: {.incremental}\n",
        "\n",
        "  - Perhaps. If your sample is small, $b$ will not be normal, and standard procedures will not work.\n",
        "  - In large Samples, however, $\\beta's$ will be normal, even if $e$ is not. Thanks to CLT\n",
        "\n",
        ":::\n",
        "\n",
        "##\n",
        "\n",
        "### Good news\n",
        "\n",
        "- Bottom line, when $N$ is large, you do not need $e$ to be normal.\n",
        "  \n",
        "- if A1-A5 hold, you can rely on asymptotic normality!\n",
        "\n",
        "- Thus you can still use t's and F's, but you can also use LM\n",
        "  \n",
        "## LM-Lagrange Multiplier\n",
        "\n",
        "- While you can still use t-stat and F-stat to draw inference from your model, there is a better test (given the large sample): Lagrange Multiplier Statistic\n",
        "- The idea: Does impossing restrictions affect the model Fitness? \n",
        "\n",
        "1. Regress $y$ on restricted $x_1,\\dots,x_{k-q}$, and obtain $\\tilde e$\n",
        "2. Regress $\\tilde e$ on all $x's$, and obtain $R^2_e$. \n",
        "   \n",
        "If the excluded regressors were not significant, the $R^2_e$ should be very small.\n",
        "\n",
        "3. Compare $nR^2_e$ with $\\chi^2(n,1-\\alpha)$, and draw conclusions.\n",
        "\n",
        "## Example:{.scrollable}\n"
      ],
      "id": "f572f0b7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| code-fold: false\n",
        "*| echo: true\n",
        "*| classes: larger\n",
        " \n",
        "frause crime1, clear\n",
        "qui: reg narr86 pcnv avgsen tottime ptime86 qemp86\n",
        "** H0: avgsen=0 and tottime=0\n",
        "test (avgsen=0) (tottime=0)"
      ],
      "id": "96c4ba3c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| code-fold: false\n",
        "*| echo: true\n",
        "*| classes: larger\n",
        "\n",
        "qui: reg narr86 pcnv                ptime86 qemp86\n",
        "* Predict residuals of constrained model\n",
        "predict u_tilde , res\n",
        "* regress residuals againts all variables\n",
        "reg u_tilde  pcnv avgsen tottime ptime86 qemp86"
      ],
      "id": "765866ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| output: asis\n",
        "*| classes: larger\n",
        "\n",
        "display \"Chi2(2)=\" `=e(N)*e(r2)'\n",
        "display \"Its p-value=\" %5.4f `=1-chi2(2, `=e(N)*e(r2)' )'"
      ],
      "id": "ff283e12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Try making it a program if you \"dare\"\n",
        "\n",
        "# Thats All folks!\n",
        "\n",
        "# Part II: \n",
        "# Addressing Problems with MRA\n"
      ],
      "id": "ac52acf5"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "nbstata",
      "language": "stata",
      "display_name": "Stata (nbstata)",
      "path": "C:\\Users\\Fernando\\AppData\\Roaming\\jupyter\\kernels\\nbstata"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}