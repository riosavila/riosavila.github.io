{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Multiple Regression Analysis\"\n",
        "subtitle: \"Specification and Data Issues: A1 how could you!\"\n",
        "author: Fernando Rios-Avila\n",
        "jupyter: nbstata\n",
        "format: \n",
        "  revealjs: \n",
        "    slide-number: true\n",
        "    width: 1600\n",
        "    height: 900\n",
        "    code-fold: true\n",
        "    code-overflow: wrap\n",
        "    echo: true\n",
        "    css: styles.css \n",
        "    chalkboard: true  \n",
        "---\n",
        "\n",
        "\n",
        "## What do we mean with model miss-specification\n",
        "\n",
        "- There are various kinds of model specification we will talk about.\n",
        "  - There are important variables you did not include in your model: Endogeneity\n",
        "  - You added all relevant variables...just not in the right way. \n",
        "  - You added proxies for variables you had no access to (Question change)\n",
        "  - You have all relevant data, but with errors.\n",
        "  - You have some missing data\n",
        "\n",
        "# Functional Form Misspecification\n",
        "\n",
        "## \n",
        "\n",
        "- Simple linear functions work in almost ALL cases. They can be thought as first order Taylor expansions:\n",
        "$$\\begin{aligned}\n",
        "y &= f(x) + e \\\\\n",
        "f(x) &\\simeq f(x_0) \n",
        "+\\frac{\\partial f(x)}{\\partial x}|_{x=x_0}\n",
        "(x-x_0)+R+e \\\\\n",
        "f(x) &\\simeq \\color{red}{ f(x_0)}\n",
        "\\color{red}{-\\frac{\\partial f(x)}{\\partial x}|_{x=x_0} x_0}\n",
        "+\\frac{\\partial f(x)}{\\partial x}|_{x=x_0} x+R+e \\\\\n",
        "y &= \\color{red}{\\beta_0}+\\beta_1 x + R+ e\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "So, for \"reasonable\" values of X, or when analyzing average marginal effects $R$ should be small enough to be ignored.\n",
        "\n",
        "- In other words, for Overall effects Simple linear model works reasonably well! (most of the time)\n",
        "    \n",
        "## {.scrollable}\n",
        "\n",
        "- If you are interested in individuals (or alike people), you may need flexiblity!\n",
        "  \n",
        "- Ignoring functional form misspecification imposes unwanted assumptions (homogeneity), that could create further problems.\n",
        "    - Specially if data is skewed\n",
        "\n",
        "- But how flexible is flexible enough?\n",
        "\n",
        "    - We will only consider quadratic terms and interactions,\n",
        "    - but there is a large literature on making very flexible estimations (non-paramatric analysis)\n"
      ],
      "id": "9bee6fe4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clear\n",
        "set seed 10\n",
        "set obs 1000\n",
        "gen p = (2*_n-1)/(2*_N) \n",
        "gen x = invchi2(5, p)/2\n",
        "gen y = 1 + x + (x-2.5)^2 + rnormal()  \n",
        "reg y x\n",
        "display \"Quadratic\"\n",
        "qui:reg y c.x##c.x\n",
        "margins, dydx(x)\n",
        "display \"Cubic\"\n",
        "qui:reg y c.x##c.x##c.x\n",
        "margins, dydx(x)"
      ],
      "id": "2404a93c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reset Ramsey test\n",
        "\n",
        "- Intuition: If the model is misspecified, perhaps we need to control for more non-linearities and interactions.\n",
        "- Naive test: Add more controls (quadratics and interactions) (like White test, this will grow fast)\n",
        "- Reset - Ramsey test: Get predictions from original model, and add it as control\n",
        "\n",
        "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\delta_1 \\hat y^2 + \\delta_2 \\hat y^3 +e\n",
        "$$\n",
        "\n",
        "$H_0: \\delta_1 = \\delta_2 = 0$: (everything is awesome)\n",
        "\n",
        "$H_1: H_0$ is false: we need to fix the problem \n",
        "\n",
        "- RRT does not tell you \"How\" to fix the problem.\n",
        "  \n",
        "```stata\n",
        "estat ovtest\n",
        "```\n",
        "(bad name tho)\n",
        "\n",
        "## Davidson-MacKinnon test\n",
        "\n",
        "Two non-tested models:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "y &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + e \\\\\n",
        "y &= \\gamma_0 + \\gamma_1 log(x_1) + \\gamma_2 log(x_2) + e \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- Which one is more appropriate? eq1? or eq2? This are non-nested models, so its difficult to say.\n",
        "  - You could nest them:\n",
        "\n",
        "$$y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 log(x_1) + \\theta_4 log(x_2) + e \n",
        "$$\n",
        "\n",
        "  and test $\\theta_1=\\theta_2=0$ or $\\theta_3=\\theta_4=0$.\n",
        "\n",
        "##\n",
        "\n",
        "- or the \"true\" Davidson-MacKinnon test:\n",
        "  - First Obtain predictions from competing models:\n",
        "$$\\begin{aligned}\n",
        "\\hat y &= \\hat\\beta_0 + \\hat\\beta_1 x_1 + \\hat\\beta_2 x_2 \\\\\n",
        "\\check y &= \\hat \\gamma_0 + \\hat\\gamma_1 log(x_1) + \\hat\\gamma_2 log(x_2) \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "  - Then add the predictions as added controls in the alternative model:\n",
        "$$\\begin{aligned}\n",
        "y &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\theta_1 \\check y +e \\\\\n",
        "y &= \\gamma_0 + \\gamma_1 log(x_1) + \\gamma_2 log(x_2) + \\theta_1 \\hat y + e \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- Unfortunately, you may ended up with conflicting results.\n",
        "\n",
        "# Proxy Variables \n",
        "For unobserved variables\n",
        "\n",
        "## A re-tell of Omitted variable Bias\n",
        "\n",
        "- We know this. If a variable that SHOULD be in the model is not added, it will generate an OMV, unless it was uncorrelated to the model error. \n",
        "  - Lesson: add important variables!\n",
        "- What if those variables are not available? how do you solve the problem?\n",
        "  - IV (we will talk about that later) or\n",
        "  - Proxy Variable (a bandaid)\n",
        "\n",
        "## Proxies\n",
        "Consider:\n",
        "$$log(wages) = \\beta_0 + \\color{blue}{\\beta_1} exper + \\color{blue}{\\beta_2} educ + \\beta_3 skill + e\n",
        "$$\n",
        "\n",
        "Where you are really interested in $\\beta_1 \\And \\beta_2$.\n",
        "\n",
        "- Since we dont have $skill$, and omitting it will bias our coefficients, we can use a proxy $ASVAB$.\n",
        "\n",
        "$$log(wages) = \\beta_0 + \\color{blue}{\\beta_1} exper + \\color{blue}{\\beta_2} educ + \\gamma_3 ASVAB + e\n",
        "$$\n",
        "\n",
        "- and done?\n",
        "\n",
        "##\n",
        "\n",
        "Using a Proxy will work only under the following condition:\n",
        "\n",
        "- Conditioning on the observed variable and proxy, the unobserved variable **has** to be uncorrelated to other variables in the model:\n",
        "  \n",
        "$$\\begin{aligned}\n",
        "E(x_3^*|x_1,x_2,x_3)&=\\alpha_0 + \\alpha_1 x_3 \\\\\n",
        "E(skill|exper,educ,ASVAB)&=\\alpha_0 + \\alpha_1 ASVAB \n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "If this happens, you can still estimate $\\beta_1 \\And \\beta_2$, although the constant and slope of the proxy varible will be biased for the proxied variable.\n",
        "\n",
        "$$\\begin{aligned}\n",
        "y &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x^*_3 + e \\ ; \\ \n",
        "\\color{blue}{x^*_3 =  \\delta_0 + \\delta_1 x_3 + v} \\\\\n",
        "y &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 (\\delta_0 + \\delta_1 x_3 + v) + e \\\\\n",
        " &= \\color{brown}{\\beta_0 +\\beta_3\\delta_0} \\color{black}{+ \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 \\delta_1 x_3 +} \\color{green}{\\beta_3 v + e} \\\\\n",
        " &=\\color{brown}{\\alpha_0} + \\beta_1 x_1 + \\beta_2 x_2 + \\alpha_1 x_3 + \\color{green}{u} \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## {.scrollable}\n",
        "### What about Lags (of dep variable)?\n",
        "\n",
        "- Increses Data requirements (panel? pseudo panel?)\n",
        "- Further assumptions are required (Past exogenous of present)\n",
        "- But allows controlling for underlying factors or historical factors\n"
      ],
      "id": "8905c3ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "frause crime2, clear\n",
        "qui:reg crmrte unem llawexpc if year == 87\n",
        "est sto m1\n",
        "qui:reg crmrte unem llawexpc lcrmrt_1 if year == 87\n",
        "est sto m2\n",
        "qui:reg ccrmrte unem llawexpc if year==87  \n",
        "est sto m3\n",
        "esttab m1 m2 m3, se star(* .1 ** 0.05 *** 0.01) b(3) ///\n",
        "mtitle(crimert crimert change_crrt)"
      ],
      "id": "d1972ca0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: Skip 9-2c and 9-3\n",
        "\n",
        "# Measurement error\n",
        "\n",
        "## Why is $X$ not the real $X$?\n",
        "\n",
        "- Often we treat data as if it they were perfect measures of the true data. But is that the case? \n",
        "  - Age: Do you report age in years, months, days, hours, minutes, etc\n",
        "  - Weight and Height: Even if measured, how accurate it can be? and do they make mistakes?\n",
        "  - Income: Do people report income accurately? or they Lie? why?\n",
        "\n",
        "- Depending on the type of error, magnitude, and if the affected variable is dep or indep, it may have diffrent consequences for OLS.\n",
        "\n",
        "- For now we will concentrate on a specific kind of measurement error: Classical measurement error\n",
        "\n",
        "$$\\begin{aligned} \n",
        "y_{obs} &= y_{true} + \\varepsilon \\\\\n",
        "E(\\varepsilon) &=0; cov(\\varepsilon,y_{true})=0; cov(\\varepsilon,X's)=0\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## Error in $y$ (dep variable) {.scrollable}\n",
        "\n",
        "- Instead of: $y^* = x\\beta + e$\n",
        "\n",
        "- We estimate $y^*+\\varepsilon = x\\beta + e \\rightarrow y^* = x\\beta + e-\\varepsilon$\n",
        "\n",
        "- This implies that $\\beta's$ can still be **unbiased** when applying OLS.\n",
        "\n",
        "- However **variance** will be larger than when using true data:\n"
      ],
      "id": "1e673ce3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "qui: frause oaxaca, clear\n",
        "set seed 101\n",
        "gen lnwage2=lnwage + rnormal(2) \n",
        "qui:reg lnwage educ exper female\n",
        "est sto m1\n",
        "qui:reg lnwage2 educ exper female\n",
        "est sto m2\n",
        "esttab m1 m2, se"
      ],
      "id": "c43ecdc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Error in $X$ (indep variable) {.scrollable}\n",
        "\n",
        "- Instead of: $y = \\beta_0 + \\beta_1 x^* + e$\n",
        "- We estimate $y = \\gamma_0 + \\gamma_1 (x^* + \\varepsilon) + v$\n",
        "  \n",
        "- By adding an error $\\varepsilon$ that has a zero relationship with $y$, the \"average\" coefficient $\\gamma_1$ will be between the true $\\beta_1$ and 0.\n",
        "$$\\begin{aligned}\n",
        "\\gamma_1 &=\\frac{\\sum (y-\\bar y)(x^* + \\varepsilon - \\bar x)}{\\sum (x^* + \\varepsilon - \\bar x)^2} =\\frac{\\sum (y-\\bar y)(x^* - \\bar x)+ \\sum (y-\\bar y) \\varepsilon}{\\sum (x^* - \\bar x)^2 + \\sum \\varepsilon^2} \\\\\n",
        " &= \\frac{\\sum (y-\\bar y)(x^* - \\bar x)}{\\sum (x^* - \\bar x)^2 + \\sum \\varepsilon^2} \\frac{\\sum (x^* - \\bar x)^2}{\\sum (x^* - \\bar x)^2} \\\\\n",
        " & =\\beta_1 \\frac{\\sigma^2_x}{\\sigma^2_x + \\sigma^2_\\varepsilon}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## \n"
      ],
      "id": "b0142186"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "frause oaxaca, clear\n",
        "qui:sum educ\n",
        "gen educ_error = educ + rnormal()*r(sd)\n",
        "sum educ educ_error\n",
        "qui:reg lnwage educ\n",
        "est sto m1\n",
        "qui:reg lnwage educ_error\n",
        "est sto m2\n",
        "esttab m1 m2, se"
      ],
      "id": "f9506fa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Missing Data, Nonrandom samples, and outliers\n",
        "\n",
        "## Missing Data (Assume Sample is complete)\n",
        "\n",
        "- What is it? you dont have data! Your $N$ falls.\n",
        "  - Some data for some observations are missing.\n",
        "  - We may or may not know why they are missing\n",
        "  - and they maybe missing at random, or following unknown patterns.\n",
        "\n",
        "- If we are Missing data, and we do not know why, its a problem. We cant know if the sample represents the population, thus cannot be used for analysis.\n",
        "\n",
        "##\n",
        "### How to deal with it?\n",
        "\n",
        "- if Missing **completely** at random (MCAR), analysis can be done as usual (no effects except smaller N)\n",
        "- if Missing **at** random (MAR), the analysis can be done, often using standard methods:\n",
        "  - Missingness depends on observed factors ($X's$).\n",
        "  - It is also known as exogenous sample selection.\n",
        "  - **Intuitively**, because all factors that determine selection are exogenous, you can identify who in the population is identified (Regression for men, women, high education, etc)\n",
        "- If Missing **not** at random (MNAR), you cant address the problem with standard analysis.\n",
        "  - Some methods such as Heckman selection or truncated regression, could be used. (advanced)\n",
        "  - Other wise, you can't analyze the data (in a satisfactory manner)\n",
        "  - **Intuitively**, missingness is determined by unobserved factors, which also determines the outcome. (ie Analyze high wage population only)\n",
        "\n",
        "## Outliers and influencers\n",
        "\n",
        "- Not all data is made equal, and not all data has the same weight when estimating regressions.\n",
        "\n",
        "- Observations with high Influence are those with outliers based on the conditional distribution ($y|x$).\n",
        "- \n",
        "  - While outliers are not necessarily bad for analysis, it is important to understand how sensitive your results are to excluding some observations.\n",
        "\n",
        "- Observations with high **leverage** are those with unusual characteristics.($X's$)\n",
        "\n",
        "- Combination of both may have strong impacts on the regression analysis.\n",
        "\n",
        "##\n",
        "\n",
        "- Leverage of an observation is determined by the following:\n",
        "\n",
        "Define $H = X(X'X)^{-1}X'$\n",
        "\n",
        "Leverage $h_i = H[i,i]$\n",
        "\n",
        "High $h_i$ denotes more influence in the model. (sensitive)\n",
        "\n",
        "- Influence is typically detected based on \"studentized\" residuals\n",
        "  \n",
        "$$r_i =  \\frac{\\hat e}{s_{-i}\\sqrt{1-h_i}}\n",
        "$$\n",
        "\n",
        "## Example\n"
      ],
      "id": "ad311690"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "qui:{\n",
        "frause oaxaca, clear\n",
        "drop if lnwage==.\n",
        "reg lnwage educ exper tenure female age\n",
        "predict lev, lev\n",
        "sum lev, meanonly\n",
        "replace lev=lev/r(mean)\n",
        "predict rst, rstud\n",
        "}\n",
        "set scheme white2\n",
        "color_style tableau\n",
        "scatter lev rst"
      ],
      "id": "19fd0d02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solutions\n",
        "\n",
        "- The problem with OLS is that it provides \"too much weight\" to outliers.\n",
        "\n",
        "- This is similar to the mean, which may not be very stable with extreme distributions. \n",
        "\n",
        "There are at least two solutions to problems with outliers.\n",
        "\n",
        "- Robust Regression (different from regression with robust Standard errors)\n",
        "  - The idea is to penalize outliers, to reduce the impact on the estimated coefficients.\n",
        "\n",
        "## \n",
        "\n",
        "- Quantile (median) Regression\n",
        "  - Modifies the objective function to be minized:\n",
        "  \n",
        "$$\\beta's=\\min_\\beta \\sum |y-x\\beta|\n",
        "$$\n",
        "\n",
        "- Instead of using the squared of errors, it uses the absolute value. \n",
        "  - by doing this, coefficients are not sensitive to outliers! (as the median is better than the mean to capture typical values)\n",
        "  - Drawbacks: Its slower than OLS, and it can be difficult to interpret\n",
        "  \n",
        "```stata{style=\"font-size: 1.3em\"}\n",
        "rreg <- Robust Regression\n",
        "qreg <- Quantile Regression\n",
        "```\n",
        "\n",
        "# Done for now\n",
        "Next week Midterm!\n",
        "and after that helping with A4"
      ],
      "id": "c42f2526"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "nbstata",
      "language": "stata",
      "display_name": "Stata (nbstata)",
      "path": "C:\\Users\\Fernando\\AppData\\Roaming\\jupyter\\kernels\\nbstata"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}