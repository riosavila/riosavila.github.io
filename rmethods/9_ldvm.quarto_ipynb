{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Limited Dependent Variable Models\"\n",
        "subtitle: \"MLE-Mua ha ha ha\"\n",
        "author: Fernando Rios-Avila\n",
        "jupyter: nbstata\n",
        "format: \n",
        "  revealjs: \n",
        "    slide-number: true\n",
        "    width: 1600\n",
        "    height: 900\n",
        "    code-fold: true\n",
        "    code-overflow: wrap\n",
        "    echo: true\n",
        "    css: styles.css \n",
        "    chalkboard: true  \n",
        "---\n",
        "\n",
        "\n",
        "## What do we mean Limited??\n"
      ],
      "id": "53dd6845"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| output: false\n",
        "\n",
        "clear\n",
        "set obs 2000\n",
        "gen r1 = runiform()\n",
        "gen r2 = rchi2(5)/5 \n",
        "gen r3 = round(rchi2(3))*3\n",
        "gen r4 = rnormal()\n",
        "set scheme white2\n",
        "color_style tableau\n",
        "histogram r1, name(m1, replace) \n",
        "histogram r2, name(m2, replace)\n",
        "histogram r3, name(m3, replace) width(1)  \n",
        "histogram r4, name(m4, replace)\n",
        "graph combine m1 m2 m3 m4\n",
        "graph export images/fig9_1.png, width(1000) replace"
      ],
      "id": "ede9b6a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Limited Dependent variables](images/fig9_1.png)\n",
        "\n",
        "##\n",
        "\n",
        "### What do we mean Limited?? {.middle}\n",
        "\n",
        "- When we think about \"limited dependent variable\" models, we refer to models when the distribution of the dep.variable is \"limited\"\n",
        "  - In other words. The values it can take are restricted! (positive, or only integer), within a range, etc\n",
        "\n",
        "- Can you still use LRM for them? \n",
        "- Will anything change if you do?\n",
        "- Do we care?\n",
        "\n",
        "## No we dont, but..\n",
        "\n",
        "- We dont really care. In fact we have already use LRM on that fashion:\n",
        "  - LPM: Dep variable was a Dummy\n",
        "  - Wages: Always positive\n",
        "  - \\# Children: Countable\n",
        "\n",
        "- But, there are couple of things one should consider.\n",
        "  1. Models of this kind are usually heteroskedastic by construction. (robust? Weighted?)\n",
        "  2. Predictions could made no sense. \n",
        "  3. There are better models we could use to analyze the data\n",
        "\n",
        "**Better** under some assumptions\n",
        "\n",
        "- However, this models cannot be estimated using OLS (there is no \"close form solution\")\n",
        "- We ***may*** need to learn a new method: Maximum Likelihood \n",
        "\n",
        "\n",
        "## Probits and Logits\n",
        "\n",
        "- **LPM** are easy, fast, and good for most data analysis (exploration). But they have some limitations.\n",
        "- Most limitations can be overcome with alternative models: Logit or Probit\n",
        "- In constrast with LPM (which aims to explain individual outcomes), Logit/probit aims to explain Conditional Probabilities:\n",
        "\n",
        "$$p(y=1|x) = G(x\\beta)$$\n",
        "\n",
        "- where the function $G()$ makes sure the predicted outcome is always between 0 and 1. \n",
        "- Caveat: Because $G()$ is nonlinear, this is a nonlinear model, and marginal effects are harder to estimate.\n",
        "\n",
        "##\n",
        "\n",
        "### What to use for $G()$\n",
        "\n",
        "- Two leading options:\n",
        "\n",
        "$$logit: G(x\\beta) = \\frac{\\exp{x\\beta}}{1+\\exp{x\\beta}}$$\n",
        "$$probit: G(x\\beta) = \\Phi(x\\beta)=\\int_{-\\infty}^{x\\beta}\\phi(z)dz$$\n",
        "\n",
        "- But in practice Either will work. Then why the difference?\n",
        "\n",
        "## \n",
        "\n",
        "### Probits and Logits: Latent variables\n",
        "\n",
        "- It all comes down to the Latent variable!\n",
        "\n",
        "- Assumption: \n",
        "  - Everybody has a latent score on every \"binary\" decision: The value to a decision $y^*$\n",
        "    $$y^* = x\\beta + e $$\n",
        "\n",
        "  - If $y^*$ is above certain threshold ($y^*>0$), you \"do\" something ($y=1$). If not you dont ($y=0$).\n",
        "- Thus the choice between logit and probit depends on the distribution of $e$.\n",
        "  - $e$ is normal, then probit\n",
        "  - $e$ is logistic, then logit\n",
        "\n",
        "\n",
        "##\n",
        "\n",
        "### Some Math\n",
        "\n",
        "Latent Model:\n",
        "\n",
        "$$ y^* = x\\beta + e $$\n",
        "\n",
        "We aim to measure the probablity of a positive latent. \n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(y^*>0|x) & = P(x\\beta + e>0|x) \\\\\n",
        "& = P( e>- x\\beta|x) \\\\\n",
        "& = 1 - P( e < - x\\beta|x) = 1-G( - x\\beta|x) \\\\\n",
        "& = G(x\\beta)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "last step valid only if $G()$ is symetrical. \n",
        "\n",
        "\n",
        "##\n",
        "\n",
        "###  Marginal Effects?\n",
        "\n",
        "- Same as before. The partial derivative!\n",
        "\n",
        "$$\\begin{aligned}\n",
        "p(y=1|x) &= G(\\beta_0 + \\beta_1 x_1 +\\beta_2 x_2 ) \\\\\n",
        "\\frac{\\partial p(y=1|x)}{\\partial x_1} = G'(x\\beta)\\beta_1=g(x\\beta)\\beta_1\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- But if variables are dummies, we need to estimate true effect.\n",
        "\n",
        "$$\\begin{aligned}\n",
        "p(y=1|x) &= G(\\beta_0 + \\beta_1 x_1 +\\beta_2 D_2 ) \\\\\n",
        "\\frac{\\partial p(y=1|x)}{\\partial D_2} = G(\\beta_0 + \\beta_1 x_1 +\\beta_2 )-G(\\beta_0 + \\beta_1 x_1 )\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "and yes, you could also have interactions, polynomials, etc\n",
        "\n",
        "## MLE: How does this work?\n",
        "\n",
        "- MLE: Maximum Likelihood Estimator, is an alternative method to OLS that allows you to estimate parameters in nonlinear models.\n",
        "- The idea of the method is to \"model\" the conditional distribution of the data $F(y|x,\\theta)$ or $f(y|x,\\theta)$, assuming $X's$ are given and modifying values of $\\theta$ (distribution parameters).\n",
        "\n",
        "- $LRM$ **could** be estimated via MLE, but you will need More assumptions:\n",
        "  - The error $e$ is normal.\n",
        "- Then \"simply\" find the parameters for the mean and variance that \"maximizes\" the probability that data Comes a given distribution.\n",
        "\n",
        "- In the case of Probit/logit, there is \"only\" one paramter we need to identify. The conditional probabilty $p(y=1|X)$.\n",
        "  - Except that we allow this to vary by $X$\n",
        "\n",
        "## Likelihood function for Logit/probit\n",
        "\n",
        "$$L_i = G(x\\beta)^{y=1}*(1-G(x\\beta))^{y=0} \n",
        "$$\n",
        "\n",
        "Under Independence:\n",
        "\n",
        "$$L_D = L_1 \\times L_2 \\times \\dots L_N\n",
        "$$\n",
        "\n",
        "Thus we need to find the $\\beta's$ that make $L_D$ the largest.\n",
        "\n",
        "But because we like sums over products:\n",
        "\n",
        "$$LL_D = \\sum_{i=1}^N log(L_i)\n",
        "$$\n",
        "\n",
        "##\n"
      ],
      "id": "2fc44c47"
    },
    {
      "cell_type": "code",
      "metadata": {
        "outcome": false
      },
      "source": [
        "  clear\n",
        "  set obs 25\n",
        "  gen r = runiform()<.7\n",
        "  mata: \n",
        "    r = st_data(.,\"r\")\n",
        "    ll = J(99,2,0)\n",
        "    for(i=1;i<=99;i++){\n",
        "      theta = i/100\n",
        "      // Log Properties\n",
        "      ll[i,]= theta,exp(sum(log(theta:^(r:==1) :* (1-theta):^(r:==0))))\n",
        "    }\n",
        "  end\n",
        "  qui getmata ll*=ll , force\n",
        "  ren ll1 theta\n",
        "  ren ll2 likelihood\n",
        "  *scatter likelihood theta \n"
      ],
      "id": "7e4a9d89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| echo: false\n",
        "qui:scatter likelihood theta "
      ],
      "id": "8a7f0ba2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing?\n",
        "\n",
        "- You can test two things:\n",
        "  - Test coefficients ($\\beta$)\n",
        "  - Test marginal effects ($G'(x\\beta)\\beta$)\n",
        "- Both test will most likely agree with each other, but some contradictions may arise.\n",
        "### How? \n",
        "- z-test and/or Wald test: Similar to t-test and Joint F-test we cover before. But, we now make the assumption of normality (not t-distribution)\n",
        "- Log-Likelihood test. Similar to F-test for restricted and unrestricted model:\n",
        "\n",
        "  - Estimate both Restricted and unrestricted model. And obtain their Log Likelihoods ($\\mathcal{L}_ur$) and ($\\mathcal{L}_r$).\n",
        "\n",
        "  $$LR = 2 (\\mathcal{L}_ur-\\mathcal{L}_r) \\overset{a}\\sim \\chi^2_q$$\n",
        "\n",
        "## Stata - Example {.scrollable}\n"
      ],
      "id": "547916f3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| classes: larger\n",
        "frause mroz, clear\n",
        "* LPM with Robust Standard errors\n",
        "qui:reg inlf nwifeinc educ exper expersq age kidslt6 kidsge6, robust\n",
        "est sto m1\n",
        "qui:logit inlf nwifeinc educ exper expersq age kidslt6 kidsge6, \n",
        "est sto m2a\n",
        "qui:margins, dydx(*) post\n",
        "est sto m2b\n",
        "probit inlf nwifeinc educ exper expersq age kidslt6 kidsge6, \n",
        "est sto m3a\n",
        "qui:margins, dydx(*) post\n",
        "est sto m3b"
      ],
      "id": "e58d3c7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set linesize 255\n",
        "*| classes: larger\n",
        "display \"Prob Models\"\n",
        "esttab m1 m2a m2b m3a m3b, scalar(r2 ll) cell(b(fmt(%5.3f)) ///\n",
        "se(par([ ])) p( par(( )) ) )  gap  mtitle(LPM Logit Logit-mfx Probit Probit-mfx)"
      ],
      "id": "f2f547f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| classes: larger\n",
        "*| code-fold: false\n",
        "\n",
        "display \"LR test\"\n",
        "qui:probit inlf nwifeinc educ exper expersq age kidslt6 kidsge6 motheduc fatheduc, \n",
        "est sto unrestricted\n",
        "qui:probit inlf nwifeinc educ exper expersq age kidslt6 kidsge6 , \n",
        "est sto restricted\n",
        "lrtest unrestricted restricted"
      ],
      "id": "a3f502d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Break? (5 mins!)\n",
        "\n",
        "## Censored and Truncated Data\n",
        "\n",
        "- Logits and Probits, are not the only models that require MLE for estimation. \n",
        "  - Among Discrete data models, you also have ologit/oprobit for ordered responses. mlogit/mprobit for unordered ones. Extends on logit/probit.\n",
        "- There are other interesting cases:\n",
        "  - When Data is censored.\n",
        "  - When Data is truncated.\n",
        "\n",
        "## Three Cases\n",
        "\n",
        ":::{.panel-tabset}\n",
        "\n",
        "## Case 1\n",
        "\n",
        "- $y$ is \"conditionally-normal\" and is Fully Observed.\n",
        "- You can estimate the model using OLS or ML\n"
      ],
      "id": "7e0e7cd8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| fig-align: center\n",
        "\n",
        "qui:{\n",
        "  clear\n",
        "  set obs 999\n",
        "  gen p   = _n/(_N+1)\n",
        "  gen fob = invnormal(p)\n",
        "}\n",
        "qui:histogram fob"
      ],
      "id": "04ef9975",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case 2\n",
        "\n",
        "- Data is observed for everyone, but is \"censored\" for some. `tobit`\n",
        "  - Either corner solution (how many hours you study) or Recoded: $y_{obs} = max(c,y^*)$\n"
      ],
      "id": "cb3fa7e3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| fig-align: center\n",
        "*| echo: false*| \n",
        "qui: replace fob = -2 if fob<-2\n",
        "qui:histogram fob, xlabel(-4 (2) 4)"
      ],
      "id": "9ff6ee22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case 3\n",
        "\n",
        "- Below (or above) some threshold, you do not have information on $y$. `truncreg` \n",
        "$$y_{obs} = y^* \\text{ if } y^*>c$$\n"
      ],
      "id": "0df15d63"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| echo: false\n",
        "*| fig-align: center\n",
        "qui: replace fob = . if fob<=-2\n",
        "qui:histogram fob, xlabel(-4 (2) 4)"
      ],
      "id": "1743b74b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Estimation: Censored and Corner Solution\n",
        "\n",
        "If data is censored or corner solution the estimation strategy is based on:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "L_i &= \\frac{1}{\\sigma} \\phi\\left( \\frac{y-x\\beta}{\\sigma} \\right) \\text{ if } y>c \\\\\n",
        "    &= 1-\\Phi\\left(\\frac{x\\beta}{\\sigma} \\right) \\text{ if } y\\leq c \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "If data is truncated, we need to \"adjust\" the distribution of what is observed\n",
        "\n",
        "$$\\begin{aligned}\n",
        "L_i &= \\frac{1}{\\Phi\\left( x\\beta/\\sigma \\right)} \\frac{1}{\\sigma} \\phi\\left( \\frac{y-x\\beta}{\\sigma} \\right) \\text{ if } y>c \\\\  \n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "We will put -truncated regression- on the side for now. But see [here](https://stats.oarc.ucla.edu/stata/output/truncated-regression/) for an example.\n",
        "\n",
        "## Interpretation: It depends!\n",
        "\n",
        "- What are you interested in analyzing? and what type of data you have?  \n",
        "\n",
        ":::{.panel-tabset}\n",
        "\n",
        "## Latent variable\n",
        "\n",
        "- Easiest Case. Just need to consider the coefficients (as in LRM)\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "E(y^*|x) &= x\\beta \\\\\n",
        "\\frac{\\partial E(y^*|x)}{\\partial x } &= \\beta_x\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "- The same applies if model was censored.\n",
        "\n",
        "## $P(y>0|x)$ \n",
        "\n",
        "- Its an alternative approach to Probit models, where you are interest in analyzing why is data Not censored, or why is it above some threshold. (why people work)\n",
        "\n",
        "- Extensive margin effect.\n",
        "$$\n",
        "\\begin{aligned}\n",
        "P(y>0|x) &= \\Phi\\left(\\frac{x\\beta}{\\sigma}\\right) \\\\\n",
        "\\frac{\\partial P(y>0|x)}{\\partial x } &= \\frac{\\beta_x}{\\sigma} \\phi\\left(\\frac{x\\beta}{\\sigma}\\right)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Note: Coefficients $\\beta$ need to be Standardized.\n",
        "\n",
        "## $E(y|y>0,x)$ \n",
        "\n",
        "- If corner solution, one may be interested in the effect of those with positive outcomes only. \n",
        "\n",
        "- This is the intensive margin effect.\n",
        "$$\n",
        "\\begin{aligned}\n",
        "E(y|y>0,x) &= x\\beta + \\sigma \\frac{\\phi(x\\beta / \\sigma )}{\\Phi(x\\beta / \\sigma )} \\\\\n",
        "\\frac{\\partial E(y|y>0,x)}{\\partial x } &= \\beta_x\n",
        "\\left[ 1-\\frac{\\phi(x\\beta / \\sigma )}{\\Phi(x\\beta / \\sigma )} \\left( \\frac{x\\beta }{\\sigma }+ \\frac{\\phi(x\\beta / \\sigma )}{\\Phi(x\\beta / \\sigma )}\\right) \\right]\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "## $E(y|x)$ \n",
        "\n",
        "- In this case, one may be interested in estimating the expected effect on everyone.\n",
        "- Combines both Intensive and extensive margin effects. Comparable to OLS.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "E(y|x) &= p(y>0|x)*E(y|y>0,x) + (1-p(y>0|x))*0 \\\\\n",
        "\\frac{\\partial E(y|x)}{\\partial x } &= \\beta_x \\Phi(x\\beta)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        "## Example {.scrollable}\n"
      ],
      "id": "f5f6ec81"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "frause mroz, clear\n",
        "qui:tobit hours nwifeinc educ c.exper##c.exper   age kidslt6 kidsge6 , ll(0)\n",
        "qui:emargins, dydx(*) estore(m1)\n",
        "qui:emargins, dydx(*) predict(p(0,.)) estore(m2)\n",
        "qui:emargins, dydx(*) predict(e(0,.)) estore(m3)\n",
        "qui:emargins, dydx(*) predict(ystar(0,.)) estore(m4)\n",
        "esttab m1 m2 m3 m4, mtitle(Latent P(y>0) E(y|y>0) E(y) ) b(3) se"
      ],
      "id": "ea334098",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tobit has problems too\n",
        "\n",
        "> That simple equation, too much aggregation  \n",
        ">    Hayek (in [Fear the Boom and Bust](https://www.youtube.com/watch?v=d0nERTFo-Sk))\n",
        "\n",
        "- Tobit, when addressing corner solutions, aims to explain two different actions (Engagement and intensity) with the same model. However, this may not be appropriate all the time.\n",
        "  - HW-Examples?\n",
        "- When this happens, other models may be more appropritate like\n",
        "  - two part model: (literally model using two equations)\n",
        "  - Hurdle Model (`craggit` or `churdle`)\n",
        "- Also...Normality...\n",
        "\n",
        "## Censored Regression {.scrollable}\n",
        "\n",
        "- Applies to the same cases as Tobit model. But, it usually refers to Censoring at other points of the distribution (upper censoring? mixed censoring?) \n",
        "- Furthermore, applies to cases with different censoring thresholds!\n",
        "  - Typical Example, Unemployment duration\n"
      ],
      "id": "61431016"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "qui:frause recid, clear\n",
        "gen lldur = ldurat             // Lower Limit\n",
        "gen uudur = ldurat if cens==0  // upper limit = . if censored.\n",
        "intreg lldur uudur workprg priors tserved felon alcohol drugs black married educ age"
      ],
      "id": "f4e8cd04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Truncated {.scrollable}\n",
        "\n",
        "- If Data is simply not there, as shown before, one needs to adjust Estimates.\n",
        "- marginal effects decisions are similar to Tobit\n"
      ],
      "id": "45d55363"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| code-fold: false\n",
        "frause mroz, clear\n",
        "qui:truncreg hours nwifeinc educ c.exper##c.exper   age kidslt6 kidsge6 , ll(0)\n",
        "emargins, dydx(*) estore(m1b)\n",
        "emargins, dydx(*) predict(e(0,.)) estore(m2b)\n",
        "esttab m1 m1b m3 m2b, mtitle(Lat-Tobit Lat-Trunc E(y>0)-Tobit E(y>0)-Trunc ) b(3) se"
      ],
      "id": "192dbedf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Break?\n",
        "\n",
        "## Poisson\n",
        "\n",
        "- Some times, Data may be non-negative, and/or countable. OLS works well, but we could do better\n",
        "\n",
        "- With Count data, some data transformations (logs) are not possible, because of the zeroes. \n",
        "\n",
        "- So instead of assuming $y|x \\sim N(\\mu_x,\\sigma)$, one could assume $y|x \\sim poisson(\\mu_x)$\n",
        "\n",
        "$$P(y=k,\\mu_x) = \\frac{\\mu_x^k e ^{-\\mu_x}}{k!} \\text{ with } \\mu_x=\\exp(x\\beta)$$\n",
        "\n",
        "- For a Poisson:\n",
        "  - $E(y|x) = \\exp{x\\beta}$ and $Var(y|x) = \\exp{x\\beta}$\n",
        "\n",
        "- As hinted before, Count data is heteroskedastic. And Poisson assumes some structure to that.\n",
        "\n",
        "## \n",
        "\n",
        "- Also convinient that Poisson models are very easy to interpret! (just like Log-lin models)  \n",
        "  After estimation:\n",
        "\n",
        "$$\\frac{\\Delta \\% E(y|x)}{\\Delta x} \\simeq \\beta_x \\times 100 \\text{ or } (\\exp \\beta_x-1)\\times 100 $$\n",
        "\n",
        "- Other points.\n",
        "  - The variance imposed in Poisson is very restrictive. This is a problem for Variance estimation!  \n",
        "    Solution: use Robust Standard Errors!\n",
        "  - Like LRM, poisson is robust to errors when modeling the conditional mean.\n",
        "  - Poisson is a very good alternative for continuous data too (if using Robust SE)\n",
        "    - Wage models, trade models\n",
        "\n",
        "## Example{.scrollable}\n"
      ],
      "id": "6eceb8bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "*| code-fold: false\n",
        "frause crime1, clear\n",
        "qui: reg narr86 pcnv avgsen tottime ptime86 qemp86 inc86 black hispan born60\n",
        "est sto m1\n",
        "qui:poisson narr86 pcnv avgsen tottime ptime86 qemp86 inc86 black hispan born60, robust\n",
        "est sto m2\n",
        "qui:emargins, dydx(*) estore(m3)\n",
        "esttab m1 m2 m3, se b(3) mtitle(LRM Poisson Poisson-mfx) ///\n",
        "keep(pcnv ptime86  qemp86 inc86 black hispan) label varwidth(20) wrap"
      ],
      "id": "192bd887",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other Methods of interest\n",
        "\n",
        "- MLE opens the door to other methods that may be more approriate to analyze data\n",
        "- They may even be able to handle otherwise unsolvable data problems. \n",
        "  - ologit, oprobit: Ordered qualitative variables\n",
        "  - mlogit, mprobit: Unordered Qualitative variables\n",
        "  - heckman: Endogenous Sample Selection\n",
        "  - fractional regression model: When the depvariable is an index\n",
        "  - etc etc\n",
        "- Worth knowing, but not for the exam!\n",
        "\n",
        "# Thats all. \n",
        "Next class: Pool and Basic Panel data analysis"
      ],
      "id": "140633fc"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "nbstata",
      "language": "stata",
      "display_name": "Stata (nbstata)",
      "path": "C:\\Users\\Fernando\\AppData\\Roaming\\jupyter\\kernels\\nbstata"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}